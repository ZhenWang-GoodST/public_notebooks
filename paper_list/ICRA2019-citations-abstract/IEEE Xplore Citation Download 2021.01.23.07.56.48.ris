TY  - CONF
TI  - Dynamics Consensus between Centroidal and Whole-Body Models for Locomotion of Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6727
EP  - 6733
AU  - R. Budhiraja
AU  - J. Carpentier
AU  - N. Mansard
PY  - 2019
KW  - humanoid robots
KW  - legged locomotion
KW  - manipulator dynamics
KW  - motion control
KW  - optimal control
KW  - optimisation
KW  - pendulums
KW  - whole-body level
KW  - whole-body optimal control problem
KW  - centroidal dynamics
KW  - manipulator dynamics
KW  - effective locomotion
KW  - HRP-2 robot
KW  - dynamics consensus
KW  - legged robots
KW  - large control problem
KW  - complex optimal control problem
KW  - numerical solver
KW  - inverted pendulum
KW  - capture points
KW  - whole-body constraints
KW  - reduced level
KW  - reduced solution
KW  - centroidal state dynamics
KW  - mathematical framework
KW  - Dynamics
KW  - Legged locomotion
KW  - Trajectory
KW  - Optimization
KW  - Convex functions
KW  - Optimal control
DO  - 10.1109/ICRA.2019.8793878
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is nowadays well-established that locomotion can be written as a large and complex optimal control problem. Yet, current knowledge in numerical solver fails to directly solve it. A common approach is to cut the dimensionality by relying on reduced models (inverted pendulum, capture points, centroidal). However it is difficult both to account for whole-body constraints at the reduced level and also to define what is an acceptable trade-off at the whole-body level between tracking the reduced solution or searching for a new one. The main contribution of this paper is to introduce a rigorous mathematical framework based on the Alternating Direction Method of Multipliers, to enforce the consensus between the centroidal state dynamics at reduced and whole-body level. We propose an exact splitting of the whole-body optimal control problem between the centroidal dynamics (under-actuation) and the manipulator dynamics (full actuation), corresponding to a re-arrangement of the equations already stated in previous works. We then describe with details how alternating descent is a good solution to implement an effective locomotion solver. We validate this approach in simulation with walking experiments on the HRP-2 robot.
ER  - 

TY  - CONF
TI  - Adaptive Bingham Distribution Based Filter for SE (3) Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6734
EP  - 6740
AU  - F. Li
AU  - G. A. G. Ricardez
AU  - J. Takamatsu
AU  - T. Ogasawara
PY  - 2019
KW  - adaptive filters
KW  - Gaussian distribution
KW  - pose estimation
KW  - SO(3) groups
KW  - incremental properties
KW  - Gaussian distribution
KW  - pose parameters
KW  - adaptive filtering ability
KW  - adaptive Bingham distribution
KW  - filter-based methods
KW  - autonomous tuning
KW  - SE (3) estimation
KW  - 3D pose estimation problems
KW  - SO(3) group
KW  - Measurement uncertainty
KW  - Pose estimation
KW  - Uncertainty
KW  - Kalman filters
KW  - Gaussian distribution
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793997
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Filter-based methods are a suitable option to deal with the burdensome 3D pose estimation problems for their incremental properties. The classical approaches use the Gaussian distribution to model the uncertainty of the pose parameters and recent work has begun to take advantage of the Bingham distribution, which is theoretically more suitable for modeling uncertainty on the SO(3) group. However, these algorithms are still at the very beginning and heavily rely on manual tuning. In this work we equip the Bingham distribution based filter with adaptive filtering ability, which realizes completely autonomous tuning without human interaction. The experiments demonstrate that our method is significantly laborsaving compared to the state-of-the-art methods as well as capable of maintaining high accuracy.
ER  - 

TY  - CONF
TI  - GuSTO: Guaranteed Sequential Trajectory optimization via Sequential Convex Programming
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6741
EP  - 6747
AU  - R. Bonalli
AU  - A. Cauligi
AU  - A. Bylard
AU  - M. Pavone
PY  - 2019
KW  - convex programming
KW  - optimal control
KW  - GuSTO
KW  - control-affine systems
KW  - indirect optimal control
KW  - guaranteed sequential trajectory optimization
KW  - optimal control setups
KW  - SCP-based methods
KW  - theoretical convergence
KW  - sequential convex programming
KW  - algorithmic framework
KW  - Trajectory optimization
KW  - Convergence
KW  - Optimal control
KW  - Robots
KW  - Heuristic algorithms
KW  - Planning
DO  - 10.1109/ICRA.2019.8794205
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sequential Convex Programming (SCP) has recently seen a surge of interest as a tool for trajectory optimization. However, most available methods lack rigorous performance guarantees and they are often tailored to specific optimal control setups. In this paper, we present GuSTO (Guaranteed Sequential Trajectory optimization), an algorithmic framework to solve trajectory optimization problems for control-affine systems with drift. GuSTO generalizes earlier SCP-based methods for trajectory optimization (by addressing, for example, goal-set constraints and problems with either fixed or free final time) and enjoys theoretical convergence guarantees in terms of convergence to, at least, a stationary point. The theoretical analysis is further leveraged to devise an accelerated implementation of GuSTO, which originally infuses ideas from indirect optimal control into an SCP context. Numerical experiments on a variety of trajectory optimization setups show that GuSTO generally outperforms current state-of-the-art approaches in terms of success rates, solution quality, and computation times.
ER  - 

TY  - CONF
TI  - Efficient Computation of Feedback Control for Equality-Constrained LQR
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6748
EP  - 6754
AU  - F. Laine
AU  - C. Tomlin
PY  - 2019
KW  - discrete time systems
KW  - feedback
KW  - linear quadratic control
KW  - optimisation
KW  - Riccati equations
KW  - robots
KW  - feedback control
KW  - equality-constrained LQR
KW  - discrete-time finite-horizon Linear Quadratic Regulator problem
KW  - auxiliary linear equality constraints
KW  - fixed end-point constraints
KW  - standard Riccati recursion
KW  - linearly-constrained LQR problem
KW  - robotic trajectory optimization
KW  - Robots
KW  - Feedback control
KW  - Optimal control
KW  - Trajectory optimization
KW  - Computational complexity
KW  - Dynamic programming
DO  - 10.1109/ICRA.2019.8793566
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A method is presented for solving the discrete-time finite-horizon Linear Quadratic Regulator (LQR) problem subject to auxiliary linear equality constraints, such as fixed end-point constraints. The method explicitly determines an affine relationship between the control and state variables, as in standard Riccati recursion, giving rise to feedback control policies that account for constraints. Since the linearly-constrained LQR problem arises commonly in robotic trajectory optimization, having a method that can efficiently compute these solutions is important. We demonstrate some of the useful properties and interpretations of said control policies, and we compare the computation time and complexity of our method against existing methods.
ER  - 

TY  - CONF
TI  - Mitigating energy loss in a robot hopping on a physically emulated dissipative substrate
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6763
EP  - 6769
AU  - S. Roberts
AU  - D. E. Koditschek
PY  - 2019
KW  - damping
KW  - energy conservation
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - sand
KW  - mitigating energy loss
KW  - physically emulated dissipative substrate
KW  - erosion
KW  - desertification
KW  - spatial resolution
KW  - temporal resolution
KW  - data collection
KW  - attractive scout robot candidate
KW  - heavily geared sensor-laden RHex
KW  - long-distance locomotion
KW  - virtual damping force
KW  - Minitaur foot
KW  - simulated granular media
KW  - bulk-behavior force law
KW  - ground emulator
KW  - single-legged hopper
KW  - physical hopping experiments
KW  - substrate emulator
KW  - linear stiffness
KW  - quadratic damping
KW  - Minitaur robot
KW  - ground properties
KW  - bulk-behavior model
KW  - energy savings
KW  - robot hopping
KW  - physical single-legged hopper jumping
KW  - Legged locomotion
KW  - Springs
KW  - Damping
KW  - Media
KW  - Foot
KW  - Force
DO  - 10.1109/ICRA.2019.8793781
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We work with geoscientists studying erosion and desertification to improve the spatial and temporal resolution of their data collection over long transects in difficult realworld environments such as deserts [1]. The Minitaur [2] robot, which can run quickly over uneven terrain and use a single leg to measure relevant ground properties such as stiffness [3], is an attractive scout robot candidate for inclusion in a heterogeneous team in collaboration with a heavily geared, sensor-laden RHex [4]. However, Minitaur is challenged by long-distance locomotion on sand dunes. Previous simulation results [5] suggested that the energetic cost of transport can be mitigated by programming a virtual damping force to slow the intrusion of a Minitaur foot into simulated granular media following a bulk-behavior force law [6]. In this paper, we present a ground emulator that can be used to test such locomotion hypotheses with a physical single-legged hopper jumping on emulated ground programmed to exhibit any compliance and damping characteristics of interest. The new emulator allows us to corroborate the conclusions of our previous simulation with physical hopping experiments. Programming the substrate emulator to exhibit the mechanics of a simplified bulk-behavior model of granular media characterized by linear stiffness and quadratic damping, we achieve a consistent energy savings of 20% in comparison with a nominal controller, with savings of up to 50% under specific conditions.
ER  - 

TY  - CONF
TI  - Energy Efficient Navigation for Running Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6770
EP  - 6776
AU  - M. Y. Harper
AU  - J. V. Nicholson
AU  - E. G. Collins
AU  - J. Pusey
AU  - J. E. Clark
PY  - 2019
KW  - energy conservation
KW  - energy consumption
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - robot dynamics
KW  - sampling methods
KW  - search problems
KW  - trajectory control
KW  - mobile robots
KW  - energy savings
KW  - energy consumption
KW  - energy efficient navigation
KW  - running legged robots
KW  - sampling-based model predictive optimization
KW  - LLAMA quadrupedal platform
KW  - heuristic-based search
KW  - robot dynamics
KW  - robot motion plan
KW  - trajectory planning
KW  - Legged locomotion
KW  - Trajectory
KW  - Computational modeling
KW  - Predictive models
KW  - Planning
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793599
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Energy-efficient navigation is an important technology for mobile robots because of its potential to increase the operation time of the robot. In particular, when coupled with a dynamic legged quadruped, the need for energy savings is made more apparent as payloads are limited. Due to the complexity in modeling motion and power models of these robots, a new approach is necessary to effectively motion plan for these complex robots. We accomplish this by using Sampling-Based Model Predictive optimization (SBMPO) which was extended for use on the LLAMA quadrupedal platform in simulation. SBMPO allows for direct generation of trajectories while using a heuristic-based search to speed up computations. This approach is shown to effectively motion plan while optimizing for energy consumption and maintaining the natural dynamics of the robot in a simulated environment.
ER  - 

TY  - CONF
TI  - Force-controllable Quadruped Robot System with Capacitive-type Joint Torque Sensor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6777
EP  - 6782
AU  - Y. H. Lee
AU  - Y. H. Lee
AU  - H. Lee
AU  - H. Kang
AU  - L. T. Phan
AU  - S. Jin
AU  - Y. B. Kim
AU  - D. Seok
AU  - S. Y. Lee
AU  - H. Moon
AU  - J. C. Koo
AU  - H. R. Choi
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - force control
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - torque control
KW  - force-controllable quadruped robot system
KW  - CJTS
KW  - zero-force control
KW  - walking/trot gait
KW  - capacitive-type joint torque sensor
KW  - joint torque controllability
KW  - actuator module
KW  - size 0.05 nm
KW  - size 70.0 nm
KW  - time 0.04 s
KW  - Robot sensing systems
KW  - Torque
KW  - Actuators
KW  - Legged locomotion
KW  - Torque measurement
DO  - 10.1109/ICRA.2019.8794459
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a force-controllable quadruped robot system consists of twelve Actuator Modules embedded a novel Capacitive-type Joint Torque Sensor (CJTS) which is accurate (0.05 Nm), robust to impact, and easy to manufacture at low cost. The Actuator Module with CJTS shows accurate joint torque controllability in range of ±70 Nm (90 % settling time 0.04 s). The leg made by the three Actuator Modules is capable of generating forces in the z-axis up to 350 N and shows force control performances with zero-force control and lifting weights in three-dimensional space. To reduce the reflected limb inertia, all the Actuator Modules are located on the body frame and light-weight limbs made of the carbon pipe (3.6 % of total body weight). The introduced robot performed the motion on various terrains with walking/trot gaits.
ER  - 

TY  - CONF
TI  - Visual Diver Recognition for Underwater Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6839
EP  - 6845
AU  - Y. Xia
AU  - J. Sattar
PY  - 2019
KW  - autonomous underwater vehicles
KW  - convolutional neural nets
KW  - human-robot interaction
KW  - mobile robots
KW  - multi-robot systems
KW  - object detection
KW  - pattern clustering
KW  - visual diver recognition
KW  - underwater human-robot collaboration
KW  - autonomous underwater robot
KW  - visual scene
KW  - human leader
KW  - detected bounding boxes
KW  - mobile robot
KW  - k-means clustering algorithm
KW  - feature vector
KW  - frequency domain descriptors
KW  - spatial domain descriptors
KW  - region proposal network
KW  - faster R-CNN algorithm
KW  - diver identification
KW  - multihuman-robot teams
KW  - multiple divers detection
KW  - Feature extraction
KW  - Robots
KW  - Image color analysis
KW  - Image edge detection
KW  - Visualization
KW  - Target tracking
DO  - 10.1109/ICRA.2019.8794290
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an approach for autonomous underwater robots to visually detect and identify divers. The proposed approach enables an autonomous underwater robot to detect multiple divers in a visual scene and distinguish between them. Such methods are useful for robots to identify a human leader, for example, in multi-human/robot teams where only designated individuals are allowed to command or lead a team of robots. Initial diver identification is performed using the Faster R-CNN algorithm with a region proposal network which produces bounding boxes around the divers' locations. Subsequently, a suite of spatial and frequency domain descriptors are extracted from the bounding boxes to create a feature vector. A K-Means clustering algorithm, with k set to the number of detected bounding boxes, thereafter identifies the detected divers based on these feature vectors. We evaluate the performance of the proposed approach on video footage of divers swimming in front of a mobile robot and demonstrate its accuracy.
ER  - 

TY  - CONF
TI  - An Integrated Approach to Navigation and Control in Micro Underwater Robotics using Radio-Frequency Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6846
EP  - 6852
AU  - D. A. Duecker
AU  - T. Johannink
AU  - E. Kreuzer
AU  - V. Rausch
AU  - E. Solowjow
PY  - 2019
KW  - autonomous underwater vehicles
KW  - marine navigation
KW  - microrobots
KW  - mobile robots
KW  - position control
KW  - radio-frequency localization
KW  - microautonomous underwater vehicles
KW  - μAUVs
KW  - integrated navigation
KW  - control architecture
KW  - low-cost embedded localization module
KW  - integrated approach
KW  - underwater localization systems
KW  - microunderwater robotics
KW  - underwater way-point tracking controller
KW  - Robots
KW  - Attenuation
KW  - Navigation
KW  - Acoustics
KW  - Computer architecture
KW  - Noise measurement
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8794088
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Navigation and control are a largely unsolved problems for micro autonomous underwater vehicles (μAUVs). The main challenges are due to the lack of accurate underwater localization systems, which fit on-board of μAUVs. In this work, we present an integrated navigation and control architecture consisting of a low-cost embedded localization module and an underwater way-point tracking controller, which fulfills the requirements of μAUVs. The performance of the navigation and control system is benchmarked in two different experimental scenarios.
ER  - 

TY  - CONF
TI  - Online Utility-Optimal Trajectory Design for Time-Varying Ocean Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6853
EP  - 6859
AU  - M. K. Nutalapati
AU  - S. Joshi
AU  - K. Rajawat
PY  - 2019
KW  - convex programming
KW  - energy consumption
KW  - gradient methods
KW  - marine engineering
KW  - mobile robots
KW  - time-varying systems
KW  - trajectory control
KW  - online utility-optimal trajectory design
KW  - time-varying ocean environments
KW  - time-varying environments
KW  - energy-efficient trajectories
KW  - strong disturbances
KW  - uncertain disturbances
KW  - time-varying goal location
KW  - constrained online convex optimization formalism
KW  - gradient descent algorithm
KW  - vehicle locations
KW  - energy consumption
KW  - regional ocean modelling system
KW  - ocean velocity measurements
KW  - Trajectory
KW  - Oceans
KW  - Planning
KW  - Convex functions
KW  - Delays
KW  - Energy consumption
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794365
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper considers the problem of online optimal trajectory design under time-varying environments. Of particular interest is the design of energy-efficient trajectories under strong and uncertain disturbances in ocean environments and time-varying goal location. We formulate the problem within the constrained online convex optimization formalism, and a modified online gradient descent algorithm is motivated. The mobility constraints are met using a carefully chosen stepsize, and the proposed algorithm is shown to incur sublinear regret. Different from the state-of-the-art algorithms that entail planning and re-planning the full trajectory using forecast data at each time instant, the proposed algorithm is entirely online and relies mostly on the current ocean velocity measurements at the vehicle locations. The trade-off between excess delay incurred in reaching the goal and the overall energy consumption is examined via numerical tests carried out on real data obtained from the regional ocean modelling system. As compared to the state-of-the-art algorithms, the proposed algorithm is not only energy-efficient but also several orders of magnitude computationally efficient.
ER  - 

TY  - CONF
TI  - Online Continuous Mapping using Gaussian Process Implicit Surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6884
EP  - 6890
AU  - B. Lee
AU  - C. Zhang
AU  - Z. Huang
AU  - D. D. Lee
PY  - 2019
KW  - approximation theory
KW  - Gaussian processes
KW  - mobile robots
KW  - path planning
KW  - regression analysis
KW  - implicit surface
KW  - SDF
KW  - regressor
KW  - gaussian process implicit surface
KW  - robotic tasks
KW  - signed-distance function
KW  - sparse measurements
KW  - grid-based methods
KW  - online continuous mapping
KW  - Surface treatment
KW  - Planning
KW  - Noise measurement
KW  - Training
KW  - Robot kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794324
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The representation of the environment strongly affects how robots can move and interact with it. This paper presents an online approach for continuous mapping using Gaussian Process Implicit Surfaces (GPISs). Compared with grid-based methods, GPIS better utilizes sparse measurements to represent the world seamlessly. It provides direct access to the signed-distance function (SDF) and its derivatives which are invaluable for other robotic tasks and it incorporates uncertainty in the sensor measurements. Our approach incrementally and efficiently updates GPIS by employing a regressor on observations and a spatial tree structure. The effectiveness of the suggested approach is demonstrated using simulations and real world 2D/3D data.
ER  - 

TY  - CONF
TI  - Dense 3D Visual Mapping via Semantic Simplification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6891
EP  - 6897
AU  - L. Morreale
AU  - A. Romanoni
AU  - M. Matteucci
AU  - P. d. Milano
PY  - 2019
KW  - data visualisation
KW  - image reconstruction
KW  - image segmentation
KW  - mesh generation
KW  - robot vision
KW  - solid modelling
KW  - semantic image segmentation
KW  - perceived point cloud
KW  - global statistics
KW  - class boundaries
KW  - infra-class edges
KW  - 3D dense model
KW  - 3D Delaunay Triangulation
KW  - variable point cloud density
KW  - semantic simplification
KW  - dense 3D visual mapping estimates
KW  - dense point clouds
KW  - pixel depths
KW  - point cloud simplification methods
KW  - roughly planar surface
KW  - Three-dimensional displays
KW  - Semantics
KW  - Solid modeling
KW  - Image reconstruction
KW  - Image segmentation
KW  - Structure from motion
KW  - Surface reconstruction
DO  - 10.1109/ICRA.2019.8793256
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dense 3D visual mapping estimates as many as possible pixel depths, for each image. This results in very dense point clouds that often contain redundant and noisy information, especially for surfaces that are roughly planar, for instance, the ground or the walls in the scene. In this paper we leverage on semantic image segmentation to discriminate which regions of the scene require simplification and which should be kept at high level of details. We propose four different point cloud simplification methods which decimate the perceived point cloud by relying on class-specific local and global statistics still maintaining more points in the proximity of class boundaries to preserve the infra-class edges and discontinuities. 3D dense model is obtained by fusing the point clouds in a 3D Delaunay Triangulation to deal with variable point cloud density. In the experimental evaluation we have shown that, by leveraging on semantics, it is possible to simplify the model and diminish the noise affecting the point clouds.
ER  - 

TY  - CONF
TI  - Predicting the Layout of Partially Observed Rooms from Grid Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6898
EP  - 6904
AU  - M. Luperto
AU  - V. Arcerito
AU  - F. Amigoni
PY  - 2019
KW  - control engineering computing
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - SLAM algorithms
KW  - 2D metric grid map
KW  - global structure
KW  - partially observed rooms
KW  - autonomous mobile robots
KW  - indoor environments
KW  - robot sensors
KW  - geometrical primitives
KW  - Layout
KW  - Measurement
KW  - Robots
KW  - Indoor environment
KW  - Two dimensional displays
KW  - Three-dimensional displays
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793489
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In several applications, autonomous mobile robots benefit from knowing the structure of the indoor environments where they operate. This knowledge can be extracted from the metric maps built (e.g., using SLAM algorithms) from the data perceived by the robots' sensors. The layout is a way to represent the structure of an indoor environment with geometrical primitives. Most of the current methods for reconstructing the layout from a metric map represent the parts of the environment that have been fully observed. In this paper, we propose an approach that predicts the layout of rooms which are only partially known in a 2D metric grid map. The prediction is made according to the global structure of the environment, as identified from its known parts. Experiments show that our approach is able to effectively predict the layout of several indoor environments that have been observed to different degrees.
ER  - 

TY  - CONF
TI  - Dense Surface Reconstruction from Monocular Vision and LiDAR
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6905
EP  - 6911
AU  - Z. Li
AU  - P. C. Gogia
AU  - M. Kaess
PY  - 2019
KW  - cameras
KW  - graph theory
KW  - image reconstruction
KW  - mobile robots
KW  - optical radar
KW  - pipelines
KW  - robot vision
KW  - stereo image processing
KW  - surface reconstruction
KW  - LiDAR measurements
KW  - multiview stereo pipeline
KW  - watertight surface mesh
KW  - state-of-the-art camera-only
KW  - LiDAR-only reconstruction methods
KW  - monocular vision
KW  - surface reconstruction pipeline
KW  - monocular camera images
KW  - moving sensor rig
KW  - indoor scenes
KW  - indoor environments
KW  - 3D mesh models
KW  - state-of-the-art multiview stereo
KW  - graph cut algorithm
KW  - Laser radar
KW  - Cameras
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Surface reconstruction
KW  - Pipelines
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793729
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we develop a new surface reconstruction pipeline that combines monocular camera images and LiDAR measurements from a moving sensor rig to reconstruct dense 3D mesh models of indoor scenes. For surface reconstruction, the 3D LiDAR and camera are widely deployed for gathering geometric information from environments. Current state-of-the-art multi-view stereo or LiDAR-only reconstruction methods cannot reconstruct indoor environments accurately due to shortcomings of each sensor type. In our approach, LiDAR measurements are integrated into a multi-view stereo pipeline for point cloud densification and tetrahedralization. In addition to that, a graph cut algorithm is utilized to generate a watertight surface mesh. Because our proposed method leverages the complementary nature of these two sensors, the accuracy and completeness of the output model are improved. The experimental results on real world data show that our method significantly outperforms both the state-of-the-art camera-only and LiDAR-only reconstruction methods in accuracy and completeness.
ER  - 

TY  - CONF
TI  - FSMI: Fast Computation of Shannon Mutual Information for Information-Theoretic Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6912
EP  - 6918
AU  - Z. Zhang
AU  - T. Henderson
AU  - V. Sze
AU  - S. Karaman
PY  - 2019
KW  - approximation theory
KW  - gradient methods
KW  - information theory
KW  - mobile robots
KW  - multi-robot systems
KW  - FSMI algorithm
KW  - fast Shannon mutual information
KW  - Cauchy-Schwarz quadratic mutual information
KW  - information-based mapping algorithms
KW  - information-theoretic mapping
KW  - CSQMI
KW  - FSMI
KW  - Mutual information
KW  - Approximation algorithms
KW  - Robot sensing systems
KW  - Measurement
KW  - Standards
KW  - Random variables
DO  - 10.1109/ICRA.2019.8793541
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Information-based mapping algorithms are critical to robot exploration tasks in several applications ranging from disaster response to space exploration. Unfortunately, most existing information-based mapping algorithms are plagued by the computational difficulty of evaluating the Shannon mutual information between potential future sensor measurements and the map. This has lead researchers to develop approximate methods, such as Cauchy-Schwarz Quadratic Mutual Information (CSQMI). In this paper, we propose a new algorithm, called Fast Shannon Mutual Information (FSMI), which is significantly faster than existing methods at computing the exact Shannon mutual information. The key insight behind FSMI is recognizing that the integral over the sensor beam can be evaluated analytically, removing an expensive numerical integration. In addition, we provide a number of approximation techniques for FSMI, which significantly improve computation time. Equipped with these approximation techniques, the FSMI algorithm is more than three orders of magnitude faster than the existing computation for Shannon mutual information; it also outperforms the CSQMI algorithm significantly, being roughly twice as fast, in our experiments.
ER  - 

TY  - CONF
TI  - Real-time Scalable Dense Surfel Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6919
EP  - 6925
AU  - K. Wang
AU  - F. Gao
AU  - S. Shen
PY  - 2019
KW  - image fusion
KW  - image reconstruction
KW  - pose estimation
KW  - SLAM (robots)
KW  - intensity images
KW  - depth images
KW  - globally consistent model
KW  - room-scale environments
KW  - urban-scale environments
KW  - RGB-D cameras
KW  - stereo cameras
KW  - monocular camera
KW  - superpixel-based surfels
KW  - reconstructed models
KW  - fast map deformation
KW  - global consistency
KW  - room-scale reconstruction
KW  - time scalable dense surfel
KW  - CPU computation
KW  - sparse SLAM system
KW  - camera poses
KW  - dense surfel mapping system
KW  - Cameras
KW  - Image reconstruction
KW  - Strain
KW  - Fuses
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794101
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel dense surfel mapping system that scales well in different environments with only CPU computation. Using a sparse SLAM system to estimate camera poses, the proposed mapping system can fuse intensity images and depth images into a globally consistent model. The system is carefully designed so that it can build from room-scale environments to urban-scale environments using depth images from RGB-D cameras, stereo cameras or even a monocular camera. First, superpixels extracted from both intensity and depth images are used to model surfels in the system. superpixel-based surfels make our method both runtime efficient and memory efficient. Second, surfels are further organized according to the pose graph of the SLAM system to achieve O(1) fusion time regardless of the scale of reconstructed models. Third, a fast map deformation using the optimized pose graph enables the map to achieve global consistency in real-time. The proposed surfel mapping system is compared with other state-of-the-art methods on synthetic datasets. The performances of urban-scale and room-scale reconstruction are demonstrated using the KITTI dataset [1] and autonomous aggressive flights, respectively. The code is available for the benefit of the community.
ER  - 

TY  - CONF
TI  - Inferring Compact Representations for Efficient Natural Language Understanding of Robot Instructions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6926
EP  - 6933
AU  - S. Patki
AU  - A. F. Daniele
AU  - M. R. Walter
AU  - T. M. Howard
PY  - 2019
KW  - control engineering computing
KW  - graph theory
KW  - human-robot interaction
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - natural language processing
KW  - probability
KW  - robot programming
KW  - compact environment model
KW  - perceptual classifiers
KW  - succinct instruction-specific environment representation
KW  - probabilistic graphical models
KW  - natural language symbol grounding
KW  - robot instructions
KW  - approximate inference algorithms
KW  - natural language understanding
KW  - environment-related information
KW  - human-robot interaction
KW  - compact representations
KW  - Grounding
KW  - Natural languages
KW  - Computational modeling
KW  - Adaptation models
KW  - Robots
KW  - Semantics
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793667
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The speed and accuracy with which robots are able to interpret natural language is fundamental to realizing effective human-robot interaction. A great deal of attention has been paid to developing models and approximate inference algorithms that improve the efficiency of language understanding. However, existing methods still attempt to reason over a representation of the environment that is flat and unnecessarily detailed, which limits scalability. An open problem is then to develop methods capable of producing the most compact environment model sufficient for accurate and efficient natural language understanding. We propose a model that leverages environment-related information encoded within instructions to identify the subset of observations and perceptual classifiers necessary to perceive a succinct, instruction-specific environment representation. The framework uses three probabilistic graphical models trained from a corpus of annotated instructions to infer salient scene semantics, perceptual classifiers, and grounded symbols. Experimental results on two robots operating in different environments demonstrate that by exploiting the content and the structure of the instructions, our method learns compact environment representations that significantly improve the efficiency of natural language symbol grounding.
ER  - 

TY  - CONF
TI  - Improving Grounded Natural Language Understanding through Human-Robot Dialog
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6934
EP  - 6941
AU  - J. Thomason
AU  - A. Padmakumar
AU  - J. Sinapov
AU  - N. Walker
AU  - Y. Jiang
AU  - H. Yedidsion
AU  - J. Hart
AU  - P. Stone
AU  - R. J. Mooney
PY  - 2019
KW  - grammars
KW  - human-robot interaction
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - natural language understanding
KW  - human-robot dialog
KW  - virtual setting
KW  - Amazon Mechanical Turk
KW  - physical robot platform
KW  - concept grounding
KW  - language parsing
KW  - robot actions
KW  - natural language commands
KW  - end-to-end pipeline
KW  - perceptual concepts
KW  - language constructions
KW  - human environments
KW  - human commands
KW  - Semantics
KW  - Task analysis
KW  - Grounding
KW  - Natural languages
KW  - Robot sensing systems
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8794287
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Natural language understanding for robotics can require substantial domain- and platform-specific engineering. For example, for mobile robots to pick-and-place objects in an environment to satisfy human commands, we can specify the language humans use to issue such commands, and connect concept words like red can to physical object properties. One way to alleviate this engineering for a new domain is to enable robots in human environments to adapt dynamically-continually learning new language constructions and perceptual concepts. In this work, we present an end-to-end pipeline for translating natural language commands to discrete robot actions, and use clarification dialogs to jointly improve language parsing and concept grounding. We train and evaluate this agent in a virtual setting on Amazon Mechanical Turk, and we transfer the learned agent to a physical robot platform to demonstrate it in the real world.
ER  - 

TY  - CONF
TI  - Prospection: Interpretable plans from language by predicting the future
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6942
EP  - 6948
AU  - C. Paxton
AU  - Y. Bisk
AU  - J. Thomason
AU  - A. Byravan
AU  - D. Foxl
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - robot programming
KW  - high-level human instructions
KW  - natural-language command
KW  - crowd-sourcing
KW  - plan fidelity
KW  - representations learning
KW  - robot agent
KW  - Task analysis
KW  - Robots
KW  - Training
KW  - Natural languages
KW  - Visualization
KW  - Planning
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794441
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High-level human instructions often correspond to behaviors with multiple implicit steps. In order for robots to be useful in the real world, they must be able to to reason over both motions and intermediate goals implied by human instructions. In this work, we propose a framework for learning representations that convert from a natural-language command to a sequence of intermediate goals for execution on a robot. A key feature of this framework is prospection, training an agent not just to correctly execute the prescribed command, but to predict a horizon of consequences of an action before taking it. We demonstrate the fidelity of plans generated by our framework when interpreting real, crowd-sourced natural language commands for a robot in simulated scenes.
ER  - 

TY  - CONF
TI  - Flight, Camera, Action! Using Natural Language and Mixed Reality to Control a Drone
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6949
EP  - 6956
AU  - B. Huang
AU  - D. Bayazit
AU  - D. Ullman
AU  - N. Gopalan
AU  - S. Tellex
PY  - 2019
KW  - aerospace computing
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - human-robot interaction
KW  - Markov processes
KW  - mobile robots
KW  - natural language processing
KW  - user interfaces
KW  - natural language commands
KW  - Markov decision process framework
KW  - web interface
KW  - MR interface
KW  - exploratory user study
KW  - fully autonomous language grounding
KW  - autonomous drone
KW  - natural language grounding
KW  - goal-oriented setting
KW  - mixed reality
KW  - radio-controlled controller
KW  - users control
KW  - Drones
KW  - Natural languages
KW  - Virtual reality
KW  - Robots
KW  - Task analysis
KW  - Planning
KW  - Grounding
DO  - 10.1109/ICRA.2019.8794200
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - With increasing autonomy, robots like drones are increasingly accessible to untrained users. Most users control drones using a low-level interface, such as a radio-controlled (RC) controller. For a wider adoption of these technologies by the public, a much higher-level interface, such as natural language or mixed reality (MR), allows the automation of the control of the agent in a goal-oriented setting. We present an interface that uses natural language grounding within an MR environment to solve high-level task and navigational instructions given to an autonomous drone. To the best of our knowledge, this is the first work to perform fully autonomous language grounding in an MR setting for a robot. Given a map, our interface first grounds natural language commands to reward specifications within a Markov Decision Process (MDP) framework. Then, it passes the reward specification to an MDP solver. Finally, the drone performs the desired operations in the real world while planning and localizing itself. Our approach uses MR to provide a set of known virtual landmarks, enabling the drone to understand commands referring to objects without being equipped with object detectors for multiple novel objects or a predefined environment model. We conducted an exploratory user study to assess users' experience of our MR interface with and without natural language, as compared to a web interface. We found that users were able to command the drone more quickly via both MR interfaces as compared to the web interface, with roughly equal system usability scores across all three interfaces.
ER  - 

TY  - CONF
TI  - An Interactive Scene Generation Using Natural Language
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6957
EP  - 6963
AU  - Y. Cheng
AU  - Y. Shi
AU  - Z. Sun
AU  - D. Feng
AU  - L. Dong
PY  - 2019
KW  - dexterous manipulators
KW  - discrete event systems
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - natural scenes
KW  - text analysis
KW  - interactive scene generation
KW  - robotic drawing
KW  - discrete event system
KW  - MSCOCO evaluation dataset
KW  - CIDEr metric
KW  - ROUGH-L metric
KW  - METEOR metric
KW  - Amazon Mechanical Turk
KW  - natural language descriptions
KW  - Layout
KW  - Dogs
KW  - Robots
KW  - Generators
KW  - Natural language processing
KW  - Semantics
KW  - Training
DO  - 10.1109/ICRA.2019.8794327
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Scene generation is an important step of robotic drawing. Recent works have shown success in scene generation conditioned on text using a variety of approaches, with which the generated scenes cannot be revised after its generation. To allow modification on generated scenes, we model the scene generation process as a discrete event system. Instead of training text-to-pixel mappings using large datasets, the proposed approach uses object instances retrieved from the Internet to synthesize scenes. Evaluated on 128 experiments using MSCOCO evaluation dataset, the result shows the scene generation performance has been increased by 197%, 22.3%, and 55.7% compared with the state of the art approach on three standard metrics (CIDEr, ROUGH-L, METEOR), respectively. Human evaluation conducted on Amazon Mechanical Turk shows over 80% of generated scenes are considered to have higher recognizability and better alignment with natural language descriptions than baseline works.
ER  - 

TY  - CONF
TI  - Efficient Generation of Motion Plans from Attribute-Based Natural Language Instructions Using Dynamic Constraint Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6964
EP  - 6971
AU  - J. S. Park
AU  - B. Jia
AU  - M. Bansal
AU  - D. Manocha
PY  - 2019
KW  - graph theory
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - natural language processing
KW  - optimisation
KW  - path planning
KW  - robot programming
KW  - dynamic constraint mapping
KW  - robot motion planning
KW  - dynamic grounding graph
KW  - 7-DOF Fetch robot
KW  - factor graph
KW  - optimization-based motion planning
KW  - parametric constraints
KW  - attribute-based natural language instructions
KW  - motion plans
KW  - Robots
KW  - Grounding
KW  - Natural languages
KW  - Cost function
KW  - Planning
KW  - Dynamics
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794394
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an algorithm for combining natural language processing (NLP) and fast robot motion planning to automatically generate robot movements. Our formulation uses a novel concept called Dynamic Constraint Mapping to transform complex, attribute-based natural language instructions into appropriate cost functions and parametric constraints for optimization-based motion planning. We generate a factor graph from natural language instructions called the Dynamic Grounding Graph (DGG), which takes latent parameters into account. The coefficients of this factor graph are learned based on conditional random fields (CRFs) and are used to dynamically generate the constraints for motion planning. We map the cost function directly to the motion parameters of the planner and compute smooth trajectories in dynamic scenes. We highlight the performance of our approach in a simulated environment and via a human interacting with a 7-DOF Fetch robot using intricate language commands including negation, orientation specification, and distance constraints.
ER  - 

TY  - CONF
TI  - Safe and Fast Path Planning in Cluttered Environment using Contiguous Free-space Partitioning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6972
EP  - 6978
AU  - A. K. Sadhu
AU  - S. Shukla
AU  - T. Bera
AU  - R. Dasgupta
PY  - 2019
KW  - convex programming
KW  - graph theory
KW  - mobile robots
KW  - path planning
KW  - random processes
KW  - cluttered environment
KW  - contiguous free-space partitioning
KW  - convex optimization
KW  - convex navigable free-spaces
KW  - contiguous convex free-spaces
KW  - random-walk based seed generation method
KW  - contiguous navigable geometry
KW  - graph search problem
KW  - multiple query planning algorithm
KW  - fast path planning
KW  - undirected graph
KW  - safe path planning
KW  - Path planning
KW  - Planning
KW  - Ellipsoids
KW  - Robots
KW  - Data structures
KW  - Iris
DO  - 10.1109/ICRA.2019.8793921
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper proposes a path planning algorithm for cluttered environment and maze. The proposed planning algorithm exploits the merit of convex optimization while forming the convex navigable free-spaces, ensuring safety of the vehicle. The contiguous convex free-spaces are iteratively computed from a random-walk based seed generation method to create a contiguous navigable geometry. Inside this contiguous navigable geometry an undirected graph is then created, whose each node and edge belong to at least one convex region which boils down the path planning problem into a graph search problem. In addition, the proposed multiple query planning algorithm can merge the user provided feasible initial and goal configuration with the existing undirected graph in each plan, without deteriorating the planning performance in terms of run-time and path length. Simulation and experimental results confirm the superiority of the proposed planning algorithm jointly in terms of both path length and run-time by a significant margin.
ER  - 

TY  - CONF
TI  - Learning from Extrapolated Corrections
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7034
EP  - 7040
AU  - J. Y. Zhang
AU  - A. D. Dragan
PY  - 2019
KW  - control engineering computing
KW  - extrapolation
KW  - function approximation
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - extrapolated corrections
KW  - cost functions
KW  - user guidance
KW  - extrapolation problem
KW  - online function approximation
KW  - function space
KW  - nonEuclidean norms
KW  - robot learning
KW  - Trajectory
KW  - Cost function
KW  - Robot kinematics
KW  - Function approximation
KW  - Kernel
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793554
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Our goal is to enable robots to learn cost functions from user guidance. Often it is difficult or impossible for users to provide full demonstrations, so corrections have emerged as an easier guidance channel. However, when robots learn cost functions from corrections rather than demonstrations, they have to extrapolate a small amount of information - the change of a waypoint along the way - to the rest of the trajectory. We cast this extrapolation problem as online function approximation, which exposes different ways in which the robot can interpret what trajectory the person intended, depending on the function space used for the approximation. Our simulation results and user study suggest that using function spaces with non-Euclidean norms can better capture what users intend, particularly if environments are uncluttered. This, in turn, can lead to the robot learning a more accurate cost function and improves the user's subjective perceptions of the robot.
ER  - 

TY  - CONF
TI  - Merging Position and orientation Motion Primitives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7041
EP  - 7047
AU  - M. Saveriano
AU  - F. Franzel
AU  - D. Lee
PY  - 2019
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - robot programming
KW  - stability
KW  - orientation motion primitives
KW  - complex robotic trajectories
KW  - time series
KW  - dynamical systems
KW  - merging position
KW  - stability analysis
KW  - merging sequential motion primitives
KW  - pose trajectories
KW  - Quaternions
KW  - Robots
KW  - Stability analysis
KW  - Trajectory
KW  - Task analysis
KW  - Acceleration
KW  - Clocks
DO  - 10.1109/ICRA.2019.8793786
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we focus on generating complex robotic trajectories by merging sequential motion primitives. A robotic trajectory is a time series of positions and orientations ending at a desired target. Hence, we first discuss the generation of converging pose trajectories via dynamical systems, providing a rigorous stability analysis. Then, we present approaches to merge motion primitives which represent both the position and the orientation part of the motion. Developed approaches preserve the shape of each learned movement and allow for continuous transitions among succeeding motion primitives. Presented methodologies are theoretically described and experimentally evaluated, showing that it is possible to generate a smooth pose trajectory out of multiple motion primitives.
ER  - 

TY  - CONF
TI  - Learning Haptic Exploration Schemes for Adaptive Task Execution
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7048
EP  - 7054
AU  - T. Eiband
AU  - M. Saveriano
AU  - D. Lee
PY  - 2019
KW  - end effectors
KW  - haptic interfaces
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - teaching
KW  - haptic exploration schemes
KW  - adaptive task execution
KW  - compliant robots
KW  - kinesthetic teaching
KW  - programming physical interactions
KW  - force data
KW  - force sensing
KW  - autonomous exploration strategies
KW  - object targeted manner
KW  - learning framework
KW  - adaptive robot
KW  - systematically changing environment
KW  - generated behavior
KW  - haptic exploration skills
KW  - relative manipulation skills
KW  - manipulation task
KW  - adaptive task structure
KW  - unseen object locations
KW  - teaching strategy
KW  - Grippers
KW  - Robot sensing systems
KW  - Task analysis
KW  - Force
KW  - Motion segmentation
DO  - 10.1109/ICRA.2019.8793934
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent generation of compliant robots enables kinesthetic teaching of novel skills by human demonstration. This enables strategies to transfer tasks to the robot in a more intuitive way than conventional programming interfaces. Programming physical interactions can be achieved by manually guiding the robot to learn the behavior from the motion and force data. To let the robot react to changes in the environment, force sensing can be used to identify constraints and act accordingly. While autonomous exploration strategies in the whole workspace are time consuming, we propose a way to learn these schemes from human demonstrations in an object targeted manner. The presented teaching strategy and the learning framework allow to generate adaptive robot behaviors relying on the robot's sense of touch in a systematically changing environment. A generated behavior consists of a hierarchical representation of skills, where haptic exploration skills are used to touch the environment with the end effector, and relative manipulation skills, which are parameterized according to previous exploration events. The effectiveness of the approach has been proven in a manipulation task, where the adaptive task structure is able to generalize to unseen object locations. The robot autonomously manipulates objects without relying on visual feedback.
ER  - 

TY  - CONF
TI  - Learning Motion Trajectories from Phase Space Analysis of the Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7055
EP  - 7061
AU  - P. Gesel
AU  - M. Begum
AU  - D. L. Roche
PY  - 2019
KW  - approximation theory
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - linear systems
KW  - motion control
KW  - path planning
KW  - regression analysis
KW  - trajectory control
KW  - closed form solutions
KW  - task generalization
KW  - phase space analysis
KW  - motion trajectories
KW  - kinematic based task
KW  - dynamic motion
KW  - phase space model
KW  - sequential trajectory task
KW  - energy-based analysis
KW  - linear time invariant equations
KW  - trajectory segments
KW  - linear piece-wise regression method
KW  - Trajectory
KW  - Mathematical model
KW  - Dynamics
KW  - Task analysis
KW  - Motion segmentation
KW  - Adaptation models
KW  - Space exploration
DO  - 10.1109/ICRA.2019.8794381
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A major goal of learning from demonstration is task generalization via observation of a teacher. In this paper, we propose a novel framework for learning motion from a single demonstration. Our approach reconstructs the demonstrated trajectory's phase space curve via a linear piece-wise regression method. We approximate dynamics of trajectory segments with linear time invariant equations, each yielding closed form solutions. We show convergence to desired phase space states via an energy-based analysis. The robustness of the model is evaluated on a robot for a sequential trajectory task. Additionally, we show the advantages that the phase space model has over the dynamic motion primitive for a kinematic based task.
ER  - 

TY  - CONF
TI  - I Can See Clearly Now: Image Restoration via De-Raining
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7087
EP  - 7093
AU  - H. Porav
AU  - T. Bruls
AU  - P. Newman
PY  - 2019
KW  - drops
KW  - image denoising
KW  - image restoration
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - rain
KW  - stereo image processing
KW  - traffic engineering computing
KW  - realrain dataset
KW  - image restoration
KW  - image reconstruction
KW  - computer-generated adherent water droplets
KW  - streaks
KW  - CamVid road marking segmentation dataset
KW  - Cityscapes semantic segmentation datasets
KW  - stereo dataset
KW  - denoising generator training
KW  - de-raining
KW  - lens
KW  - Rain
KW  - Image segmentation
KW  - Lenses
KW  - Task analysis
KW  - Computational modeling
KW  - Roads
KW  - Generators
DO  - 10.1109/ICRA.2019.8793486
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a method for improving segmentation tasks on images affected by adherent rain drops and streaks. We introduce a novel stereo dataset recorded using a system that allows one lens to be affected by real water droplets while keeping the other lens clear. We train a denoising generator using this dataset and show that it is effective at removing the effect of real water droplets, in the context of image reconstruction and road marking segmentation. To further test our de-noising approach, we describe a method of adding computer-generated adherent water droplets and streaks to any images, and use this technique as a proxy to demonstrate the effectiveness of our model in the context of general semantic segmentation. We benchmark our results using the CamVid road marking segmentation dataset, Cityscapes semantic segmentation datasets and our own realrain dataset, and show significant improvement on all tasks.
ER  - 

TY  - CONF
TI  - Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7094
EP  - 7100
AU  - A. Milioto
AU  - C. Stachniss
PY  - 2019
KW  - computer vision
KW  - control engineering computing
KW  - convolutional neural nets
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - public domain software
KW  - robot vision
KW  - deployment interface
KW  - existing robotics codebase
KW  - label prediction
KW  - open-source training
KW  - CNNs
KW  - semantic segmentation labels each pixel
KW  - class label
KW  - convolutional neural networks
KW  - high-quality open-source frameworks
KW  - neural network implementation
KW  - semantic segmentation task
KW  - modular approach
KW  - robotic platform
KW  - CNN approach
KW  - robotics research
KW  - open-source codebase
KW  - semantic segmentation CNN
KW  - semantic annotation
KW  - Bonnet framework
KW  - Python
KW  - TensorFlow
KW  - C++ library
KW  - Semantics
KW  - Training
KW  - C++ languages
KW  - Tools
KW  - Robot sensing systems
KW  - Hardware
DO  - 10.1109/ICRA.2019.8793510
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.
ER  - 

TY  - CONF
TI  - Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7101
EP  - 7107
AU  - V. Nekrasov
AU  - T. Dharmasiri
AU  - A. Spek
AU  - T. Drummond
AU  - C. Shen
AU  - I. Reid
PY  - 2019
KW  - computer vision
KW  - image annotation
KW  - image reconstruction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - depth estimation
KW  - asymmetric annotations
KW  - deep learning models
KW  - sensory information extractors
KW  - generic GPU cards
KW  - asymmetric datasets
KW  - real-time semantic segmentation network
KW  - floating point operations
KW  - hard knowledge distillation
KW  - dense 3D semantic reconstruction
KW  - Task analysis
KW  - Semantics
KW  - Estimation
KW  - Real-time systems
KW  - Adaptation models
KW  - Image segmentation
KW  - Robots
DO  - 10.1109/ICRA.2019.8794220
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deployment of deep learning models in robotics as sensory information extractors can be a daunting task to handle, even using generic GPU cards. Here, we address three of its most prominent hurdles, namely, i) the adaptation of a single model to perform multiple tasks at once (in this work, we consider depth estimation and semantic segmentation crucial for acquiring geometric and semantic understanding of the scene), while ii) doing it in real-time, and iii) using asymmetric datasets with uneven numbers of annotations per each modality. To overcome the first two issues, we adapt a recently proposed real-time semantic segmentation network, making changes to further reduce the number of floating point operations. To approach the third issue, we embrace a simple solution based on hard knowledge distillation under the assumption of having access to a powerful `teacher' network. We showcase how our system can be easily extended to handle more tasks, and more datasets, all at once, performing depth estimation and segmentation both indoors and outdoors with a single model. Quantitatively, we achieve results equivalent to (or better than) current state-of-the-art approaches with one forward pass costing just 13ms and 6.5 GFLOPs on 640×480 inputs. This efficiency allows us to directly incorporate the raw predictions of our network into the SemanticFusion framework [1] for dense 3D semantic reconstruction of the scene.
ER  - 

TY  - CONF
TI  - Semantic Mapping for View-Invariant Relocalization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7108
EP  - 7115
AU  - J. Li
AU  - D. Meger
AU  - G. Dudek
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - image representation
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - semantic mapping
KW  - view-invariant relocalization
KW  - accurate local tracking
KW  - view-invariant object-driven relocalization
KW  - sampling-based approach
KW  - 2D bounding box object detections
KW  - view-invariant representation
KW  - camera relocalization
KW  - view-invariance
KW  - relocalization rate
KW  - visual simultaneous localization and mapping
KW  - object landmarks
KW  - local appearance-based features
KW  - SLAM
KW  - 3D pose
KW  - SIFT
KW  - mean rotational error
KW  - Three-dimensional displays
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Two dimensional displays
KW  - Visualization
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793624
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a system for visual simultaneous localization and mapping (SLAM) that combines traditional local appearance-based features with semantically meaningful object landmarks to achieve both accurate local tracking and highly view-invariant object-driven relocalization. Our mapping process uses a sampling-based approach to efficiently infer the 3D pose of object landmarks from 2D bounding box object detections. These 3D landmarks then serve as a view-invariant representation which we leverage to achieve camera relocalization even when the viewing angle changes by more than 125 degrees. This level of view-invariance cannot be attained by local appearance-based features (e.g. SIFT) since the same set of surfaces are not even visible when the viewpoint changes significantly. Our experiments show that even when existing methods fail completely for viewpoint changes of more than 70 degrees, our method continues to achieve a relocalization rate of around 90%, with a mean rotational error of around 8 degrees.
ER  - 

TY  - CONF
TI  - Automatic Targeting of Plant Cells via Cell Segmentation and Robust Scene-Adaptive Tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7116
EP  - 7122
AU  - I. Paranawithana
AU  - Z. H. Chau
AU  - L. Yang
AU  - Z. Chen
AU  - K. Youcef-Toumi
AU  - U. Tan
PY  - 2019
KW  - biology computing
KW  - botany
KW  - cellular biophysics
KW  - image segmentation
KW  - micromanipulators
KW  - needles
KW  - robot vision
KW  - plant cell manipulation
KW  - plant cell centroids
KW  - automatic targeting
KW  - robust scene-adaptive tracking
KW  - cell segmentation method
KW  - plant cell detection
KW  - plant cell localization
KW  - template tracking
KW  - manipulator trajectory
KW  - score-based normalized weighted averaging
KW  - microneedle tracking
KW  - visual tracking
KW  - plant biology
KW  - Visualization
KW  - Target tracking
KW  - Image segmentation
KW  - Motion segmentation
KW  - Trajectory
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793944
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Automatic targeting of plant cells to perform tasks like extraction of chloroplast is often desired in the study of plant biology. Hence, this paper proposes an improved cell segmentation method combined with a robust tracking algorithm for vision-guided micromanipulation in plant cells. The objective of this work is to develop an automatic plant cell detection and localization technique to complete the automated workflow for plant cell manipulation. The complex structural properties of plant cells make both segmentation of cells and visual tracking of the microneedle immensely challenging, unlike single animal cell applications. Thus, an improved version of watershed segmentation with adaptive thresholding is proposed to detect the plant cells without the need for staining of the cells or additional tedious preparations. To manipulate the needle to reach the identified centroid of the cells, tracking of the needle tip is required. Visual and motion information from two data sources namely, template tracking and projected manipulator trajectory are combined using score-based normalized weighted averaging to continuously track the microneedle. The selection of trackers is influenced by their complementary nature as the former and latter are individually robust against physical and visual uncertainties, respectively. Experimental results validate the effectiveness of the proposed method by detecting plant cell centroids accurately, tracking the microneedle constantly and reaching the plant cell of interest despite the presence of visual disturbances.
ER  - 

TY  - CONF
TI  - Real-Time Monocular Object-Model Aware Sparse SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7123
EP  - 7129
AU  - M. Hosseinzadeh
AU  - K. Li
AU  - Y. Latif
AU  - I. Reid
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - mobile robotics
KW  - sparse point-based SLAM methods
KW  - CNN-based plane detector
KW  - semantic SLAM
KW  - simultaneous localization and mapping
KW  - camera localization
KW  - deep-learned object detector
KW  - CNN network
KW  - semantic objects representation
KW  - monocular object-model aware sparse SLAM framework
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Image reconstruction
KW  - Real-time systems
KW  - Cameras
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793728
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simultaneous Localization And Mapping (SLAM) is a fundamental problem in mobile robotics. While sparse point-based SLAM methods provide accurate camera localization, the generated maps lack semantic information. On the other hand, state of the art object detection methods provide rich information about entities present in the scene from a single image. This work incorporates a real-time deep-learned object detector to the monocular SLAM framework for representing generic objects as quadrics that permit detections to be seamlessly integrated while allowing the real-time performance. Finer reconstruction of an object, learned by a CNN network, is also incorporated and provides a shape prior for the quadric leading further refinement. To capture the structure of the scene, additional planar landmarks are detected by a CNN-based plane detector and modelled as independent landmarks in the map. Extensive experiments support our proposed inclusion of semantic objects and planar structures directly in the bundle-adjustment of SLAM - Semantic SLAM- that enriches the reconstructed map semantically, while significantly improving the camera localization.
ER  - 

TY  - CONF
TI  - Probabilistic Projective Association and Semantic Guided Relocalization for Dense Reconstruction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7130
EP  - 7136
AU  - S. Yang
AU  - Z. Kuang
AU  - Y. Cao
AU  - Y. Lai
AU  - S. Hu
PY  - 2019
KW  - convolutional neural nets
KW  - image coding
KW  - image recognition
KW  - image reconstruction
KW  - image representation
KW  - image retrieval
KW  - image segmentation
KW  - object detection
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - convolutional neural networks
KW  - geometric quality
KW  - probabilistic projective association
KW  - loop frames
KW  - 2D labeling
KW  - CNN
KW  - semantic prediction
KW  - simultaneous localization and mapping system
KW  - SLAM system
KW  - 3D scenes
KW  - randomized ferns
KW  - semantic recognition
KW  - geometric reconstruction
KW  - loop detection
KW  - reconstruction pipeline
KW  - semantic information
KW  - camera trajectory estimation
KW  - semantic labels
KW  - real-time dense mapping system
KW  - dense reconstruction
KW  - semantic guided relocalization
KW  - Semantics
KW  - Probabilistic logic
KW  - Labeling
KW  - Two dimensional displays
KW  - Cameras
KW  - Tracking loops
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794299
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a real-time dense mapping system which uses the predicted 2D semantic labels for optimizing the geometric quality of reconstruction. With a combination of Convolutional Neural Networks (CNNs) for 2D labeling and a Simultaneous Localization and Mapping (SLAM) system for camera trajectory estimation, recent approaches have succeeded in incrementally fusing and labeling 3D scenes. However, the geometric quality of the reconstruction can be further improved by incorporating such semantic prediction results, which is not sufficiently exploited by existing methods. In this paper, we propose to use semantic information to improve two crucial modules in the reconstruction pipeline, namely tracking and loop detection, for obtaining mutual benefits in geometric reconstruction and semantic recognition. Specifically for tracking, we use a novel probabilistic projective association approach to efficiently pick out candidate correspondences, where the confidence of these correspondences is quantified concerning similarities on all available short-term invariant features. For the loop detection, we incorporate these semantic labels into the original encoding through Randomized Ferns to generate a more comprehensive representation for retrieving candidate loop frames. Evaluations on a publicly available synthetic dataset have shown the effectiveness of our approach that considers such semantic hints as a reliable feature for achieving higher geometric quality.
ER  - 

TY  - CONF
TI  - MRS-VPR: a multi-resolution sampling based global visual place recognition method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7137
EP  - 7142
AU  - P. Yin
AU  - R. A. Srivatsan
AU  - Y. Chen
AU  - X. Li
AU  - H. Zhang
AU  - L. Xu
AU  - L. Li
AU  - Z. Jia
AU  - J. Ji
AU  - Y. He
PY  - 2019
KW  - image filtering
KW  - image matching
KW  - image recognition
KW  - image resolution
KW  - image sampling
KW  - image sequences
KW  - mobile robots
KW  - navigation
KW  - object recognition
KW  - particle filtering (numerical methods)
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - global visual place recognition method
KW  - multiresolution sampling
KW  - particle filter-based global sampling scheme
KW  - matching efficiency
KW  - brute-force sequential matching method
KW  - long-term localization
KW  - long-term visual navigation tasks
KW  - loop closure detection
KW  - MRS-VPR
KW  - SeqSLAM
KW  - Testing
KW  - Feature extraction
KW  - Indexes
KW  - Task analysis
KW  - Trajectory
KW  - Visualization
KW  - Robots
DO  - 10.1109/ICRA.2019.8793853
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Place recognition and loop closure detection are challenging for long-term visual navigation tasks. SeqSLAM is considered to be one of the most successful approaches to achieve long-term localization under varying environmental conditions and changing viewpoints. SeqSLAM uses a brute-force sequential matching method, which is computationally intensive. In this work, we introduce a multi-resolution sampling-based global visual place recognition method (MRS-VPR), which can significantly improve the matching efficiency and accuracy in sequential matching. The novelty of this method lies in the coarse-to-fine searching pipeline and a particle filter-based global sampling scheme, that can balance the matching efficiency and accuracy in the long-term navigation task. Moreover, our model works much better than SeqSLAM when the testing sequence is over a much smaller time scale than the reference sequence. Our experiments demonstrate that MRSVPR is efficient in locating short temporary trajectories within long-term reference ones without compromising on the accuracy compared to SeqSLAM.
ER  - 

TY  - CONF
TI  - Robust low-overlap 3-D point cloud registration for outlier rejection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7143
EP  - 7149
AU  - J. Stechschulte
AU  - N. Ahmed
AU  - C. Heckman
PY  - 2019
KW  - feature extraction
KW  - image registration
KW  - iterative methods
KW  - Markov processes
KW  - stereo image processing
KW  - hidden Markov random field model
KW  - iterative closest point algorithm
KW  - outlier rejection
KW  - 3D point cloud registration
KW  - Hidden Markov models
KW  - Three-dimensional displays
KW  - Cloud computing
KW  - Probabilistic logic
KW  - Robot sensing systems
KW  - Solid modeling
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793857
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When registering 3-D point clouds it is expected that some points in one cloud do not have corresponding points in the other cloud. These non-correspondences are likely to occur near one another, as surface regions visible from one sensor pose are obscured or out of frame for another. In this work, a hidden Markov random field model is used to capture this prior within the framework of the iterative closest point algorithm. The EM algorithm is used to estimate the distribution parameters and learn the hidden component memberships. Experiments are presented demonstrating that this method outperforms several other outlier rejection methods when the point clouds have low or moderate overlap.
ER  - 

TY  - CONF
TI  - Generalized Controllers in POMDP Decision-Making
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7166
EP  - 7172
AU  - K. H. Wray
AU  - S. Zilberstein
PY  - 2019
KW  - decision making
KW  - Markov processes
KW  - nonlinear programming
KW  - robots
KW  - controller family policy
KW  - finite state controller
KW  - generalized controller policies
KW  - POMDP model
KW  - customized POMDP policy form
KW  - belief-integrated FSC
KW  - vanilla FSC-based policy form
KW  - POMDP robotic solutions
KW  - generalized controllers
KW  - POMDP decision-making
KW  - general policy formulation
KW  - partially observable Markov decision processes
KW  - nonlinear programming
KW  - Power capacitors
KW  - Mathematical model
KW  - Robots
KW  - Approximation algorithms
KW  - Markov processes
KW  - Process control
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794258
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a general policy formulation for partially observable Markov decision processes (POMDPs) called controller family policies that may be used as a framework to facilitate the design of new policy forms. We prove how modern approximate policy forms: point-based, finite state controller (FSC), and belief compression, are instances of this family of generalized controller policies. Our analysis provides a deeper understanding of the POMDP model and suggests novel ways to design POMDP solutions that can combine the benefits of different state-of-the-art methods. We illustrate this capability by creating a new customized POMDP policy form called the belief-integrated FSC (BI-FSC) tailored to overcome the shortcomings of a state-of-the-art algorithm that uses non-linear programming (NLP). Specifically, experiments show that for NLP the BI-FSC offers improved performance over a vanilla FSC-based policy form on benchmark domains. Furthermore, we demonstrate the BI-FSC's execution on a real robot navigating in a maze environment. Results confirm the value of using the controller family policy as a framework to design customized policies in POMDP robotic solutions.
ER  - 

TY  - CONF
TI  - Continuous Value Iteration (CVI) Reinforcement Learning and Imaginary Experience Replay (IER) For Learning Multi-Goal, Continuous Action and State Space Controllers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7173
EP  - 7179
AU  - A. Gerken
AU  - M. Spranger
PY  - 2019
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - state-space methods
KW  - continuous action
KW  - state space controllers
KW  - goal space
KW  - optimal value functions
KW  - nonparametric estimators
KW  - multiple arbitrary goals
KW  - real-world voltage controlled robot
KW  - nonobservable Cartesian task space
KW  - multigoal
KW  - model-free reinforcement learning algorithm
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Task analysis
KW  - Trajectory
KW  - Mathematical model
KW  - Voltage control
DO  - 10.1109/ICRA.2019.8794347
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel model-free Reinforcement Learning algorithm for learning behavior in continuous action, state, and goal spaces. The algorithm approximates optimal value functions using non-parametric estimators. It is able to efficiently learn to reach multiple arbitrary goals in deterministic and nondeterministic environments. To improve generalization in the goal space, we propose a novel sample augmentation technique. Using these methods, robots learn faster and overall better controllers. We benchmark the proposed algorithms using simulation and a real-world voltage controlled robot that learns to maneuver in a non-observable Cartesian task space.
ER  - 

TY  - CONF
TI  - iX-BSP: Belief Space Planning through Incremental Expectation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7180
EP  - 7186
AU  - E. I. Farhi
AU  - V. Indelman
PY  - 2019
KW  - computational complexity
KW  - mobile robots
KW  - path planning
KW  - statistical analysis
KW  - robotics replanning
KW  - statistical simulation
KW  - incremental expectation calculations
KW  - planning session
KW  - computational complexity
KW  - belief space planning
KW  - iX-BSP
KW  - Planning
KW  - Current measurement
KW  - Robots
KW  - Uncertainty
KW  - History
KW  - Time measurement
KW  - Linear programming
DO  - 10.1109/ICRA.2019.8793548
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Belief space planning (BSP) is a fundamental problem in robotics. Determining an optimal action quickly grows intractable as it involves calculating the expected accumulated cost (reward), where the expectation accounts for all future measurement realizations. State of the art approaches therefore resort to simplifying assumptions and approximations to reduce computational complexity. Importantly, while in robotics re-planning is essential, these approaches calculate each planning session from scratch. In this work we contribute a novel approach, iX-BSP, that is based on the key insight that calculations in consecutive planning sessions are similar in nature and can be thus re-used. Our approach performs incremental calculation of the expectation by appropriately re-using computations already performed in a precursory planing session while accounting for the information obtained in inference between the two planning sessions. The formulation of our approach considers general distributions and accounts for data association aspects. We evaluate iX-BSP in statistical simulation and show that incremental expectation calculations significantly reduce runtime without impacting performance.
ER  - 

TY  - CONF
TI  - What am I touching? Learning to classify terrain via haptic sensing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7187
EP  - 7193
AU  - J. Bednarek
AU  - M. Bednarek
AU  - L. Wellhausen
AU  - M. Hutter
AU  - K. Walas
PY  - 2019
KW  - control engineering computing
KW  - haptic interfaces
KW  - image classification
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - pattern clustering
KW  - robot vision
KW  - terrain mapping
KW  - haptic sensing
KW  - mobile robots
KW  - real-world outdoors applications
KW  - robot control
KW  - optimal terrain negotiation
KW  - terrain classification
KW  - terrain identification
KW  - legged robot foot
KW  - fixed-length step
KW  - controlled environment
KW  - clustering method
KW  - robot perception
KW  - machine learning
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Computer architecture
KW  - Convolution
KW  - Force
KW  - Foot
DO  - 10.1109/ICRA.2019.8794478
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mobile robots are becoming very popular in real-world outdoors applications, where there are many challenges in robot control and perception. One of the most critical problems is to characterise the terrain traversed by the robot. This knowledge is indispensable for optimal terrain negotiation. Currently, most approaches are performing terrain classification from vision, but there is not enough research on terrain identification from a direct interaction of the robot with the environment. In our work, we proposed new methods for classification of force/torque data from an interaction of the legged robot foot with the ground, gathered during the walking process. We provided machine learning methods for terrain classification from raw force/torque signals for which we achieved 93% accuracy on a challenging dataset with 160 minutes of recorded fixed-length steps. We also worked on a dataset where the assumption of a fixed-length step is not valid. In this case, the final result is around 80% of accuracy. The most important fact is that the data in both cases was recorded while the robot was walking, no particular movements or controlled environment were needed. Additionally, we also proposed a clustering method which allows us to learn about the class membership based on the recorded data only, without any human supervision.
ER  - 

TY  - CONF
TI  - Multi-Object Search using Object-Oriented POMDPs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7194
EP  - 7200
AU  - A. Wandzel
AU  - Y. Oh
AU  - M. Fishman
AU  - N. Kumar
AU  - L. L. S. Wong
AU  - S. Tellex
PY  - 2019
KW  - Markov processes
KW  - mobile robots
KW  - Monte Carlo methods
KW  - path planning
KW  - object-oriented POMDPs
KW  - OO-POMDP
KW  - observable Markov decision process
KW  - object-oriented partially observable Monte-Carlo planning
KW  - multiobject search task
KW  - sequential decision making
KW  - mobile robot
KW  - Task analysis
KW  - Uncertainty
KW  - Search problems
KW  - Robot sensing systems
KW  - Planning
KW  - Object oriented modeling
DO  - 10.1109/ICRA.2019.8793888
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A core capability of robots is to reason about multiple objects under uncertainty. Partially Observable Markov Decision Processes (POMDPs) provide a means of reasoning under uncertainty for sequential decision making, but are computationally intractable in large domains. In this paper, we propose Object-Oriented POMDPs (OO-POMDPs), which represent the state and observation spaces in terms of classes and objects. The structure afforded by OO-POMDPs support a factorization of the agent's belief into independent object distributions, which enables the size of the belief to scale linearly versus exponentially in the number of objects. We formulate a novel Multi-Object Search (MOS) task as an OO-POMDP for mobile robotics domains in which the agent must find the locations of multiple objects. Our solution exploits the structure of OO-POMDPs by featuring human language to selectively update the belief at task onset. Using this structure, we develop a new algorithm for efficiently solving OO-POMDPs: Object-Oriented Partially Observable Monte-Carlo Planning (OOPOMCP). We show that OO-POMCP with grounded language commands is sufficient for solving challenging MOS tasks both in simulation and on a physical mobile robot.
ER  - 

TY  - CONF
TI  - Depth Generation Network: Estimating Real World Depth from Stereo and Depth Images*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7201
EP  - 7206
AU  - Z. Dong
AU  - Y. Gao
AU  - Q. Ren
AU  - Y. Yan
AU  - F. Chen
PY  - 2019
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - Depth Generation Network
KW  - real world Depth
KW  - dense depth estimation
KW  - deep-learning technique
KW  - stereo RGB images
KW  - stereo pairs
KW  - depth ground-truth
KW  - stereo setting parameters
KW  - image pairs
KW  - supervision learning
KW  - synthetic depth maps
KW  - relative dense depth
KW  - stereo geometric settings
KW  - optic settings
KW  - epipolar geometric cues
KW  - DGN
KW  - falling things dataset
KW  - variational method
KW  - Training
KW  - Estimation
KW  - Three-dimensional displays
KW  - Data models
KW  - Fats
KW  - Cameras
KW  - Robots
DO  - 10.1109/ICRA.2019.8794315
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we propose the Depth Generation Network (DGN) to address the problem of dense depth estimation by exploiting the variational method and the deep-learning technique. In particular, we focus on improving the feasibility of depth estimation under complex scenarios given stereo RGB images, where the stereo pairs and/or depth ground-truth captured by real sensors may be deteriorated; the stereo setting parameters may be unavailable or unreliable, hence hamper efforts to establish the correspondence between image pairs via supervision learning or epipolar geometric cues. Instead of relying on real data, we supervise the training of our model using synthetic depth maps generated by the simulator, which deliver complex scenes and reliable data with ease. Two non-trivial challenges, i.e., (i) attaining reasonable amount yet realistic samples for training, and (ii) developing a model that adapts to both synthetic and real scenes arise, whereas in this work we mainly deal with the later one yet leveraging state-of-the-art Falling Things (FAT) dataset to overcome the first. Experiments on FAT and KITTI datasets demonstrate that our model estimates relative dense depth in fine details, potentially generalizable to real scenes without knowing the stereo geometric and optic settings.
ER  - 

TY  - CONF
TI  - Multi-Task Template Matching for Object Detection, Segmentation and Pose Estimation Using Depth Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7207
EP  - 7213
AU  - K. Park
AU  - T. Patten
AU  - J. Prankl
AU  - M. Vincze
PY  - 2019
KW  - image colour analysis
KW  - image matching
KW  - image sampling
KW  - image segmentation
KW  - object detection
KW  - pose estimation
KW  - MultiTask Template Matching
KW  - object detection
KW  - pose estimation
KW  - color images
KW  - target object
KW  - segmentation masks
KW  - object region
KW  - texture-less objects
KW  - Training
KW  - Pose estimation
KW  - Feature extraction
KW  - Task analysis
KW  - Image segmentation
KW  - Robots
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8794448
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Template matching has been shown to accurately estimate the pose of a new object given a limited number of samples. However, pose estimation of occluded objects is still challenging. Furthermore, many robot application domains encounter texture-less objects for which depth images are more suitable than color images. In this paper, we propose a novel framework, Multi-Task Template Matching (MTTM), that finds the nearest template of a target object from a depth image while predicting segmentation masks and a pose transformation between the template and a detected object in the scene using the same feature map of the object region. The proposed feature comparison network computes segmentation masks and pose predictions by comparing feature maps of templates and cropped features of a scene. The segmentation result from this network improves the robustness of the pose estimation by excluding points that do not belong to the object. Experimental results show that MTTM outperforms baseline methods for segmentation and pose estimation of occluded objects despite using only depth images.
ER  - 

TY  - CONF
TI  - A Clustering Approach to Categorizing 7 Degree-of-Freedom Arm Motions during Activities of Daily Living
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7214
EP  - 7220
AU  - Y. Gloumakov
AU  - A. J. Spiers
AU  - A. M. Dollar
PY  - 2019
KW  - image motion analysis
KW  - motion average
KW  - recorded motions
KW  - on-table motion
KW  - clustering methodology
KW  - K-medoids clustering
KW  - clustering approach
KW  - naturalistic human arm motions
KW  - clustering techniques
KW  - heuristic interpretation
KW  - unsupervised approach
KW  - hierarchical description
KW  - natural human motion
KW  - task achievement
KW  - semiautonomous prosthetic device applications
KW  - motion segments
KW  - DTW barycenter averaging
KW  - Task analysis
KW  - Motion segmentation
KW  - Protocols
KW  - Elbow
KW  - Wrist
KW  - Prosthetics
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794421
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we present a novel method of categorizing naturalistic human arm motions during activities of daily living using clustering techniques. While many current approaches attempt to define all arm motions using heuristic interpretation, or a combination of several abstract motion primitives, our unsupervised approach generates a hierarchical description of natural human motion with well recognized groups. Reliable recommendation of a subset of motions for task achievement is beneficial to various fields, such as robotic and semi-autonomous prosthetic device applications. The proposed method makes use of well-known techniques such as dynamic time warping (DTW) to obtain a divergence measure between motion segments, DTW barycenter averaging (DBA) to get a motion average, and Ward's distance criterion to build the hierarchical tree. The clusters that emerge summarize the variety of recorded motions into the following general tasks: reach-to-front, transfer-box, drinking from vessel, on-table motion, turning a key or door knob, and reach-to-back pocket. The clustering methodology is justified by comparing against an alternative measure of divergence using Bezier coefficients and K-medoids clustering.
ER  - 

TY  - CONF
TI  - Factored Pose Estimation of Articulated Objects using Efficient Nonparametric Belief Propagation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7221
EP  - 7227
AU  - K. Desingh
AU  - S. Lu
AU  - A. Opipari
AU  - O. C. Jenkins
PY  - 2019
KW  - belief networks
KW  - industrial manipulators
KW  - Markov processes
KW  - message passing
KW  - mobile robots
KW  - pose estimation
KW  - random processes
KW  - robot vision
KW  - uncertainty handling
KW  - articulated objects
KW  - articulation constraint
KW  - continuous pose variable
KW  - robot perception
KW  - PMPNBP
KW  - pull message passing algorithm for nonparametric belief propagation
KW  - hidden node model
KW  - pairwise Markov random field
KW  - pairwise MRF
KW  - object-part pose beliefs
KW  - 3D sensor data
KW  - geometrical models
KW  - nonparametric belief propagation algorithm
KW  - multimodal uncertainty
KW  - perception problem
KW  - high-dimensional continuous space
KW  - human environments
KW  - factored pose estimation
KW  - Robot sensing systems
KW  - Belief propagation
KW  - Pose estimation
KW  - Three-dimensional displays
KW  - Quaternions
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8793973
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots working in human environments often encounter a wide range of articulated objects, such as tools, cabinets, and other jointed objects. Such articulated objects can take an infinite number of possible poses, as a point in a potentially high-dimensional continuous space. A robot must perceive this continuous pose in order to manipulate the object to a desired pose. This problem of perception and manipulation of articulated objects remains a challenge due to its high dimensionality and multi-modal uncertainty. In this paper, we propose a factored approach to estimate the poses of articulated objects using an efficient non-parametric belief propagation algorithm. We consider inputs as geometrical models with articulation constraints, and observed 3D sensor data. The proposed framework produces object-part pose beliefs iteratively. The problem is formulated as a pairwise Markov Random Field (MRF) where each hidden node (continuous pose variable) models an observed object-part's pose and each edge denotes an articulation constraint between a pair of parts. We propose articulated pose estimation by a Pull Message Passing algorithm for Nonparametric Belief Propagation (PMPNBP) and evaluate its convergence properties over scenes with articulated objects.
ER  - 

TY  - CONF
TI  - Domain Randomization for Active Pose Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7228
EP  - 7234
AU  - X. Ren
AU  - J. Luo
AU  - E. SolowjoW
AU  - J. A. Ojea
AU  - A. Gupta
AU  - A. Tamar
AU  - P. Abbeel
PY  - 2019
KW  - image sequences
KW  - image texture
KW  - neural nets
KW  - pose estimation
KW  - domain randomization
KW  - active pose estimation
KW  - robotic control
KW  - robotic manipulation tasks
KW  - robot trains
KW  - domain-randomized simulation
KW  - Pose estimation
KW  - Cameras
KW  - Predictive models
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794126
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate state estimation is a fundamental component of robotic control. In robotic manipulation tasks, as is our focus in this work, state estimation is essential for identifying the positions of objects in the scene, forming the basis of the manipulation plan. However, pose estimation typically requires expensive 3D cameras or additional instrumentation such as fiducial markers to perform accurately. Recently, Tobin et al. introduced an approach to pose estimation based on domain randomization, where a neural network is trained to predict pose directly from a 2D image of the scene. The network is trained on computer generated images with a high variation in textures and lighting, thereby generalizing to real world images. In this work, we investigate how to improve the accuracy of domain randomization based pose estimation. Our main idea is that active perception - moving the robot to get a better estimate of pose- can be trained in simulation and transferred to real using domain randomization. In our approach, the robot trains in a domain-randomized simulation how to estimate pose from a sequence of images. We show that our approach can significantly improve the accuracy of standard pose estimation in several scenarios: when the robot holding an object moves, when reference objects are moved in the scene, or when the camera is moved around the object.
ER  - 

TY  - CONF
TI  - GraspFusion: Realizing Complex Motion by Learning and Fusing Grasp Modalities with Instance Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7235
EP  - 7241
AU  - S. Hasegawa
AU  - K. Wada
AU  - S. Kitagawa
AU  - Y. Uchimi
AU  - K. Okada
AU  - M. Inaba
PY  - 2019
KW  - grippers
KW  - image fusion
KW  - image matching
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - deep learning
KW  - multimodal grippers
KW  - simultaneous pinch
KW  - multimodal grasp fusion
KW  - object-class-agnostic grasp
KW  - modality detection
KW  - object-class-agnostic instance segmentation
KW  - grasp template matching
KW  - object manipulation
KW  - object geometry
KW  - grasp modalities
KW  - instance segmentation
KW  - integrated system
KW  - Image segmentation
KW  - Grippers
KW  - Grasping
KW  - Motion segmentation
KW  - Image color analysis
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793710
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent progress of deep learning improved the capability of a robot to find a proper grasp of a novel object for different grasp modalities (e.g., pinch and suction). While these previous studies consider multiple modalities separately, several studies develop multi-modal grippers that can achieve simultaneous pinch and suction grasp (multi-modal grasp fusion) for more capable and stable object manipulation. However, the previous studies with these grippers restrict the situations: simple object geometry and uncluttered environments. To overcome these difficulties, we propose a system that consists of: 1) object-class-agnostic grasp modality detection; 2) object-class-agnostic instance segmentation; and 3) grasp template matching for different modalities. The key idea of our work is the introduction of instance segmentation to fuse multiple modalities regarding each instance eluding a grasp of multiple objects at once. In the experiments, we evaluated the proposed system on the real-world picking task in clutter. The experimental results show that the effectiveness of modality detection, instance segmentation, and the integrated system as a whole.
ER  - 

TY  - CONF
TI  - Factored Contextual Policy Search with Bayesian optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7242
EP  - 7248
AU  - R. Pinsler
AU  - P. Karkus
AU  - A. Kupcsik
AU  - D. Hsu
AU  - W. S. Lee
PY  - 2019
KW  - learning (artificial intelligence)
KW  - robots
KW  - search problems
KW  - truly complex tasks
KW  - locally learned policies
KW  - data-efficient learning
KW  - parametric context space
KW  - contextual policy representation
KW  - target contexts
KW  - task objectives
KW  - target position
KW  - environment contexts
KW  - contextual policy search algorithms
KW  - Bayesian optimization approach
KW  - active learning settings
KW  - faster learning
KW  - factored contextual policy search
KW  - scarce data
KW  - task contexts
KW  - Task analysis
KW  - Trajectory
KW  - Optimization
KW  - Bayes methods
KW  - Robot kinematics
KW  - Entropy
DO  - 10.1109/ICRA.2019.8793808
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Scarce data is a major challenge to scaling robot learning to truly complex tasks, as we need to generalize locally learned policies over different task contexts. Contextual policy search offers data-efficient learning and generalization by explicitly conditioning the policy on a parametric context space. In this paper, we further structure the contextual policy representation. We propose to factor contexts into two components: target contexts that describe the task objectives, e.g. target position for throwing a ball; and environment contexts that characterize the environment, e.g. initial position or mass of the ball. Our key observation is that experience can be directly generalized over target contexts. We show that this can be easily exploited in contextual policy search algorithms. In particular, we apply factorization to a Bayesian optimization approach to contextual policy search both in sampling-based and active learning settings. Our simulation results show faster learning and better generalization in various robotic domains. See our supplementary video: https://youtu.be/IIJTbBAOufDY.
ER  - 

TY  - CONF
TI  - Structured Domain Randomization: Bridging the Reality Gap by Context-Aware Synthetic Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7249
EP  - 7255
AU  - A. Prakash
AU  - S. Boochoon
AU  - M. Brophy
AU  - D. Acuna
AU  - E. Cameracci
AU  - G. State
AU  - O. Shapira
AU  - S. Birchfield
PY  - 2019
KW  - computer vision
KW  - neural nets
KW  - object detection
KW  - probability
KW  - synthetic SDR data
KW  - structured domain randomization
KW  - context-aware synthetic data
KW  - uniform probability distribution
KW  - SDR places objects
KW  - probability distributions
KW  - SDR-generated imagery
KW  - 2D bounding box car detection
KW  - Splines (mathematics)
KW  - Roads
KW  - Object oriented modeling
KW  - Automobiles
KW  - Object detection
KW  - Neural networks
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8794443
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present structured domain randomization (SDR), a variant of domain randomization (DR) that takes into account the structure of the scene in order to add context to the generated data. In contrast to DR, which places objects and distractors randomly according to a uniform probability distribution, SDR places objects and distractors randomly according to probability distributions that arise from the specific problem at hand. In this manner, SDR-generated imagery enables the neural network to take the context around an object into consideration during detection. We demonstrate the power of SDR for the problem of 2D bounding box car detection, achieving competitive results on real data after training only on synthetic data. On the KITTI easy, moderate, and hard tasks, we show that SDR outperforms other approaches to generating synthetic data (VKITTI, Sim 200k, or DR), as well as real data collected in a different domain (BDD100K). Moreover, synthetic SDR data combined with real KITTI data outperforms real KITTI data alone.
ER  - 

TY  - CONF
TI  - Probabilistic Active Filtering for Object Search in Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7256
EP  - 7261
AU  - J. Poon
AU  - Y. Cui
AU  - J. Ooga
AU  - A. Ogawa
AU  - T. Matsubara
PY  - 2019
KW  - Gaussian processes
KW  - graph theory
KW  - grippers
KW  - image filtering
KW  - learning (artificial intelligence)
KW  - probability
KW  - robot vision
KW  - search problems
KW  - complex state-action space
KW  - Gaussian process active filtering strategy
KW  - object search
KW  - state dynamics
KW  - object search problem
KW  - large-scale model
KW  - heavy occlusions
KW  - clutter
KW  - probabilistic active filtering
KW  - Search problems
KW  - Training
KW  - Robots
KW  - Task analysis
KW  - Probabilistic logic
KW  - Clutter
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8794418
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a probabilistic approach for object search in clutter. Due to heavy occlusions, it is vital for an agent to be able to gradually reduce uncertainty in observations of the objects in its workspace by systematically rearranging them. Probabilistic methodologies present a promising sample-efficient alternative to handle the massively complex state-action space that inherently comes with this problem, avoiding the need for both exhaustive training samples and the accompanying heuristics for traversing a large-scale model during runtime. We approach the object search problem by extending a Gaussian Process active filtering strategy with an additional model for capturing state dynamics as the objects are moved over the course of the activity. This allows viable models to be built upon relatively scarce training data, while the complexity of the action space is also reduced by shifting objects over relatively short distances. Validation in both simulation and with a real Baxter robot with a limited number of training samples demonstrates the efficacy of the proposed approach.
ER  - 

TY  - CONF
TI  - Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7262
EP  - 7268
AU  - J. Weibel
AU  - T. Patten
AU  - M. Vincze
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - graph theory
KW  - image classification
KW  - image matching
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - object classification
KW  - vital semantic information
KW  - high-level tasks
KW  - point pair features
KW  - modern deep learning methods
KW  - discriminative features
KW  - graph convolutional networks
KW  - Stanford 3D indoor dataset
KW  - robust 3D object classification
KW  - Three-dimensional displays
KW  - Deep learning
KW  - Feature extraction
KW  - Solid modeling
KW  - Sensors
KW  - Robots
KW  - Convolution
DO  - 10.1109/ICRA.2019.8794432
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Object classification is an important capability for robots as it provides vital semantic information that underpin most practical high-level tasks. Classic handcrafted features, such as point pair features, have demonstrated their robustness for this task. Combining these features with modern deep learning methods provide discriminative features that are rotation invariant and robust to various sources of noise. In this work, we aim to improve the descriptiveness of point pair features while retaining their robustness. We propose a method to achieve more structured sampling of pairs and combine this information through the use of graph convolutional networks. We introduce a novel attention model based on a repeatable local reference frame. Experiments show that our approach significantly improves the state of the art for object classification on large scale reconstruction such as the Stanford 3D indoor dataset and ScanNet and obtains competitive accuracy on the artificial dataset ModelNet.
ER  - 

TY  - CONF
TI  - Discrete Rotation Equivariance for Point Cloud Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7269
EP  - 7275
AU  - J. Li
AU  - Y. Bi
AU  - G. H. Lee
PY  - 2019
KW  - feature extraction
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - discrete rotation equivariance
KW  - point cloud recognition
KW  - point clouds
KW  - deep networks
KW  - deep learning architecture
KW  - rotation group
KW  - rotated inputs
KW  - point cloud based networks
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Task analysis
KW  - Feature extraction
KW  - Robots
KW  - Deep learning
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8793983
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Despite the recent active research on processing point clouds with deep networks, few attention has been on the sensitivity of the networks to rotations. In this paper, we propose a deep learning architecture that achieves discrete SO(2)/SO(3) rotation equivariance for point cloud recognition. Specifically, the rotation of an input point cloud with elements of a rotation group is similar to shuffling the feature vectors generated by our approach. The equivariance is easily reduced to invariance by eliminating the permutation with operations such as maximum or average. Our method can be directly applied to any existing point cloud based networks, resulting in significant improvements in their performance for rotated inputs. We show state-of-the-art results in the classification tasks with various datasets under both SO(2) and SO(3) rotations. In addition, we further analyze the necessary conditions of applying our approach to PointNet [1] based networks.
ER  - 

TY  - CONF
TI  - MVX-Net: Multimodal VoxelNet for 3D Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7276
EP  - 7282
AU  - V. A. Sindagi
AU  - Y. Zhou
AU  - O. Tuzel
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image fusion
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - stereo image processing
KW  - MVX-net
KW  - multimodal VoxelNet
KW  - 3D object detection
KW  - neural network architectures
KW  - point cloud data
KW  - point cloud modalities
KW  - state-of-the-art multimodal algorithms
KW  - 3D detection categories
KW  - simple single stage network
KW  - early-fusion approach
KW  - VoxelNet architecture
KW  - PointFusion
KW  - VoxelFusion
KW  - RGB modalities
KW  - KITTI dataset
KW  - birds eye view
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Feature extraction
KW  - Laser radar
KW  - Object detection
KW  - Proposals
KW  - Fuses
DO  - 10.1109/ICRA.2019.8794195
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many recent works on 3D object detection have focused on designing neural network architectures that can consume point cloud data. While these approaches demonstrate encouraging performance, they are typically based on a single modality and are unable to leverage information from other modalities, such as a camera. Although a few approaches fuse data from different modalities, these methods either use a complicated pipeline to process the modalities sequentially, or perform late-fusion and are unable to learn interaction between different modalities at early stages. In this work, we present PointFusion and VoxelFusion: two simple yet effective early-fusion approaches to combine the RGB and point cloud modalities, by leveraging the recently introduced VoxelNet architecture. Evaluation on the KITTI dataset demonstrates significant improvements in performance over approaches which only use point cloud data. Furthermore, the proposed method provides results competitive with the state-of-the-art multimodal algorithms, achieving top-2 ranking in five of the six birds eye view and 3D detection categories on the KITTI benchmark, by using a simple single stage network.
ER  - 

TY  - CONF
TI  - Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7283
EP  - 7290
AU  - M. Danielczuk
AU  - M. Matl
AU  - S. Gupta
AU  - A. Li
AU  - A. Lee
AU  - J. Mahler
AU  - K. Goldberg
PY  - 2019
KW  - CAD
KW  - convolutional neural nets
KW  - image coding
KW  - image colour analysis
KW  - image enhancement
KW  - image resolution
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - masks
KW  - object tracking
KW  - category-agnostic instance segmentation
KW  - hand-labeled data
KW  - object tracking
KW  - automated dataset generation
KW  - network training
KW  - computer vision research
KW  - RGB imaging
KW  - synthetic depth data sensors
KW  - unknown object segmentation
KW  - SD mask R-CNN
KW  - high-resolution synthetic depth imaging
KW  - synthetic depth mask R-CNN
KW  - unknown 3D object segmentation
KW  - 3D CAD models
KW  - domain randomization
KW  - point cloud clustering baselines
KW  - COCO benchmarks
KW  - hand-labeled RGB datasets
KW  - instance-specific grasping pipeline
KW  - synthetic training dataset
KW  - Image segmentation
KW  - Training
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Robots
KW  - Cameras
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793744
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.
ER  - 

TY  - CONF
TI  - Multi-Modal Geometric Learning for Grasping and Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7339
EP  - 7345
AU  - D. Watkins-Valls
AU  - J. Varley
AU  - P. Allen
PY  - 2019
KW  - computational geometry
KW  - control engineering computing
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - solid modelling
KW  - multimodal geometric learning
KW  - robotic manipulation tasks
KW  - 3D convolutional neural network
KW  - captured depth information
KW  - object geometry
KW  - visual-tactile approaches
KW  - 3D models
KW  - tactile information
KW  - geometric prediction
KW  - geometric reasoning
KW  - Geometry
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Shape
KW  - Training
KW  - Grasping
DO  - 10.1109/ICRA.2019.8794233
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work provides an architecture that incorporates depth and tactile information to create rich and accurate 3D models useful for robotic manipulation tasks. This is accomplished through the use of a 3D convolutional neural network (CNN). Offline, the network is provided with both depth and tactile information and trained to predict the object's geometry, thus filling in regions of occlusion. At runtime, the network is provided a partial view of an object. Tactile information is acquired to augment the captured depth information. The network can then reason about the object's geometry by utilizing both the collected tactile and depth information. We demonstrate that even small amounts of additional tactile information can be incredibly helpful in reasoning about object geometry. This is particularly true when information from depth alone fails to produce an accurate geometric prediction. Our method is benchmarked against and outperforms other visual-tactile approaches to general geometric reasoning. We also provide experimental results comparing grasping success with our method.
ER  - 

TY  - CONF
TI  - Panthera: Design of a Reconfigurable Pavement Sweeping Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7346
EP  - 7352
AU  - A. A. Hayat
AU  - R. Parween
AU  - M. R. Elara
AU  - K. Parsuraman
AU  - P. S. Kandasamy
PY  - 2019
KW  - cleaning
KW  - couplings
KW  - design engineering
KW  - fasteners
KW  - hygiene
KW  - mobile robots
KW  - motion control
KW  - pedestrians
KW  - roads
KW  - robot kinematics
KW  - service robots
KW  - shafts
KW  - steering systems
KW  - wheels
KW  - Panthera
KW  - urban hygiene
KW  - single lead screw shaft
KW  - linkages mechanism
KW  - reconfigurable pavement sweeping robot design
KW  - pavement cleaning robot
KW  - pedestrian
KW  - in-wheels motors
KW  - steering kinematics
KW  - motion control
KW  - onboard batteries
KW  - Robots
KW  - Fasteners
KW  - Wheels
KW  - Lead
KW  - Cleaning
KW  - Couplings
KW  - Meters
DO  - 10.1109/ICRA.2019.8794268
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The pavement cleaning is essential to maintain urban hygiene and keep the long stretch of pavements spick and span. This paper reports on the development of novel reconfigurable pavement cleaning robot named Panthera. Reconfiguration in Panthera is gained by the expansion and contraction of the body frame using a single lead screw shaft and linkages mechanism. It gives the capability to reshape itself based on factors like pavement width and pedestrian density. The independent steering action is derived using two in-wheels motors for each steering axis. This imparts the flexibility in motion and make system omnidirectional and allows the convenient movement of the robot in any direction along the pavement. It is powered using onboard batteries that generate lesser noise compared to the existing solution powered with gasoline. The modeling and steering kinematics is presented along with experimental results of the path followed and discussion supporting the robot's capability.
ER  - 

TY  - CONF
TI  - Automatic Leg Regeneration for Robot Mobility Recovery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7353
EP  - 7359
AU  - L. Wang
AU  - R. S. Fearing
PY  - 2019
KW  - fault tolerance
KW  - legged locomotion
KW  - microprocessor chips
KW  - automatic leg regeneration
KW  - robot mobility recovery
KW  - automatic repair
KW  - robotic system
KW  - modular approach
KW  - robot functionality
KW  - robot structure regeneration
KW  - leg fabrication
KW  - mechanical structures
KW  - regeneration-based approach
KW  - legged robot disengagement
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Maintenance engineering
KW  - Fabrication
KW  - Permanent magnet motors
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793596
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Automatic repair of mechanical structures would enable a robot to recover or improve functions after physical damage. Little work exists on real-world execution of automatic repair in robotic systems. State-of-the-art takes a modular approach where the robotic system is modular and a replacement module is available. However, the modular approach suffers from low granularity in repair even with tens of motors. In addition, there is a lack of quantitative evaluation of the effect of automatic repair on robot functionality. Here we propose a cooperative method for automatic repair in a robotic system. Our method is regeneration-based rather than module-based and does not assume availability of a replacement part. It integrates a fabrication process on the fly for robot structure regeneration. With a system that consists of a regenerating robot, a legged robot and a pre-engineered ribbon, we demonstrate end-to-end execution of automated repair of the legged robot's leg by the regenerating robot in 335 seconds. Experiments on repeatability show a 100% success rate for sub-processes such as positioning, leg fabrication, and legged robot disengagement and a 90% success rate for leg detachment. We quantify the effect of leg regeneration on mobility recovery and found a 90% recovery of forward speed, a 19.7% increase of peak power and a 9.3% reduction of cost of transport with a regenerated leg.
ER  - 

TY  - CONF
TI  - Geometric interpretation of the general POE model for a serial-link robot via conversion into D-H parameterization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7360
EP  - 7366
AU  - L. Wu
AU  - R. Crawford
AU  - J. Roberts
PY  - 2019
KW  - calibration
KW  - industrial robots
KW  - robot kinematics
KW  - serial-link robot
KW  - helical joints
KW  - revolute joints
KW  - general joints
KW  - low pair joints
KW  - calibration
KW  - degree of freedom
KW  - Denavit-Hartenberg model
KW  - prismatic joints
KW  - geometric interpretation
KW  - product of exponentials formula
KW  - kinematic parameters
KW  - Robots
KW  - Mathematical model
KW  - Kinematics
KW  - Tools
KW  - Analytical models
KW  - Calibration
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794384
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While Product of Exponentials (POE) formula has been gaining maturity in modeling the kinematics of a serial-link robot, the Denavit-Hartenberg (D-H) notation is still the most widely used due to its intuitive and concise geometric interpretation of the robot. This paper has developed an analytical solution to automatically convert a POE model into a D-H model for a robot with revolute, prismatic, and helical joints, which are the complete set of three basic one degree of freedom lower pair joints for constructing a serial-link robot. The conversion algorithm developed can be used in applications such as calibration where it is necessary to convert the D-H model to the POE model for identification and then back to the D-H model for compensation. The equivalence of the two models proved in this paper also benefits the analysis of the identifiability of the kinematic parameters. It is found that the maximum number of identifiable parameters in a general POE model is 5h+4r+2t+n+6 where h, r, t, and n stand for the number of helical, revolute, prismatic, and general joints, respectively. It is also suggested that the identifiability of the base frame and the tool frame in the D-H model is restricted rather than the arbitrary six parameters as assumed previously.
ER  - 

TY  - CONF
TI  - Dynamic friction model with thermal and load dependency: modeling, compensation, and external force estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7367
EP  - 7373
AU  - M. Iskandar
AU  - S. Wolf
PY  - 2019
KW  - drives
KW  - gears
KW  - sliding friction
KW  - slip
KW  - dynamic friction model
KW  - external force estimation
KW  - static friction model
KW  - gross sliding regime
KW  - Lund Grenoble
KW  - dynamic simulation
KW  - external torque estimation
KW  - generalized-Maxwell-slip
KW  - harmonic drive CSD 25 gear
KW  - test-bed
KW  - friction compensation
KW  - thermal-load dependency
KW  - nonlinear temperature dependency
KW  - nonlinear velocity dependency
KW  - Friction
KW  - Load modeling
KW  - Torque
KW  - Mathematical model
KW  - Temperature dependence
KW  - Estimation
KW  - Robots
DO  - 10.1109/ICRA.2019.8794406
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A physically-motivated friction model with a parametric description of the nonlinear dependency of the temperature and velocity as well as the dependency on external load is presented. The fully parametric approach extends a static friction model in the gross sliding regime. We show how it can be seamlessly integrated in standard dynamic friction models such as Lund Grenoble (LuGre) and Generalized-Maxwell-Slip (GMS). Parameters of a Harmonic Drive CSD 25 gear are experimentally identified and the final model is evaluated on a dedicated test-bed. We show the integration and effectiveness in dynamic simulation, friction compensation, and external torque estimation.
ER  - 

TY  - CONF
TI  - Echinoderm Inspired Variable Stiffness Soft Actuator with Connected Ossicle Structure
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7389
EP  - 7394
AU  - H. Jeong
AU  - J. Kim
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - design engineering
KW  - dexterous manipulators
KW  - elastic constants
KW  - elastomers
KW  - grippers
KW  - mobile robots
KW  - muscle
KW  - robot dynamics
KW  - robot kinematics
KW  - structural engineering
KW  - connective tissue
KW  - interossicular muscle
KW  - soft material robots
KW  - stiffness modulation method
KW  - structural stiffness
KW  - calcite ossicles
KW  - echinoderm inspired soft actuator
KW  - ossicle structure
KW  - robot kinematics
KW  - robot dynamics
KW  - load-bearing capability
KW  - design engineering
KW  - elastomer
KW  - finger-shaped stiffening structure
KW  - vacuum level
KW  - robotic gripper
KW  - Shape
KW  - Actuators
KW  - Jamming
KW  - Force
KW  - Muscles
KW  - Soft robotics
DO  - 10.1109/ICRA.2019.8793545
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - An echinoderm can actively modulate the structural stiffness of its body wall by as much as 10 times, using the material and structural features that make up its body, including calcite ossicles, connective tissue and interossicular muscle. This capacity for variable stiffness makes it possible to adapt to the kinematics and dynamics required to perform a given task and the surrounding environment. This characteristic can improve the ability of soft material robots, which currently have limited application because of their low load-bearing capability. This paper presents a stiffness modulation method inspired by the connected ossicle structures of echinoderms. We introduce the mechanism, structure, and stiffness variation of the proposed design with respect to different ossicle shape, interval, and elastomer. Then we built a finger-shaped stiffening structure using the proposed design, measured its stiffness according to vacuum level, and showed its load-bearing capacity under control. The proposed design was then applied to a robotic gripper, a typical device that interacts with unpredictable environments and needs variable stiffening ability.
ER  - 

TY  - CONF
TI  - Controllability pre-verification of silicone soft robots based on finite-element method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7395
EP  - 7400
AU  - G. Zheng
AU  - O. Goury
AU  - M. Thieffry
AU  - A. Kruszewski
AU  - C. Duriez
PY  - 2019
KW  - controllability
KW  - finite element analysis
KW  - Galerkin method
KW  - reduced order systems
KW  - robots
KW  - finite-element method
KW  - silicone soft robots
KW  - differential geometric method
KW  - controllable parallel soft robot
KW  - controllability pre-verification
KW  - emergent research field
KW  - variant promising applications
KW  - design soft robots
KW  - pre-checking controllability
KW  - numerical design phase
KW  - trial-and-error process
KW  - Soft robotics
KW  - Finite element analysis
KW  - Actuators
KW  - Numerical models
KW  - Analytical models
KW  - Controllability
DO  - 10.1109/ICRA.2019.8794370
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robot is an emergent research field which has variant promising applications. However, the design of soft robots nowadays still follows the trial-and-error process, which is not at all efficient. This paper proposes to design soft robots by pre-checking controllability during the numerical design phase. Finite-element method is used to model the dynamics of silicone soft robots, based on which the differential geometric method is applied to analyze the controllability of the points of interest. Such a verification is also investigated via model order reduction technique and Galerkin projection. The proposed methodology is finally validated by numerically designing a controllable parallel soft robot.
ER  - 

TY  - CONF
TI  - A Vacuum-driven Origami “Magic-ball” Soft Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7401
EP  - 7408
AU  - S. Li
AU  - J. J. Stampfli
AU  - H. J. Xu
AU  - E. Malkin
AU  - E. V. Diaz
AU  - D. Rus
AU  - R. J. Wood
PY  - 2019
KW  - control system synthesis
KW  - design engineering
KW  - grippers
KW  - mechanical testing
KW  - mobile robots
KW  - pneumatic actuators
KW  - robust control
KW  - vacuum-driven origami magic-ball
KW  - designing soft grippers
KW  - substantial grasping strength
KW  - vacuum-driven soft robotic gripper
KW  - robustness
KW  - flexible thin membrane
KW  - mechanical load tests
KW  - pneumatic pressure
KW  - fabrication method
KW  - Grippers
KW  - Skin
KW  - Skeleton
KW  - Rubber
KW  - Connectors
KW  - Grasping
KW  - Shape
DO  - 10.1109/ICRA.2019.8794068
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robotics has yielded numerous examples of soft grippers that utilize compliance to achieve impressive grasping performances with great simplicity, adaptability, and robustness. Designing soft grippers with substantial grasping strength while remaining compliant and gentle is one of the most important challenges in this field. In this paper, we present a light-weight, vacuum-driven soft robotic gripper made of an origami “magic-ball” and a flexible thin membrane. We also describe the design and fabrication method to rapidly manufacture the gripper with different combinations of low-cost materials for diverse applications. Grasping experiments demonstrate that our gripper can lift a large variety of objects, including delicate foods, heavy bottles, and other miscellaneous items. The grasp force on 3D-printed objects is also characterized through mechanical load tests. The results reveal that our soft gripper can produce significant grasp force on various shapes using negative pneumatic pressure (vacuum). This new gripper holds the potential for many practical applications that require safe, strong, and simple grasping.
ER  - 

TY  - CONF
TI  - Azimuthal Shear Deformation of a Novel Soft Fiber-reinforced Rotary Pneumatic Actuator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7409
EP  - 7414
AU  - Y. M. Lee
AU  - H. J. Lee
AU  - H. P. Moon
AU  - H. R. Choi
AU  - J. C. Koo
PY  - 2019
KW  - bending
KW  - displacement measurement
KW  - elasticity
KW  - electroactive polymer actuators
KW  - finite element analysis
KW  - force measurement
KW  - pneumatic actuators
KW  - shear deformation
KW  - torsion
KW  - fiber pattern lead
KW  - azimuthal deformation
KW  - anisotropically distributed fiber element
KW  - hyper elastic material
KW  - azimuthal shear deformation
KW  - soft materials
KW  - elastic inflatable actuators
KW  - soft fiber-reinforced rotary pneumatic actuator
KW  - structure design
KW  - fabrication process
KW  - FEM simulation
KW  - rotation angles
KW  - Actuators
KW  - Strain
KW  - Windings
KW  - Prototypes
KW  - Limiting
KW  - Fabrication
KW  - Shafts
DO  - 10.1109/ICRA.2019.8794431
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The Elastic Inflatable Actuators (EIAs) has several advantages such as the inherent compliance due to the body comprised of a soft materials such as silicone. Among them, the soft fiber reinforced actuator is based on the principle that the expansion of enclosure and constraint of fiber pattern lead to a desired operation. While lots of researches on the actuator has been attributed to linear and bending motions, however, there are only few researches on rotary, or torsional, motions. In this paper, we propose a new actuator that causes azimuthal deformation due to restriction of anisotropically distributed fiber element along the radial direction and expansion of the hyper elastic material. Structure design of the actuator and a fabrication process of the actuator are presented. Subsequently, FEM simulation and experiment are executed to measure rotation angles of the actuators corresponding to the applied pressure.
ER  - 

TY  - CONF
TI  - INFORA: A Novel Inflatable Origami-based Actuator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7415
EP  - 7420
AU  - A. L. Shoushtari
AU  - G. A. Naselli
AU  - A. Sadeghi
AU  - B. Mazzolai
PY  - 2019
KW  - control system synthesis
KW  - grippers
KW  - pneumatic actuators
KW  - INFORA
KW  - pneumatic actuators
KW  - soft robotics
KW  - inflatable thin membranes
KW  - rigid foldable structure
KW  - high stiffness
KW  - inflatable origami-based actuator
KW  - tendril-like structure
KW  - grasping tasks
KW  - Actuators
KW  - Fabrication
KW  - Grippers
KW  - Task analysis
KW  - Mathematical model
KW  - Grasping
KW  - Laser beam cutting
DO  - 10.1109/ICRA.2019.8794422
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pneumatic actuators have gained huge popularity in the field of soft robotics. A class of this kind of devices exploits inflatable thin membranes which generate a desired displacement upon inflation, but often without providing sufficient force/torque to perform their task. In this paper, we propose a novel actuator combining a membrane and a rigid foldable structure. Experimental tests show that such INFlatable ORigami Actuator (INFORA) is characterized by relatively high stiffness compared to other actuators of the same class. We provide a mathematical model to be used for design purposes and we describe the fabrication process. In addition, we show how the INFORA can be used to build a tendril-like structure capable of performing grasping tasks.
ER  - 

TY  - CONF
TI  - Dynamic Period-two Gait Generation in a Hexapod Robot based on the Fixed-point Motion of a Reduced-order Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7427
EP  - 7433
AU  - W. Lu
AU  - P. Lin
PY  - 2019
KW  - gait analysis
KW  - legged locomotion
KW  - pendulums
KW  - reduced order systems
KW  - robot dynamics
KW  - springs (mechanical)
KW  - dynamic period-two gait generation
KW  - hexapod robot
KW  - fixed-point motion
KW  - reduced-order model
KW  - period-two dynamic running motion
KW  - spring-loaded inverted pendulum model
KW  - stance phases
KW  - flight phases
KW  - period-two fixed points
KW  - motion cycle
KW  - period-two motion trajectories
KW  - landing angles
KW  - R-SLIP model
KW  - Legged locomotion
KW  - Trajectory
KW  - Bifurcation
KW  - Numerical models
KW  - Dynamics
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793738
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This research explored the generation of period-two dynamic running motion in a robot, based on the passive dynamic period-two motion of the reduced order, rolling spring-loaded inverted pendulum (R-SLIP) model. Each cycle of period-two motion consists of two stance phases separated by two flight phases. The distribution of the period-two fixed points of the model was analyzed using a return map. Models with the same or different landing angles per motion cycle were studied, and two sets of period-two motion trajectories were implemented in a robot for experimental evaluation. Without sensory feedback or control, this evaluation relied on the open loop trajectory of the model. Based on the experiments, the robot was capable of performing dynamic period-two motion.
ER  - 

TY  - CONF
TI  - Realizing Learned Quadruped Locomotion Behaviors through Kinematic Motion Primitives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7434
EP  - 7440
AU  - A. Singla
AU  - S. Bhattacharya
AU  - D. Dholakiya
AU  - S. Bhatnagar
AU  - A. Ghosal
AU  - B. Amrutur
AU  - S. Kolathaya
PY  - 2019
KW  - control engineering computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - principal component analysis
KW  - robot kinematics
KW  - robot programming
KW  - quadruped locomotion behavior learning
KW  - single gait learning
KW  - Stoch
KW  - policy gradient
KW  - PCA
KW  - quadrupedal walking
KW  - walking gaits
KW  - robust locomotion behaviors
KW  - D-RL
KW  - deep reinforcement learning
KW  - kMPs
KW  - kinematic motion primitives
KW  - Legged locomotion
KW  - Trajectory
KW  - Computational modeling
KW  - Kinematics
KW  - Optimization
KW  - Training
DO  - 10.1109/ICRA.2019.8794179
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then analyze the resulting walking by using principal component analysis. We observe that the kMPs extracted from PCA followed a similar pattern irrespective of the type of gaits generated. Leveraging on this underlying structure, we then realize walking in Stoch by a straightforward reconstruction of joint trajectories from kMPs. This type of methodology improves the transferability of these gaits to real hardware, lowers the computational overhead on-board, and also avoids multiple training iterations by generating a set of derived behaviors from a single learned gait.
ER  - 

TY  - CONF
TI  - Single-shot Foothold Selection and Constraint Evaluation for Quadruped Locomotion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7441
EP  - 7447
AU  - D. Belter
AU  - J. Bednarek
AU  - H. Lin
AU  - G. Xin
AU  - M. Mistry
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - geometry
KW  - legged locomotion
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - robot kinematics
KW  - single-shot foothold selection
KW  - constraint evaluation
KW  - quadruped locomotion
KW  - optimal footholds
KW  - legged systems
KW  - swing leg
KW  - local elevation map
KW  - kinematic constraints
KW  - convolutional neural network
KW  - geometrical characteristics
KW  - Legged locomotion
KW  - Foot
KW  - Kinematics
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793801
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a method for selecting the optimal footholds for legged systems. The goal of the proposed method is to find the best foothold for the swing leg on a local elevation map. First, we evaluate the geometrical characteristics of each cell on the elevation map, checks kinematic constraints and collisions. Then, we apply the Convolutional Neural Network to learn the relationship between the local elevation map and the quality of potential footholds. During execution time, the controller obtains the qualitative measurement of each potential foothold from the neural model. This method evaluates hundreds of potential footholds and checks multiple constraints in a single step which takes 10 ms on a standard computer without GPU. The experiments were carried out on a quadruped robot walking over rough terrain in both simulation and real robotic platforms.
ER  - 

TY  - CONF
TI  - Optimized Jumping on the MIT Cheetah 3 Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7448
EP  - 7454
AU  - Q. Nguyen
AU  - M. J. Powell
AU  - B. Katz
AU  - J. D. Carlo
AU  - S. Kim
PY  - 2019
KW  - legged locomotion
KW  - optimisation
KW  - position control
KW  - robot dynamics
KW  - MIT Cheetah 3 robot
KW  - optimized jumping behavior
KW  - quadruped robots
KW  - precise high-frequency tracking controller
KW  - robust landing controller
KW  - robot body position
KW  - experimental validation
KW  - robot hardware
KW  - trajectory optimization
KW  - robot body orientation
KW  - Legged locomotion
KW  - Optimization
KW  - Torque
KW  - Robot kinematics
KW  - Hardware
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794449
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel methodology for implementing optimized jumping behavior on quadruped robots. Our method includes efficient trajectory optimization, precise high-frequency tracking controller and robust landing controller for stabilizing the robot body position and orientation after impact. Experimental validation was successfully conducted on the MIT Cheetah 3, enabling the robot to repeatably jump onto and jump down from a desk with the height of 30" (0.76 m). The result demonstrates the advantages of the approach as well as the capability of the robot hardware itself.
ER  - 

TY  - CONF
TI  - Lift Your Leg: Mechanics of Running Through Fluids
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7455
EP  - 7461
AU  - R. Alicea
AU  - K. Ladyko
AU  - J. Clark
PY  - 2019
KW  - energy consumption
KW  - gait analysis
KW  - legged locomotion
KW  - robot dynamics
KW  - fluid interaction mechanics
KW  - energy consumption
KW  - center of mass
KW  - gait stability
KW  - mud
KW  - SLIP runner
KW  - viscous medium
KW  - snow
KW  - stream banks
KW  - beach-head
KW  - dense fluids
KW  - shallow fluids
KW  - outdoor environments
KW  - unstructured environments
KW  - legged robotic platforms
KW  - Legged locomotion
KW  - Hip
KW  - Foot
KW  - Drag
KW  - Mathematical model
KW  - Actuators
DO  - 10.1109/ICRA.2019.8793992
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order for legged robotic platforms to become adept enough to operate in unstructured, outdoor environments it is critical that they have the ability to adapt to a variety of terrains. One class of terrains to consider are regions of shallow, dense fluids, such as a beach-head, stream banks, snow or mud. This work examines the behavior of a simulated SLIP runner operating in such a viscous medium. Simulation results show that intelligently retracting the leg during flight can have a profound effect on the maximum achievable velocity of the runner, the stability of the resulting gait, and the cost of transport of the runner. Results also show that trudging gaits, in which the leg is positioned behind the center of mass, can be favorable in certain situations in terms of energy consumption and forward velocity.
ER  - 

TY  - CONF
TI  - Safely Probabilistically Complete Real-Time Planning and Exploration in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7470
EP  - 7476
AU  - D. Fridovich-Keil
AU  - J. F. Fisac
AU  - C. J. Tomlin
PY  - 2019
KW  - approximation theory
KW  - collision avoidance
KW  - mobile robots
KW  - predictive control
KW  - probability
KW  - reachability analysis
KW  - robot dynamics
KW  - robust control
KW  - safe backward reachable set
KW  - real-time simulation
KW  - safely probabilistically complete real-time planning
KW  - motion planning
KW  - kinodynamic planners
KW  - a priori unknown
KW  - static environments
KW  - collision avoidance
KW  - robust controller
KW  - reachability analysis
KW  - motion plans
KW  - robot operating system software environment
KW  - Planning
KW  - Trajectory
KW  - Safety
KW  - Computational modeling
KW  - Real-time systems
KW  - Vehicle dynamics
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2019.8793905
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a new framework for motion planning that wraps around existing kinodynamic planners and guarantees recursive feasibility when operating in a priori unknown, static environments. Our approach makes strong guarantees about overall safety and collision avoidance by utilizing a robust controller derived from reachability analysis. We ensure that motion plans never exit the safe backward reachable set of the initial state, while safely exploring the space. This preserves the safety of the initial state, and guarantees that that we will eventually find the goal if it is possible to do so while exploring safely. We implement our framework in the Robot Operating System (ROS) software environment and demonstrate it in a real-time simulation.
ER  - 

TY  - CONF
TI  - Handling robot constraints within a Set-Based Multi-Task Priority Inverse Kinematics Framework
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7477
EP  - 7483
AU  - P. D. Lillo
AU  - S. Chiaverini
AU  - G. Antonelli
PY  - 2019
KW  - manipulator kinematics
KW  - optimisation
KW  - redundant manipulators
KW  - safety related tasks
KW  - set-based task
KW  - equality tasks
KW  - set-bases tasks
KW  - optimization tasks
KW  - set-based multitask priority framework
KW  - set-based multitask priority inverse kinematics framework
KW  - robot constraint handling
KW  - redundant structures
KW  - 7DOF Jaco2 arm
KW  - Task analysis
KW  - Optimization
KW  - Safety
KW  - Kinematics
KW  - Robots
KW  - Jacobian matrices
KW  - Redundancy
DO  - 10.1109/ICRA.2019.8793625
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Set-Based Multi-Task Priority is a recent framework to handle inverse kinematics for redundant structures. Both equality tasks, i.e., control objectives to be driven to a desired value, and set-bases tasks, i.e., control objectives to be satisfied with a set/range of values can be addressed in a rigorous manner within a priority framework. In addition, optimization tasks, driven by the gradient of a proper function, may be considered as well, usually as lower priority tasks. In this paper the proper design of the tasks, their priority and the use of a Set-Based Multi-Task Priority framework is proposed in order to handle several constraints simultaneously in real-time. It is shown that safety related tasks such as, e.g., joint limits or kinematic singularity, may be properly handled by consider them both at an higher priority as set-based task and at a lower within a proper optimization functional. Experimental results on a 7DOF Jaco2 arm with and without the proposed approach show the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - Compliant Limb Sensing and Control for Safe Human-Robot Interactions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7484
EP  - 7490
AU  - C. Miyata
AU  - M. Ahmadi
PY  - 2019
KW  - force control
KW  - friction
KW  - human-robot interaction
KW  - robot dynamics
KW  - robot kinematics
KW  - stability
KW  - transient response
KW  - controller parameters
KW  - maximum safe operating velocity
KW  - linear model
KW  - 1 DoF robotic joint
KW  - traditional admittance control law
KW  - simple control structure
KW  - compliant limb sensing
KW  - safe human-robot interactions
KW  - control methodology
KW  - human-robot interaction
KW  - compliant sensor
KW  - robot links
KW  - existing robots
KW  - mechanical redesign
KW  - linear robot model
KW  - stability analysis
KW  - admittance control law
KW  - comparable transient response
KW  - control structure
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Impedance
KW  - Safety
KW  - Force
KW  - Analytical models
DO  - 10.1109/ICRA.2019.8793965
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The current paper proposes a control methodology for ensuring safety during human-robot interaction based on a compliant sensor covering the robot links as a lightweight shell. The method can be used with existing robots without the need for mechanical redesign. To assess the behaviour of the proposed control law, the controller is analysed using a linear robot model. Stability analysis is performed and requirements on the controller parameters are derived. The effect of the controller parameters on the perceived impedance and the maximum safe operating velocity of the robot are determined via the linear model. The adverse impact of dry friction is analysed in simulation and methods are developed to mitigate the effects. The controller is implemented on a 1 DoF robotic joint and the results are compared to those of a traditional admittance control law, demonstrating comparable transient response while maintaining a simple control structure and decreased risk of instability.
ER  - 

TY  - CONF
TI  - Ascento: A Two-Wheeled Jumping Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7515
EP  - 7521
AU  - V. Klemm
AU  - A. Morra
AU  - C. Salzmann
AU  - F. Tschopp
AU  - K. Bodie
AU  - L. Gulich
AU  - N. Küng
AU  - D. Mannhart
AU  - C. Pfister
AU  - M. Vierneisel
AU  - F. Weber
AU  - R. Deuber
AU  - R. Siegwart
PY  - 2019
KW  - inspection
KW  - legged locomotion
KW  - robot dynamics
KW  - wheels
KW  - Ascento
KW  - jumping robot
KW  - mobile ground robots
KW  - complex indoor environments
KW  - mobile robotics
KW  - indoor inspection tasks
KW  - compact wheeled bipedal robot
KW  - flat terrain
KW  - mechanical design
KW  - Wheels
KW  - Legged locomotion
KW  - Hip
KW  - Robot kinematics
KW  - Batteries
DO  - 10.1109/ICRA.2019.8793792
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Applications of mobile ground robots demand high speed and agility while navigating in complex indoor environments. These present an ongoing challenge in mobile robotics. A system with these specifications would be of great use for a wide range of indoor inspection tasks. This paper introduces Ascento, a compact wheeled bipedal robot that is able to move quickly on flat terrain, and to overcome obstacles by jumping. The mechanical design and overall architecture of the system is presented, as well as the development of various controllers for different scenarios. A series of experiments1 with the final prototype system validate these behaviors in realistic scenarios.
ER  - 

TY  - CONF
TI  - Path Following Controller for Differentially Driven Planar Robots with Limited Torques and Uncertain and Changing Dynamics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7522
EP  - 7528
AU  - V. Pitkänen
AU  - V. Halonen
AU  - A. Kemppainen
AU  - J. Röning
PY  - 2019
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - robot dynamics
KW  - torque control
KW  - wheel torque commands
KW  - motor torque limits
KW  - internal control elements
KW  - differentially driven planar robots
KW  - asymmetrical planar robots
KW  - limited motor torques
KW  - environmental forces
KW  - unscented Kalman filter
KW  - robot inertia
KW  - Acceleration
KW  - Mobile robots
KW  - Force
KW  - Wheels
KW  - Torque
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794198
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a path following controller that is suitable for asymmetrical planar robots with significant mass and limited motor torques. the controller is resistant against environmental forces, and inaccurate estimates of robot's inertia, by estimating their effects with unscented kalman filter. the controller outputs wheel torque commands which take in account the motor torque limits and given relative priority of internal control elements. the method presented is thoroughly explained and the simulation results demonstrate the performance of the controller.
ER  - 

TY  - CONF
TI  - Nonlinear Tire Cornering Stiffness Observer for a Double Steering Off-Road Mobile Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7529
EP  - 7534
AU  - M. Fnadi
AU  - F. Plumet
AU  - F. Benamar
PY  - 2019
KW  - linear quadratic control
KW  - mobile robots
KW  - nonlinear control systems
KW  - observers
KW  - off-road vehicles
KW  - path planning
KW  - predictive control
KW  - steering systems
KW  - tyres
KW  - vehicle dynamics
KW  - open environments
KW  - rear contact cornering stiffnesses
KW  - soil proprieties
KW  - steering angles
KW  - LQR controller
KW  - nonlinear tire cornering stiffness observer
KW  - double steering off-road mobile robot
KW  - path tracking controllers
KW  - autonomous vehicle
KW  - dynamic model
KW  - wheel-ground contact
KW  - Kalman-Bucy observer
KW  - ground parameter estimation
KW  - Observers
KW  - Tires
KW  - Mobile robots
KW  - Vehicle dynamics
KW  - Wheels
KW  - Nonlinear optics
DO  - 10.1109/ICRA.2019.8794047
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Path tracking controllers for an autonomous vehicle are often designed by using either a dynamic model or a kinematic one and some models are related to wheel-ground contact, that makes the efficiency of the controller highly dependent on the ground parameters estimation, especially for off-road mobile robots intended to navigate in open environments. This paper proposes a new nonlinear observer designed to estimate the front and rear contact cornering stiffnesses in real time, that are related both on tire and soil proprieties. The latter is estimated using steering angles as well as yaw rate and lateral velocity, which are provided by a preliminary Kalman-Bucy observer. The performance of the proposed nonlinear observer combined with the LQR controller is evaluated by both advanced simulations and experiments in real conditions at different speeds.
ER  - 

TY  - CONF
TI  - Hierarchical optimization for Whole-Body Control of Wheeled Inverted Pendulum Humanoids
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7535
EP  - 7542
AU  - M. Zafar
AU  - S. Hutchinson
AU  - E. A. Theodorou
PY  - 2019
KW  - control system synthesis
KW  - end effectors
KW  - humanoid robots
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - optimisation
KW  - pendulums
KW  - redundant manipulators
KW  - high-level controller plans
KW  - hierarchical optimization
KW  - whole-body control framework
KW  - redundant manipulators
KW  - wheels
KW  - optimal participation
KW  - low level controller
KW  - control zero dynamics
KW  - low-level controller plans
KW  - body joint manipulation
KW  - WIP humanoids
KW  - wheeled inverted pendulum humanoids
KW  - Wheels
KW  - Manipulator dynamics
KW  - Humanoid robots
KW  - Task analysis
KW  - Mobile robots
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794360
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a whole-body control framework for Wheeled Inverted Pendulum (WIP) Humanoids. WIP Humanoids are redundant manipulators dynamically balancing themselves on wheels. Characterized by several degrees of freedom, they have the ability to perform several tasks simultaneously, such as balancing, maintaining a body pose, controlling the gaze, lifting a load or maintaining end-effector configuration in operation space. The problem of whole-body control is to enable simultaneous performance of these tasks with optimal participation of all degrees of freedom at specified priorities for each objective. The control also has to obey constraint of angle and torque limits on each joint. The proposed approach is hierarchical with a low level controller for body joints manipulation and a high-level controller that defines center of mass (CoM) targets for the low-level controller to control zero dynamics of the system driving the wheels. The low-level controller plans for shorter horizons while considering more complete dynamics of the system, while the high-level controller plans for longer horizon based on an approximate model of the robot for computational efficiency.
ER  - 

TY  - CONF
TI  - An Actively Controlled Variable Stiffness Structure via Layer Jamming and Pneumatic Actuation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7555
EP  - 7561
AU  - C. Mikol
AU  - H. Su
PY  - 2019
KW  - finite element analysis
KW  - friction
KW  - human-robot interaction
KW  - microactuators
KW  - pneumatic actuators
KW  - actively controlled variable stiffness structure
KW  - collaborative robots
KW  - robotic structures
KW  - actuation system
KW  - actively controlled stiffness structure
KW  - structure shape
KW  - shape morphing
KW  - morphed curvature
KW  - input actuator pressure
KW  - stiffness variation range
KW  - robotics field
KW  - lightweight morphing structures
KW  - pneumatic artificial muscles
KW  - human-robot interaction
KW  - bidirectional morphing
KW  - Pneumatic systems
KW  - Actuators
KW  - Jamming
KW  - Shape
KW  - Service robots
KW  - Muscles
DO  - 10.1109/ICRA.2019.8794340
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Current robotics industry trends show an increased interest in the interaction between humans and robots in a variety of fields, ranging from collaborative robots in manufacturing to assisted medical devices in the medical field. One limiting factor in present applications is the ability to actively morph these robotic structures and control their stiffness using the same type of actuation system. This paper focuses on developing an actively controlled, variable stiffness structure that uses a pneumatic system for both morphing and locking the structure shape. The structure design integrates Pneumatic Artificial Muscles (PAMs) that are pressurized to control shape morphing. The pressurization of the PAM provides a radial force that allows bi-directional morphing based on the pressurization scheme. Layer Jamming, which utilizes varied friction between thin sheets based on pressure, is used to control the variable stiffness of the structure. In this paper, a control model is developed to predict the morphed curvature of the structure based on the input actuator pressure. This experimental control model is also validated using a theoretical pseudo-rigid-body model. The repeatability and accuracy of morphing is also discussed. Through experimental testing, a measure of the stiffness variation range of the structure is also developed. This novel research would positively impact the robotics field by creating lightweight morphing structures that are flexible and easily deformed, but also stiff with high load-carrying capability for increased human-robot interaction.
ER  - 

TY  - CONF
TI  - A Floating-Piston Hydrostatic Linear Actuator and Remote-Direct-Drive 2-DOF Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7562
EP  - 7568
AU  - E. Schwarm
AU  - K. M. Gravesmill
AU  - J. P. Whitney
PY  - 2019
KW  - brushless DC motors
KW  - design engineering
KW  - dexterous manipulators
KW  - diaphragms
KW  - elastomers
KW  - gears
KW  - grippers
KW  - hydraulic actuators
KW  - hydrostatics
KW  - medical robotics
KW  - motion control
KW  - pistons
KW  - prosthetics
KW  - seals (stoppers)
KW  - stiction
KW  - remote-direct-drive 2-DOF gripper
KW  - serial-chain motor-driven robotic arms
KW  - passive compliance
KW  - remote direct-drive manipulator
KW  - low-friction hydrostatic transmission
KW  - soft fiber-elastomer rolling-diaphragm seals
KW  - static friction
KW  - seal rubbing
KW  - gear ratios
KW  - dexterous robotic arm
KW  - floating-piston hydrostatic linear actuator design
KW  - backdrivable brushless electric motors
KW  - system hysteresis
KW  - powered prosthetic hand design
KW  - size 20.0 mm
KW  - Actuators
KW  - Pistons
KW  - Force
KW  - Manipulators
KW  - Hydraulic systems
KW  - Seals
DO  - 10.1109/ICRA.2019.8794378
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dexterous, serial-chain motor-driven robotic arms have high moving mass, since most of the actuators must be located in the arm itself. This necessitates high gear ratios, sacrificing passive compliance, backdrivability, and the capacity for delicate motion. We introduce the concept of a remote direct-drive (RDD) manipulator, in which every motor is located in the base, connected to remote joints via a low-friction hydrostatic transmission. We have designed a new hydrostatic linear actuator with a fully-floating piston; the piston floats within the cylinder using a pair of soft fiber-elastomer rolling-diaphragm seals. This eliminates static friction from seal rubbing and piston/rod misalignment. Actuators were developed with a 20mm bore, weighing 55 grams each with a 400:1 bidirectional strength-to-weight ratio $( + /-230\mathrm {N}$), which drive a 2-DOF manipulator (wrist pitch/finger pinch; 120-degree range-of-motion; 6.6 Nm max grip strength). The gripper is hydrostatically coupled to remotely-located direct-drive/backdrivable brushless electric motors. System hysteresis and friction are 1 percent of full-range force. This low-mass low-friction configuration is of great interest for powered prosthetic hand design, and passively-safe high dynamic range robot arms.
ER  - 

TY  - CONF
TI  - 3D Printed Ferrofluid Based Soft Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7569
EP  - 7574
AU  - E. S. Keneth
AU  - A. R. Epstein
AU  - M. S. Harari
AU  - R. S. Pierre
AU  - S. Magdassi
AU  - S. Bergbreiter
PY  - 2019
KW  - magnetic actuators
KW  - magnetic fluids
KW  - magnetic particles
KW  - three-dimensional printing
KW  - magnetic particles
KW  - polymeric matrix
KW  - actuator response
KW  - 3D printed material
KW  - 3D printed tubes
KW  - 3D printed more complex actuators
KW  - complex motion
KW  - ferrofluid based soft actuators
KW  - 3D printed soft actuators
KW  - complex shapes
KW  - remote actuation
KW  - external magnetic field
KW  - ferrofluid-based actuator
KW  - Electron tubes
KW  - Magnetic moments
KW  - Ferrofluid
KW  - Actuators
KW  - Magnetic separation
KW  - Magnetic resonance imaging
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793998
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work demonstrates 3D printed soft actuators with complex shapes and remote actuation using an external magnetic field. Instead of embedding magnetic particles in a polymeric matrix, we fabricated a novel ferrofluid-based actuator, in which the fluid can be moved to different locations in the actuator to affect actuator response. We studied the effect of both the ferrofluid and the 3D printed material on the motion of simple actuators using 3D printed tubes. In addition, we 3D printed more complex actuators mimicking a human hand and a worm to demonstrate more complex motion.
ER  - 

TY  - CONF
TI  - Learning Primitive Skills for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7597
EP  - 7603
AU  - Y. Zhu
AU  - D. Schwab
AU  - M. Veloso
PY  - 2019
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - multi-robot systems
KW  - robot vision
KW  - robot soccer small-size domain
KW  - tactical level team strategies
KW  - high-level team strategies
KW  - individual robot ball-based skills
KW  - robot primitive skills
KW  - continuous action space
KW  - hardware fidelity
KW  - learned skills
KW  - mobile robots
KW  - hand-coding algorithms
KW  - training parameters
KW  - mobile robot system
KW  - deep reinforcement learning algorithm
KW  - primitive skills
KW  - task performance
KW  - learning algorithms
KW  - Robot kinematics
KW  - Sports
KW  - Task analysis
KW  - Training
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793688
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Achieving effective task performance on real mobile robots is a great challenge when hand-coding algorithms, both due to the amount of effort involved and manually tuned parameters required for each skill. Learning algorithms instead have the potential to lighten up this challenge by using one single set of training parameters for learning different skills, but the question of the feasibility of such learning in real robots remains a research pursuit. We focus on a kind of mobile robot system - the robot soccer “small-size” domain, in which tactical and high-level team strategies build upon individual robot ball-based skills. In this paper, we present our work using a Deep Reinforcement Learning algorithm to learn three real robot primitive skills in continuous action space: go-to-ball, turn-and-shoot and shoot-goalie, for which there is a clear success metric to reach a destination or score a goal. We introduce the state and action representation, as well as the reward and network architecture. We describe our training and testing using a simulator of high physical and hardware fidelity. Then we test the policies trained from simulation on real robots. Our results show that the learned skills achieve an overall better success rate at the expense of taking 0.29 seconds slower on average for all three skills. In the end, we show that our policies trained in simulation have good performance on real robots by directly transferring the policy.
ER  - 

TY  - CONF
TI  - Coverage Path Planning in Belief Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7604
EP  - 7610
AU  - R. Schirmer
AU  - P. Biber
AU  - C. Stachniss
PY  - 2019
KW  - C++ language
KW  - collision avoidance
KW  - control engineering computing
KW  - lawnmowers
KW  - mobile robots
KW  - navigation
KW  - operating systems (computers)
KW  - robot programming
KW  - coverage path planning
KW  - belief space
KW  - robotic lawn mowers
KW  - safety-critical tasks
KW  - robot safety
KW  - cheap range sensors
KW  - low range sensors
KW  - uncertainty-aware coverage path
KW  - lawn mower
KW  - safe navigation
KW  - collision avoidance
KW  - C++ language
KW  - ROS
KW  - Robot sensing systems
KW  - Planning
KW  - Path planning
KW  - Uncertainty
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793969
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For safety reasons, robotic lawn mowers and similar devices are required to stay within a predefined working area. Keeping the robot within its workspace is typically achieved by special safeguards such as a wire installed in the ground. In the case of robotic lawn mowers, this causes a certain customer reluctance. It is more desirable to fulfill those safety-critical tasks by safe navigation and path planning. In this paper, we tackle the problem of planning a coverage path composed of parallel lanes that maximizes robot safety under the constraints of cheap, low range sensors and thus substantial uncertainty in the robot's belief and ability to execute actions. Our approach uses a map of the environment to estimate localizability at all locations, and it uses these estimates to search for an uncertainty-aware coverage path while avoiding collisions. We implemented our approach using C++ and ROS and thoroughly tested it on real garden data. The experiment shows that our approach leads to safer meander patterns for the lawn mower and takes expected localizability information into account.
ER  - 

TY  - CONF
TI  - Continuous Control for High-Dimensional State Spaces: An Interactive Learning Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7611
EP  - 7617
AU  - R. Pérez-Dattari
AU  - C. Celemin
AU  - J. Ruiz-del-Solar
AU  - J. Kober
PY  - 2019
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - interactive learning approach
KW  - deep reinforcement learning
KW  - corrective advice communicated by humans
KW  - DRL agent
KW  - human training effort
KW  - D-COACH framework
KW  - human corrective feedback
KW  - human knowledge
KW  - machine learning methods
KW  - reward function
KW  - simulated environments
KW  - robotics applications
KW  - complex decision-making problems
KW  - high-dimensional state spaces
KW  - continuous control
KW  - Training
KW  - Robots
KW  - Shape
KW  - Task analysis
KW  - Adaptation models
KW  - Decoding
KW  - Machine learning
DO  - 10.1109/ICRA.2019.8793675
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep Reinforcement Learning (DRL) has become a powerful methodology to solve complex decision-making problems. However, DRL has several limitations when used in real-world problems (e.g., robotics applications). For instance, long training times are required and cannot be accelerated in contrast to simulated environments, and reward functions may be hard to specify/model and/or to compute. Moreover, the transfer of policies learned in a simulator to the real-world has limitations (reality gap). On the other hand, machine learning methods that rely on the transfer of human knowledge to an agent have shown to be time efficient for obtaining well performing policies and do not require a reward function. In this context, we analyze the use of human corrective feedback during task execution to learn policies with high-dimensional state spaces, by using the D-COACH framework, and we propose new variants of this framework. D-COACH is a Deep Learning based extension of COACH (COrrective Advice Communicated by Humans), where humans are able to shape policies through corrective advice. The enhanced version of DCOACH, which is proposed in this paper, largely reduces the time and effort of a human for training a policy. Experimental results validate the efficiency of the D-COACH framework in three different problems (simulated and with real robots), and show that its enhanced version reduces the human training effort considerably, and makes it feasible to learn policies within periods of time in which a DRL agent do not reach any improvement.
ER  - 

TY  - CONF
TI  - A Predictive Reward Function for Human-Like Driving Based on a Transition Model of Surrounding Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7618
EP  - 7624
AU  - D. Hayashi
AU  - Y. Xu
AU  - T. Bando
AU  - K. Takeda
PY  - 2019
KW  - decision making
KW  - image processing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - road traffic
KW  - road vehicles
KW  - robot vision
KW  - traffic engineering computing
KW  - autonomous driving vehicles
KW  - deep predictive network
KW  - predictive reward function
KW  - human-like driving
KW  - decision making
KW  - vehicle control
KW  - traffic flow
KW  - occupancy grid image
KW  - prediction network training
KW  - real driving data
KW  - reinforcement learning agent training
KW  - deep neural networks
KW  - Autonomous vehicles
KW  - Roads
KW  - Predictive models
KW  - Reinforcement learning
KW  - Decision making
KW  - Object detection
KW  - Autonomous driving
KW  - Prediction
KW  - Reward
KW  - Deep Learning
KW  - Reinforcement Learning
KW  - naturalistic Driving Data
DO  - 10.1109/ICRA.2019.8794010
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Driving is a complex task that requires the perception of the surrounding environment, decision making and control of the vehicle. Human drivers predict how surrounding objects move and decide an appropriate driving behavior. As with human drivers, autonomous driving vehicles should consider the condition of the surrounding environment and behave naturally so as not to disturb the traffic flow. We propose a reward function for learning how natural the driving is based on the hypothesis that the movement of surrounding vehicles becomes unpredictable when the ego vehicle takes an unnatural driving behavior. The reward function is based on the prediction error of a deep predictive network that models the transition of the surrounding environment. Occupancy grid image is used to perceive the surrounding environment and the predictions up to two seconds are used to calculate the reward function. We evaluated the reward function using both simulated and the real world data. We trained the prediction network using real driving data and trained a reinforcement learning agent based on the reward function. Then we compared the speed planned by the agent and a human driver, which showed a correlation of 0.52. We also confirmed the benefit of taking prediction into account by observing the behavior of the agent in a specific traffic scenario.
ER  - 

TY  - CONF
TI  - ADAPS: Autonomous Driving Via Principled Simulations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7625
EP  - 7631
AU  - W. Li
AU  - D. Wolinski
AU  - M. C. Lin
PY  - 2019
KW  - hierarchical systems
KW  - remotely operated vehicles
KW  - road traffic control
KW  - robust control
KW  - ADAPS
KW  - autonomous driving
KW  - robust control policy
KW  - autonomous vehicles
KW  - simulation platforms
KW  - learning mechanism
KW  - hierarchical control policy
KW  - DAGGER method
KW  - Task analysis
KW  - Training
KW  - Accidents
KW  - Autonomous vehicles
KW  - Training data
KW  - Trajectory
KW  - Learning systems
DO  - 10.1109/ICRA.2019.8794239
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous driving has gained significant advancements in recent years. However, obtaining a robust control policy for driving remains challenging as it requires training data from a variety of scenarios, including rare situations (e.g., accidents), an effective policy architecture, and an efficient learning mechanism. We propose ADAPS for producing robust control policies for autonomous vehicles. ADAPS consists of two simulation platforms in generating and analyzing accidents to automatically produce labeled training data, and a memoryenabled hierarchical control policy. Additionally, ADAPS offers a more efficient online learning mechanism that reduces the number of iterations required in learning compared to existing methods such as DAGGER [1]. We present both theoretical and experimental results. The latter are produced in simulated environments, where qualitative and quantitative results are generated to demonstrate the benefits of ADAPS.
ER  - 

TY  - CONF
TI  - Planning Coordinated Event Observation for Structured Narratives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7632
EP  - 7638
AU  - D. A. Shell
AU  - L. Huang
AU  - A. T. Becker
AU  - J. M. O’Kane
PY  - 2019
KW  - finite automata
KW  - mobile robots
KW  - multi-robot systems
KW  - sport
KW  - structured narratives
KW  - autonomous robots
KW  - robot teams
KW  - large-scale road race
KW  - marathon
KW  - legible form
KW  - weighted finite automaton
KW  - simulated race scenario
KW  - coordinated event observation planning
KW  - Videos
KW  - Robot kinematics
KW  - Cameras
KW  - Robot vision systems
KW  - Mobile robots
KW  - Observers
DO  - 10.1109/ICRA.2019.8794450
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of using autonomous robots to record events that obey narrative structure. The work is motivated by a vision of robot teams that can, for example, produce individualized highlight videos for each runner in a large-scale road race such as a marathon. We introduce a method for specifying the desired structure as a function that describes how well the captured events can be used to produce an output that meets the specification. This function is specified in a compact, legible form similar to a weighted finite automaton. Then we describe a planner that uses simple predictions of future events to coordinate the robots' efforts to capture the most important events, as determined by the specification. We describe an implementation of this approach, and demonstrate its effectiveness in a simulated race scenario both in simulation and in a hardware testbed.
ER  - 

TY  - CONF
TI  - Algorithmic Resolution of Multiple Impacts in Nonsmooth Mechanical Systems with Switching Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7639
EP  - 7645
AU  - Y. Li
AU  - H. Yu
AU  - D. J. Braun
PY  - 2019
KW  - complementarity
KW  - differential algebraic equations
KW  - impact (mechanical)
KW  - iterative methods
KW  - legged locomotion
KW  - plasticity
KW  - robot dynamics
KW  - algorithmic resolution
KW  - multiple impacts
KW  - nonsmooth mechanical systems
KW  - switching constraints
KW  - differential-algebraic formulation
KW  - nonsmooth dynamics
KW  - robotic systems
KW  - changing constraints
KW  - kinematic constraints
KW  - algorithmic impact resolution method
KW  - classical plastic impact law
KW  - multiple simultaneous impacts
KW  - prior linear-complementarity-based formulations
KW  - implicit impact resolution
KW  - Switches
KW  - Mathematical model
KW  - Mechanical systems
KW  - Robots
KW  - Dynamics
KW  - Heuristic algorithms
KW  - Plastics
DO  - 10.1109/ICRA.2019.8793767
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a differential-algebraic formulation with switching constraints to model the nonsmooth dynamics of robotic systems subject to changing constraints and multiple impacts. The formulation combines a single structurally simple governing equation, a set of switching kinematic constraints, and the plastic impact law, to represent the dynamics of robots that interact with their environment. The main contribution of this formulation is a novel algorithmic impact resolution method which provides an explicit solution to the classical plastic impact law in the case of multiple simultaneous impacts. This method serves as an alternative to prior linear-complementarity-based formulations which offer an implicit impact resolution through iterative calculation. We demonstrate the utility of the proposed method by simulating the locomotion of a planar anthropometric biped.
ER  - 

TY  - CONF
TI  - Rigid Body Motion Prediction with Planar Non-convex Contact Patch
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7646
EP  - 7652
AU  - J. Xie
AU  - N. Chakraborty
PY  - 2019
KW  - computational geometry
KW  - manipulator dynamics
KW  - mechanical contact
KW  - shear modulus
KW  - planar nonconvex contact patch
KW  - intermittent contact
KW  - rigid body dynamic simulation
KW  - convex contact patches
KW  - contact detection
KW  - contacting rigid bodies
KW  - multiple point contact
KW  - single point contact
KW  - rigid body motion prediction
KW  - convex hull
KW  - Mathematical model
KW  - Dynamics
KW  - Numerical models
KW  - Transmission line matrix methods
KW  - Robots
KW  - Bars
KW  - Symmetric matrices
DO  - 10.1109/ICRA.2019.8793724
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a principled method for motion prediction via dynamic simulation for rigid bodies in intermittent contact with each other where the contact is assumed to be a planar non-convex contact patch. The planar non-convex contact patch can either be a topologically connected set or disconnected set. Such algorithms are useful in planning and control for robotic manipulation. Most work in rigid body dynamic simulation assume that the contact between objects is a point contact, which may not be valid in many applications. In this paper, by using the convex hull of the contact patch, we build on our recent work on simulating rigid bodies with convex contact patches, for simulating motion of objects with planar non-convex contact patches. We formulate a discrete-time mixed complementarity problem where we solve the contact detection and integration of the equations of motion simultaneously. Thus, our method is a geometrically-implicit method and we prove that in our formulation, there is no artificial penetration between the contacting rigid bodies. We solve for the equivalent contact point (ECP) and contact impulse of each contact patch simultaneously along with the state, i.e., configuration and velocity of the objects. We provide empirical evidence to show that our method can seamlessly capture transition between different contact modes like patch contact to multiple or single point contact during simulation.
ER  - 

TY  - CONF
TI  - A Data-driven Approach for Fast Simulation of Robot Locomotion on Granular Media
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7653
EP  - 7659
AU  - Y. Zhu
AU  - L. Abdulmajeid
AU  - K. Hauser
PY  - 2019
KW  - control engineering computing
KW  - data analysis
KW  - granular materials
KW  - legged locomotion
KW  - mechanical contact
KW  - optimisation
KW  - shear modulus
KW  - stick-slip
KW  - data-driven approach
KW  - robot locomotion
KW  - granular media
KW  - semiempirical approach
KW  - contact model
KW  - stick-slip behavior
KW  - rigid objects
KW  - granular grains
KW  - granular substrate
KW  - optimization-based contact force
KW  - contact solver
KW  - contact wrenches
KW  - fast simulation
KW  - convex volume
KW  - frictional dissipation
KW  - plausible interaction response
KW  - Substrates
KW  - Computational modeling
KW  - Force
KW  - Media
KW  - Legged locomotion
KW  - Foot
DO  - 10.1109/ICRA.2019.8794337
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a semi-empirical approach for simulating robot locomotion on granular media. We first develop a contact model based on the stick-slip behavior between rigid objects and granular grains, which is then learned through running extensive experiments. The contact model represents all possible contact wrenches that the granular substrate can provide as a convex volume, which our method formulates as constraints in an optimization-based contact force solver. During simulation, granular substrates are treated as rigid objects that allow penetration and the contact solver solves for wrenches that maximize frictional dissipation. We show that our method is able to simulate plausible interaction response with several granular media at interactive rates.
ER  - 

TY  - CONF
TI  - Controller Synthesis for Discrete-time Hybrid Polynomial Systems via Occupation Measures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7675
EP  - 7682
AU  - W. Han
AU  - R. Tedrake
PY  - 2019
KW  - computational complexity
KW  - control system synthesis
KW  - discrete time systems
KW  - feedback
KW  - legged locomotion
KW  - linear programming
KW  - linear systems
KW  - manipulator dynamics
KW  - optimisation
KW  - polynomials
KW  - stability
KW  - discrete-time hybrid polynomial system
KW  - occupation measures
KW  - controller synthesis
KW  - computational complexity
KW  - polynomial dynamics equation
KW  - feedback design
KW  - rigid body system stabilization
KW  - state-input space
KW  - finite-dimensional semidefinite programs
KW  - robot locomotion
KW  - robot manipulation
KW  - Aerospace electronics
KW  - Switches
KW  - Mathematical model
KW  - Optimization
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793881
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the feedback design for stabilizing a rigid body system by making and breaking multiple contacts with the environment without prespecifying the timing or the number of occurrence of the contacts. We model such a system as a discrete-time hybrid polynomial system, where the state-input space is partitioned into several polytopic regions with each region associated with a different polynomial dynamics equation. Based on the notion of occupation measures, we present a novel controller synthesis approach that solves finite-dimensional semidefinite programs as approximations to an infinite-dimensional linear program to stabilize the system. The optimization formulation is simple and convex, and for any fixed degree of approximations the computational complexity is polynomial in the state and control input dimensions. We illustrate our approach on some robotics examples.
ER  - 

TY  - CONF
TI  - Optimal Path Planning for ω-regular Objectives with Abstraction-Refinement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7683
EP  - 7689
AU  - Y. P. Leong
AU  - P. Prabhakar
PY  - 2019
KW  - automata theory
KW  - computational complexity
KW  - control system synthesis
KW  - discrete time systems
KW  - game theory
KW  - optimal control
KW  - optimisation
KW  - path planning
KW  - trajectory control
KW  - optimal path planning
KW  - ω-regular objective
KW  - abstraction-refinement based framework
KW  - optimal controller synthesis
KW  - discrete-time concrete system
KW  - finite weighted transition system
KW  - optimal abstract controller
KW  - formal controller synthesis algorithms
KW  - robot surveillance scenario
KW  - Büchi automaton
KW  - Games
KW  - Automata
KW  - Surveillance
KW  - Cost function
KW  - Path planning
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2019.8794209
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an abstraction-refinement based framework for optimal controller synthesis of discrete-time systems with respect to ω-regular objectives. It first abstracts the discrete-time “concrete” system into a finite weighted transition system using a finite partition of the state-space. Then, a two-player mean payoff parity game is solved on the product of the abstract system and the Büchi automaton corresponding to the ω-regular objective, to obtain an optimal “abstract” controller that satisfies the ω-regular objective. The abstract controller is guaranteed to be implementable in the concrete discrete-time system, with a sub-optimal cost. The abstraction is refined with finer partitions to reduce the suboptimality. In contrast to existing formal controller synthesis algorithms based on abstractions, this technique provides an upper bound on the trajectory cost when implementing the suboptimal controller. A robot surveillance scenario is presented to illustrate the feasibility of the approach.
ER  - 

TY  - CONF
TI  - Sampling-Based Polytopic Trees for Approximate Optimal Control of Piecewise Affine Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7690
EP  - 7696
AU  - S. Sadraddini
AU  - R. Tedrake
PY  - 2019
KW  - approximation theory
KW  - closed loop systems
KW  - control system synthesis
KW  - convex programming
KW  - discrete time systems
KW  - feedback
KW  - integer programming
KW  - linear quadratic control
KW  - Lyapunov methods
KW  - nonlinear control systems
KW  - optimal control
KW  - piecewise linear techniques
KW  - predictive control
KW  - stability
KW  - piecewise affine systems
KW  - contact dynamics
KW  - robot locomotion
KW  - control techniques
KW  - feedback control policies
KW  - discrete-time PWA systems
KW  - closed-loop trajectories
KW  - cost function
KW  - LQR-trees
KW  - open-loop trajectory optimization
KW  - PWA dynamics
KW  - contact-based dynamics
KW  - sampling-based polytopic trees
KW  - approximate optimal control
KW  - Trajectory
KW  - Robots
KW  - Programming
KW  - Integrated circuit modeling
KW  - Optimization
KW  - Optimal control
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793634
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Piecewise affine (PWA) systems are widely used to model highly nonlinear behaviors such as contact dynamics in robot locomotion and manipulation. Existing control techniques for PWA systems have computational drawbacks, both in offline design and online implementation. In this paper, we introduce a method to obtain feedback control policies and a corresponding set of admissible initial conditions for discrete-time PWA systems such that all the closed-loop trajectories reach a goal polytope, while a cost function is optimized. The idea is conceptually similar to LQR-trees [1], which consists of 3 steps: (1) open-loop trajectory optimization, (2) feedback control for computation of “funnels” of states around trajectories, and (3) repeating (1) and (2) in a way that the funnels are grown backward from the goal in a tree fashion and fill the state-space as much as possible. We show PWA dynamics can be exploited to combine step (1) and (2) into a single step that is tackled using mixed-integer convex programming, which makes the method suitable for dealing with hard constraints. Illustrative examples on contact-based dynamics are presented.
ER  - 

TY  - CONF
TI  - A Classification-based Approach for Approximate Reachability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7697
EP  - 7704
AU  - V. Rubies-Royo
AU  - D. Fridovich-Keil
AU  - S. Herbert
AU  - C. J. Tomlin
PY  - 2019
KW  - approximation theory
KW  - computational complexity
KW  - controllability
KW  - nonlinear control systems
KW  - optimal control
KW  - pattern classification
KW  - reachability analysis
KW  - goal satisfaction
KW  - safety verification
KW  - nonlinear systems
KW  - computational complexity
KW  - restrictive problem classes
KW  - optimal controller
KW  - HJ reachability problem
KW  - control-affine systems
KW  - dynamical systems
KW  - reachability value function
KW  - classification-based approach
KW  - approximate reachability
KW  - Hamilton-Jacobi reachability analysis
KW  - simple binary classifiers
KW  - grid-based methodologies
KW  - physical quadrotor navigation task
KW  - Optimal control
KW  - Reachability analysis
KW  - Tools
KW  - Neural networks
KW  - Safety
KW  - System dynamics
DO  - 10.1109/ICRA.2019.8793919
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Hamilton-Jacobi (HJ) reachability analysis has been developed over the past decades into a widely-applicable tool for determining goal satisfaction and safety verification in nonlinear systems. While HJ reachability can be formulated very generally, computational complexity can be a serious impediment for many systems of practical interest. Much prior work has been devoted to computing approximate solutions to large reachability problems, yet many of these methods may only apply to very restrictive problem classes, do not generate controllers, and/or can be extremely conservative. In this paper, we present a new method for approximating the optimal controller of the HJ reachability problem for control-affine systems. While also a specific problem class, many dynamical systems of interest are, or can be well approximated, by control-affine models. We explicitly avoid storing a representation of the reachability value function, and instead learn a controller as a sequence of simple binary classifiers. We compare our approach to existing grid-based methodologies in HJ reachability and demonstrate its utility on several examples, including a physical quadrotor navigation task.
ER  - 

TY  - CONF
TI  - Improving drone localisation around wind turbines using monocular model-based tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7713
EP  - 7719
AU  - O. Moolan-Feroze
AU  - K. Karachalios
AU  - D. N. Nikolaidis
AU  - A. Calway
PY  - 2019
KW  - convolutional neural nets
KW  - Global Positioning System
KW  - graph theory
KW  - image matching
KW  - image representation
KW  - inertial navigation
KW  - mobile robots
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - wind turbines
KW  - image-based measurements
KW  - drone navigation system
KW  - automated inspection
KW  - wind turbines
KW  - 3D skeleton representation
KW  - image data
KW  - convolutional neural network
KW  - generic turbine model
KW  - turbine shapes
KW  - image measurements
KW  - drone localisation
KW  - monocular model-based tracking
KW  - pose graph optimiser
KW  - Wind turbines
KW  - Blades
KW  - Drones
KW  - Inspection
KW  - Poles and towers
KW  - Cameras
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794156
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel method of integrating image-based measurements into a drone navigation system for the automated inspection of wind turbines. We take a model-based tracking approach, where a 3D skeleton representation of the turbine is matched to the image data. Matching is based on comparing the projection of the representation to that inferred from images using a convolutional neural network. This enables us to find image correspondences using a generic turbine model that can be applied to a wide range of turbine shapes and sizes. To estimate 3D pose of the drone, we fuse the network output with GPS and IMU measurements using a pose graph optimiser. Results illustrate that the use of the image measurements significantly improves the accuracy of the localisation over that obtained using GPS and IMU alone.
ER  - 

TY  - CONF
TI  - Experimental Assessment of Plume Mapping using Point Measurements from Unmanned Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7720
EP  - 7726
AU  - M. Hutchinson
AU  - P. Ladosz
AU  - C. Liu
AU  - W. Chen
PY  - 2019
KW  - air pollution
KW  - air quality
KW  - autonomous aerial vehicles
KW  - environmental monitoring (geophysics)
KW  - Gaussian processes
KW  - interpolation
KW  - mobile robots
KW  - Monte Carlo methods
KW  - regression analysis
KW  - point measurements
KW  - autonomous robots
KW  - mapping algorithms
KW  - piecewise linear interpolation
KW  - steady state ground truth
KW  - unmanned aerial vehicle
KW  - Gaussian process regression
KW  - polynomial interpolation
KW  - plume mapping
KW  - neural networks
KW  - Robot sensing systems
KW  - Interpolation
KW  - Gaussian processes
KW  - Dispersion
KW  - Noise measurement
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793848
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents experiments to assess the plume mapping performance of autonomous robots. The paper compares several mapping algorithms including Gaussian Process regression, Neural networks and polynomial and piecewise linear interpolation. The methods are compared in Monte Carlo simulations using a well known plume model and in indoor experiments using a ground robot. Unlike previous work on mapping using unmanned vehicles, the indoor experiments were performed in a controlled and repeatable manner where a steady state ground truth could be obtained in order to properly assess the various regression methods using data from a real dispersive source and sensor. The effect of sampling time during data collection was assessed with regards to the mapping accuracy, and the data collected during the experiments have been made available. Overall, the Gaussian Process method was found to perform the best among the regression algorithms, showing more robustness to the noisy measurements obtained from short sampling periods, enabling an accurate map to be produced in significantly less time. Finally, plume mapping results are presented in uncontrolled outdoor conditions, using an unmanned aerial vehicle, to demonstrate the system in a realistic uncontrolled environment.
ER  - 

TY  - CONF
TI  - Online Deep Learning for Improved Trajectory Tracking of Unmanned Aerial Vehicles Using Expert Knowledge
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7727
EP  - 7733
AU  - A. Sarabakha
AU  - E. Kayacan
PY  - 2019
KW  - autonomous aerial vehicles
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - trajectory control
KW  - input-output dataset
KW  - deep neural network-based controller
KW  - trained DNN
KW  - expert knowledge
KW  - learning-based approach
KW  - trajectory tracking performance
KW  - online deep learning
KW  - unmanned aerial vehicles
KW  - online learning-based control method
KW  - trajectory tracking
KW  - Training
KW  - Fuzzy logic
KW  - Unmanned aerial vehicles
KW  - Trajectory
KW  - Real-time systems
KW  - Trajectory tracking
DO  - 10.1109/ICRA.2019.8794314
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work presents an online learning-based control method for improved trajectory tracking of unmanned aerial vehicles using both deep learning and expert knowledge. The proposed method does not require the exact model of the system to be controlled, and it is robust against variations in system dynamics as well as operational uncertainties. The learning is divided into two phases: offline (pre-)training and online (post-)training. In the former, a conventional controller performs a set of trajectories and, based on the input-output dataset, the deep neural network (DNN)-based controller is trained. In the latter, the trained DNN, which mimics the conventional controller, controls the system. Unlike the existing papers in the literature, the network is still being trained for different sets of trajectories which are not used in the training phase of DNN. Thanks to the rule-base, which contains the expert knowledge, the proposed framework learns the system dynamics and operational uncertainties in real-time. The experimental results show that the proposed online learning-based approach gives better trajectory tracking performance when compared to the only offline trained network.
ER  - 

TY  - CONF
TI  - Decentralized collaborative transport of fabrics using micro-UAVs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7734
EP  - 7740
AU  - R. Cotsakis
AU  - D. St-Onge
AU  - G. Beltrame
PY  - 2019
KW  - autonomous aerial vehicles
KW  - decentralised control
KW  - microrobots
KW  - mobile robots
KW  - remotely operated vehicles
KW  - microUAV
KW  - small unmanned aerial vehicles
KW  - Buzz swarm-specific scripting language
KW  - fully decentralized control infrastructure
KW  - task demands
KW  - unstructured environments
KW  - maximum flexibility
KW  - joint payload capacity
KW  - decentralized collaborative transport
KW  - Robots
KW  - Payloads
KW  - Springs
KW  - Force
KW  - Task analysis
KW  - Shock absorbers
KW  - Python
DO  - 10.1109/ICRA.2019.8793778
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Small unmanned aerial vehicles (UAVs) have generally little capacity to carry payloads. Through collaboration, the UAVs can increase their joint payload capacity and carry more significant loads. For maximum flexibility to dynamic and unstructured environments and task demands, we propose a fully decentralized control infrastructure based on a swarm-specific scripting language, Buzz. In this paper, we describe the control infrastructure and use it to compare two algorithms for collaborative transport: field potentials and spring-damper. We test the performance of our approach with a fleet of micro-UAVs, demonstrating the potential of decentralized control for collaborative transport.
ER  - 

TY  - CONF
TI  - Precision Stationary Flight of a Robotic Hummingbird*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7741
EP  - 7747
AU  - A. Roshanbin
AU  - E. Garone
AU  - A. Preumont
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - cascade control
KW  - compensation
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - torque control
KW  - trajectory control
KW  - robotic hummingbird project
KW  - flapping mechanism
KW  - wing trajectory
KW  - cascade control strategy
KW  - precision stationary flight
KW  - residual parasitic torques compensation
KW  - lift vector
KW  - autopilot
KW  - Bars
KW  - Robots
KW  - Acceleration
KW  - Aerodynamics
KW  - Harmonic analysis
KW  - Couplings
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8793841
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes recent developments of a robotic hummingbird project, aimed at achieving precision stationary hovering. To this end, the early version of our flapping mechanism is modified which, besides being more efficient, reduces significantly the asymmetry of the wing trajectory of the previous version. A cascade control strategy is used to compensate for the residual parasitic torques and the misalignment of the lift vector and the autopilot.
ER  - 

TY  - CONF
TI  - Robust attitude estimation using an adaptive unscented Kalman filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7748
EP  - 7754
AU  - A. C. B. Chiella
AU  - B. O. S. Teixeira
AU  - G. A. S. Pereira
PY  - 2019
KW  - attitude control
KW  - attitude measurement
KW  - covariance matrices
KW  - Kalman filters
KW  - manipulators
KW  - nonlinear filters
KW  - robust control
KW  - UKF innovation
KW  - adaptive strategy
KW  - measurement covariance matrix online
KW  - outlier detection
KW  - robust attitude estimation
KW  - standard UKF
KW  - unit quaternion algebra
KW  - outlier detector algorithm
KW  - robust adaptive unscented Kalman filter
KW  - Quaternions
KW  - Estimation
KW  - Covariance matrices
KW  - Magnetometers
KW  - Kalman filters
KW  - Accelerometers
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793714
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the robust Adaptive unscented Kalman filter (RAUKF) for attitude estimation. Since the proposed algorithm represents attitude as a unit quaternion, all basic tools used, including the standard UKF, are adapted to the unit quaternion algebra. Additionally, the algorithm adopts an outlier detector algorithm to identify abrupt changes in the UKF innovation and an adaptive strategy based on covariance matching to tune the measurement covariance matrix online. Adaptation and outlier detection make the proposed algorithm robust to fast and slow perturbations such as magnetic field interference and linear accelerations. Experimental results with a manipulator robot suggest that our method overcomes other algorithms found in the literature.
ER  - 

TY  - CONF
TI  - One-Shot Learning of Multi-Step Tasks from Observation via Activity Localization in Auxiliary Video
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7755
EP  - 7761
AU  - W. Goo
AU  - S. Niekum
PY  - 2019
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - video signal processing
KW  - one-shot learning
KW  - multistep tasks
KW  - activity localization
KW  - reinforcement learning
KW  - action policies learning
KW  - reward functions inference
KW  - user-segmented demonstration
KW  - auxiliary video data
KW  - Task analysis
KW  - Reinforcement learning
KW  - Neural networks
KW  - Training
KW  - Robot sensing systems
KW  - Training data
DO  - 10.1109/ICRA.2019.8793515
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to burdensome data requirements, learning from demonstration often falls short of its promise to allow users to quickly and naturally program robots. Demonstrations are inherently ambiguous and incomplete, making correct generalization to unseen situations difficult without a large number of demonstrations in varying conditions. By contrast, humans are often able to learn complex tasks from a single demonstration (typically observations without action labels) by leveraging context learned over a lifetime. Inspired by this capability, our goal is to enable robots to perform one-shot learning of multi-step tasks from observation by leveraging auxiliary video data as context. Our primary contribution is a novel system that achieves this goal by: (1) using a single user-segmented demonstration to define the primitive actions that comprise a task, (2) localizing additional examples of these actions in unsegmented auxiliary videos via a metalearning-based approach, (3) using these additional examples to learn a reward function for each action, and (4) performing reinforcement learning on top of the inferred reward functions to learn action policies that can be combined to accomplish the task. We empirically demonstrate that a robot can learn multi-step tasks more effectively when provided auxiliary video, and that performance greatly improves when localizing individual actions, compared to learning from unsegmented videos.
ER  - 

TY  - CONF
TI  - LVIS: Learning from Value Function Intervals for Contact-Aware Robot Controllers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7762
EP  - 7768
AU  - R. Deits
AU  - T. Koolen
AU  - R. Tedrake
PY  - 2019
KW  - concave programming
KW  - feedback
KW  - humanoid robots
KW  - integer programming
KW  - learning (artificial intelligence)
KW  - mechanical contact
KW  - mobile robots
KW  - neurocontrollers
KW  - optimal control
KW  - predictive control
KW  - robot dynamics
KW  - tree searching
KW  - LVIS
KW  - contact-aware robot controllers
KW  - guided policy search
KW  - high-dimensional systems
KW  - nonconvex trajectory optimization
KW  - local minima
KW  - optimal policy
KW  - independently-optimized samples
KW  - optimal value function
KW  - mixed-integer programs
KW  - global optimality
KW  - interval samples
KW  - terminal cost
KW  - feedback control
KW  - learning from value function intervals
KW  - controller training
KW  - global mixed-integer optimization
KW  - nonuniqueness issue
KW  - branch-and-bound algorithm
KW  - neural net training
KW  - learned cost-to-go
KW  - one-step model-predictive controller
KW  - piecewise affine models
KW  - cart-pole system
KW  - planar humanoid robot
KW  - Humanoid robots
KW  - Trajectory optimization
KW  - Neural networks
KW  - Force
KW  - Training
DO  - 10.1109/ICRA.2019.8794352
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Guided policy search is a popular approach for training controllers for high-dimensional systems, but it has a number of pitfalls. Non-convex trajectory optimization has local minima, and non-uniqueness in the optimal policy itself can mean that independently-optimized samples do not describe a coherent policy from which to train. We introduce LVIS, which circumvents the issue of local minima through global mixed-integer optimization and the issue of non-uniqueness through learning the optimal value function rather than the optimal policy. To avoid the expense of solving the mixed-integer programs to full global optimality, we instead solve them only partially, extracting intervals containing the true cost-to-go from early termination of the branch-and-bound algorithm. These interval samples are used to weakly supervise the training of a neural net which approximates the true cost-to-go. Online, we use that learned cost-to-go as the terminal cost of a one-step model-predictive controller, which we solve via a small mixed-integer optimization. We demonstrate LVIS on piecewise affine models of a cart-pole system with walls and a planar humanoid robot and show that it can be applied to a fundamentally hard problem in feedback control-control through contact.
ER  - 


