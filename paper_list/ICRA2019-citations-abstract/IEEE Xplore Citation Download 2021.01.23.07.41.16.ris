TY  - CONF
TI  - Estimating the Localizability in Tunnel-like Environments using LiDAR and UWB
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4903
EP  - 4908
AU  - W. Zhen
AU  - S. Scherer
PY  - 2019
KW  - Global Positioning System
KW  - inspection
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - probability
KW  - robot vision
KW  - sensor fusion
KW  - tunnels
KW  - ultra wideband technology
KW  - UWB
KW  - inspection tasks
KW  - autonomous navigation technology
KW  - robot localization techniques
KW  - GPS-denied environments
KW  - onboard sensors
KW  - cameras
KW  - LiDAR
KW  - probabilistic sensor fusion method
KW  - tunnel-like environments
KW  - degeneration characterization model
KW  - ultra-wideband ranging radio
KW  - Robot sensing systems
KW  - Laser radar
KW  - Uncertainty
KW  - Probabilistic logic
KW  - Distance measurement
DO  - 10.1109/ICRA.2019.8794167
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The application of robots in inspection tasks has been growing quickly thanks to the advancements in autonomous navigation technology, especially the robot localization techniques in GPS-denied environments. Although many methods have been proposed to localize a robot using onboard sensors such as cameras and LiDARs, achieving robust localization in geometrically degenerated environments, e.g. tunnels, remains a challenging problem. In this work, we focus on the robust localization problem in such situations. A novel degeneration characterization model is presented to estimate the localizability at a given location in the prior map. And the localizability of a LiDAR and an Ultra-Wideband (UWB) ranging radio is analyzed. Additionally, a probabilistic sensor fusion method is developed to combine IMU, LiDAR and the UWB. Experiment results show that this method allows for robust localization inside a long straight tunnel.
ER  - 

TY  - CONF
TI  - Global Localization with Object-Level Semantics and Topology
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4909
EP  - 4915
AU  - Y. Liu
AU  - Y. Petillot
AU  - D. Lane
AU  - S. Wang
PY  - 2019
KW  - feature extraction
KW  - graph theory
KW  - image matching
KW  - image representation
KW  - pose estimation
KW  - stereo image processing
KW  - object-level representation
KW  - semantic object association
KW  - semantic-level point alignment
KW  - object-level semantics
KW  - appearance-based approach
KW  - 3D dense semantics
KW  - semantic graph
KW  - vision-based global localization
KW  - topology
KW  - autonomous navigation
KW  - simultaneous localization and mapping
KW  - place recognition
KW  - 6-DoF pose estimation
KW  - visual feature matching
KW  - Semantics
KW  - Three-dimensional displays
KW  - Topology
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Cameras
KW  - Pose estimation
DO  - 10.1109/ICRA.2019.8794475
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Global localization lies at the heart of autonomous navigation and Simultaneous Localization and Mapping (SLAM). The appearance-based approach has been successful, but still faces many open challenges in environments where visual conditions vary significantly over time. In this paper, we propose an integrated solution to leverage object-level dense semantics and spatial understanding of the environment for global localization. Our approach models an environment with 3D dense semantics, semantic graph and their topology. This object-level representation is then used for place recognition via semantic object association, followed by 6-DoF pose estimation by the semantic-level point alignment. Extensive experiments show that our approach can achieve robust global localization under extreme appearance changes. It is also capable of coping with other challenging scenarios, such as dynamic environments and incomplete query observations.
ER  - 

TY  - CONF
TI  - Look No Deeper: Recognizing Places from Opposing Viewpoints under Varying Scene Appearance using Single-View Depth Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4916
EP  - 4923
AU  - S. Garg
AU  - M. Babu V
AU  - T. Dharmasiri
AU  - S. Hausler
AU  - N. Suenderhauf
AU  - S. Kumar
AU  - T. Drummond
AU  - M. Milford
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image filtering
KW  - image matching
KW  - image representation
KW  - image sensors
KW  - image sequences
KW  - object detection
KW  - keypoint sequence
KW  - single query image
KW  - depth-filtered keypoint sequences
KW  - camera motion
KW  - varying scene appearance
KW  - single-view depth estimation
KW  - familiar visual place
KW  - extreme environmental appearance change
KW  - field-of-view vision
KW  - temporal-aware visual place recognition system
KW  - extreme appearance-change visual place recognition problem
KW  - sequence-to-single frame matching
KW  - depth-filtered keypoints
KW  - depth estimation pipeline
KW  - Visualization
KW  - Estimation
KW  - Feature extraction
KW  - Cameras
KW  - Indexes
KW  - Robots
KW  - Measurement
DO  - 10.1109/ICRA.2019.8794178
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual place recognition (VPR) - the act of recognizing a familiar visual place - becomes difficult when there is extreme environmental appearance change or viewpoint change. Particularly challenging is the scenario where both phenomena occur simultaneously, such as when returning for the first time along a road at night that was previously traversed during the day in the opposite direction. While such problems can be solved with panoramic sensors, humans solve this problem regularly with limited field-of-view vision and without needing to constantly turn around. In this paper, we present a new depth- and temporal-aware visual place recognition system that solves the opposing viewpoint, extreme appearance-change visual place recognition problem. Our system performs sequence-to-single frame matching by extracting depth-filtered keypoints using a state-of-the-art depth estimation pipeline, constructing a keypoint sequence over multiple frames from the reference dataset, and comparing these keypoints to the keypoints extracted from a single query image. We evaluate the system on a challenging benchmark dataset and show that it consistently outperforms state-of-the-art techniques. We also develop a range of diagnostic simulation experiments that characterize the contribution of depth-filtered keypoint sequences with respect to key domain parameters including the degree of appearance change and camera motion.
ER  - 

TY  - CONF
TI  - Exploiting Trademark Databases for Robotic Object Fetching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4946
EP  - 4952
AU  - J. Song
AU  - H. Kurniawati
PY  - 2019
KW  - feature extraction
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - service robots
KW  - shape recognition
KW  - trademarks
KW  - synthetic data
KW  - convolutional neural network logo detector
KW  - domain randomization
KW  - soft drinks
KW  - logo images
KW  - large-scale data
KW  - household objects
KW  - service robots
KW  - robotic object
KW  - trademark databases
KW  - object fetching
KW  - Databases
KW  - Trademarks
KW  - Robots
KW  - Detectors
KW  - Task analysis
KW  - Training
KW  - Shape
DO  - 10.1109/ICRA.2019.8793829
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.
ER  - 

TY  - CONF
TI  - Object Detection Approach for Robot Grasp Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4953
EP  - 4959
AU  - H. Karaoguz
AU  - P. Jensfelt
PY  - 2019
KW  - convolutional neural nets
KW  - grippers
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - robot platform
KW  - object detection approach
KW  - robot grasp detection
KW  - robot grasping problem
KW  - parallel gripper
KW  - image data
KW  - end-to-end approach
KW  - RGB images
KW  - transfer learning
KW  - adapted network
KW  - convolutional neural network based based object detection architecture
KW  - Grasping
KW  - Robot kinematics
KW  - Grippers
KW  - Neural networks
KW  - Object detection
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793751
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we focus on the robot grasping problem with parallel grippers using image data. For this task, we propose and implement an end-to-end approach. In order to detect the good grasping poses for a parallel gripper from RGB images, we have employed transfer learning for a Convolutional Neural Network (CNN) based object detection architecture. Our obtained results show that, the adapted network either outperforms or is on-par with the state-of-the art methods on a benchmark dataset. We also performed grasping experiments on a real robot platform to evaluate our method's real world performance.
ER  - 

TY  - CONF
TI  - MetaGrasp: Data Efficient Grasping by Affordance Interpreter Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4960
EP  - 4966
AU  - J. Cai
AU  - H. Cheng
AU  - Z. Zhang
AU  - J. Su
PY  - 2019
KW  - dexterous manipulators
KW  - grippers
KW  - image colour analysis
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - data efficient grasping
KW  - data-driven approach
KW  - training data
KW  - data collection
KW  - grasp training system
KW  - model inference
KW  - antipodal grasp rule
KW  - affordance map
KW  - ungraspability
KW  - grasp affordances
KW  - pixel-level affordance interpreter network
KW  - quantitative experiments
KW  - real-world grasp experiments
KW  - qualitative experiments
KW  - Grasping
KW  - Training
KW  - Data collection
KW  - Data models
KW  - Grippers
KW  - Robots
KW  - Deep learning
DO  - 10.1109/ICRA.2019.8793912
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Data-driven approach for grasping shows significant advance recently. But these approaches usually require much training data. To increase the efficiency of grasping data collection, this paper presents a novel grasp training system including the whole pipeline from data collection to model inference. The system can collect effective grasp sample with a corrective strategy assisted by antipodal grasp rule, and we design an affordance interpreter network to predict pixelwise grasp affordance map. We define graspability, ungraspability and background as grasp affordances. The key advantage of our system is that the pixel-level affordance interpreter network trained with only a small number of grasp samples under antipodal rule can achieve significant performance on totally unseen objects and backgrounds. The training sample is only collected in simulation. Extensive qualitative and quantitative experiments demonstrate the accuracy and robustness of our proposed approach. In the real-world grasp experiments, we achieve a grasp success rate of 93% on a set of household items and 91% on a set of adversarial items with only about 6,300 simulated samples. We also achieve 87% accuracy in clutter scenario. Although the model is trained using only RGB image, when changing the background textures, it also performs well and can achieve even 94% accuracy on the set of adversarial objects, which outperforms current state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Toward Fingertip Non-Contact Material Recognition and Near-Distance Ranging for Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4967
EP  - 4974
AU  - C. Fang
AU  - D. Wang
AU  - D. Song
AU  - J. Zou
PY  - 2019
KW  - displacement measurement
KW  - grippers
KW  - image sensors
KW  - photoacoustic effect
KW  - ultrasonic imaging
KW  - ultrasonic transducers
KW  - pre-touch approaches
KW  - fingertip noncontact material recognition
KW  - conventional contact
KW  - acoustic bi-modal distance
KW  - near-distance ranging
KW  - sensor design
KW  - nimble grasping
KW  - robust grasping
KW  - material type
KW  - robotic fingers
KW  - single-element air-coupled transducers
KW  - optoacoustic effects
KW  - pulse-echo ultrasound
KW  - last-moment perception
KW  - robot fingertip
KW  - robotic grasping
KW  - optical bi-modal distance
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8793922
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We report the feasibility study of a new acoustic and optical bi-modal distance & material sensor for robotic grasping. The new sensor is designed to be mounted on the robot fingertip to provide last-moment perception before contact happens. It is based on both pulse-echo ultrasound and optoacoustic effects enabled by single-element air-coupled transducers. In contrast to conventional contact-based and recent pre-touch approaches, this new method overcomes their disadvantages and provides robotic fingers with the capability to detect the distance and material type of the target at a near distance before contact occurs, which is crucial for robust and nimble grasping. The proposed sensor has been tested with different materials, shapes, and porous properties. The experimental results show that this sensor design is functional and practical.
ER  - 

TY  - CONF
TI  - Video-based Prediction of Hand-grasp Preshaping with Application to Prosthesis Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4975
EP  - 4982
AU  - L. T. Taverne
AU  - M. Cognolato
AU  - T. BÃ¼tzer
AU  - R. Gassert
AU  - O. Hilliges
PY  - 2019
KW  - dexterous manipulators
KW  - electromyography
KW  - learning (artificial intelligence)
KW  - medical control systems
KW  - medical signal processing
KW  - orthotics
KW  - prosthetics
KW  - video signal processing
KW  - deep learning
KW  - automatic prediction
KW  - hand prosthesis
KW  - video sequences
KW  - RGB-D video data
KW  - orthotic devices
KW  - prosthetic devices
KW  - surface electromyography pattern recognition
KW  - arbitrary objects
KW  - video-based technique
KW  - grasp-type selection techniques
KW  - prosthesis control
KW  - hand-grasp
KW  - video-based prediction
KW  - Cameras
KW  - Prosthetics
KW  - Deep learning
KW  - Predictive models
KW  - Grasping
KW  - Object recognition
KW  - Pattern recognition
DO  - 10.1109/ICRA.2019.8794175
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Among the currently available grasp-type selection techniques for hand prostheses, there is a distinct lack of intuitive, robust, low-latency solutions. In this paper we investigate the use of a portable, forearm-mounted, video-based technique for the prediction of hand-grasp preshaping for arbitrary objects. The purpose of this system is to automatically select the grasp-type for the user of the prosthesis, potentially increasing ease-of-use and functionality. This system can be used to supplement and improve existing control strategies, such as surface electromyography (sEMG) pattern recognition, for prosthetic and orthotic devices. We designed and created a suitable dataset consisting of RGB-D video data for 2212 grasp examples split evenly across 7 classes; 6 grasps commonly used in activities of daily living, and an additional no-grasp category. We processed and analyzed the dataset using several state-of-the-art deep learning architectures. Our selected model shows promising results for realistic, intuitive, real-world use, reaching per-frame accuracies on video sequences of up to 95.90% on the validation set. Such a system could be integrated into the palm of a hand prosthesis, allowing an automatic prediction of the grasp-type without requiring any special movements or aiming by the user.
ER  - 

TY  - CONF
TI  - Reactive Walking Based on Upper-Body Manipulability: An application to Intention Detection and Reaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4991
EP  - 4997
AU  - P. Mohammadi
AU  - E. M. Hoffman
AU  - L. Muratore
AU  - N. G. Tsagarakis
AU  - J. J. Steil
PY  - 2019
KW  - humanoid robots
KW  - human-robot interaction
KW  - legged locomotion
KW  - manipulators
KW  - motion control
KW  - position control
KW  - robot platforms
KW  - reactive walking
KW  - upper-body manipulability
KW  - intention detection
KW  - human robot interaction
KW  - hand-in-hand interaction scenario
KW  - impedance controlled humanoid
KW  - velocity transmission
KW  - robot arms manipulation quality
KW  - appropriate directions
KW  - robot manipulation ability
KW  - COMAN + humanoid robot
KW  - manipulation motion
KW  - human operator
KW  - reactive steps
KW  - humanoid COMAN+ control
KW  - walking pattern generators
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Manipulators
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8794309
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we look at the challenge of human robot interaction in locomotion. We consider a hand-in-hand interaction scenario where a human compliantly interacts with the upper-body of an impedance controlled humanoid. By exploring the velocity transmission of the robot arms, and the interaction in terms of robot arms manipulation quality evaluated through the monitoring of their manipulability the proposed method derives suitable reactive steps in appropriate directions to ensure that the robot manipulation ability is maintained with the robot arms providing high capacity of motion along the different directions. The proposed approach can be combined with different walking pattern generators and is not tailored to a specific one used in this work. The results of the proposed method are experimentally validated on the COMAN + humanoid robot showing the efficacy of the method to generate reactive stepping driven by the interaction and manipulation motion of the human operator. Besides, the work also provides a real-time software architecture to control humanoid COMAN+, but it is also flexible to be used for the control of other robot platforms.
ER  - 

TY  - CONF
TI  - A Self-Modulated Impedance Multimodal Interaction Framework for Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4998
EP  - 5004
AU  - L. Muratore
AU  - A. Laurenzi
AU  - N. G. Tsagarakis
PY  - 2019
KW  - active disturbance rejection control
KW  - humanoid robots
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - unexpected interaction forces
KW  - online self-tuning stiffness regulation principle
KW  - unexpected interaction loads
KW  - unnecessary motion commands
KW  - human generated motions
KW  - verbal interaction channel
KW  - human-robot collaboration task
KW  - self-modulated impedance multimodal interaction framework
KW  - human robot interaction
KW  - manipulation manoeuvres
KW  - humanoid robot COMAN +
KW  - Task analysis
KW  - Impedance
KW  - Collaboration
KW  - Robot sensing systems
KW  - Payloads
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794168
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Human Robot interaction is a fundamental perquisite for any robot performing a physical task in collaboration with a human. The presence of disturbances arising from the partially known tasks payloads, the unexpected interaction forces in general, and the uncertainty in the interpretation of the human intention in terms of motions and forces can pose significant challenges and eventually compromise the execution of the collaborative task. This work presents a novel, intrinsically adaptable multimodal (force, motion and verbal) interaction framework for human-robot collaboration (HRC) that leverages on an online self-tuning stiffness regulation principle to provide adaptation to interaction/payload forces and reject disturbances arising by unexpected interaction loads. Besides the presented method, it enables the rejection of unnecessary motion commands (e.g. oscillations generated by the human operator) to reach the robot co-worker through the filtering of the human generated motions, that are outside the range (in terms of speed and acceleration) of the envisioned manipulation manoeuvres. Finally, a verbal interaction channel allows the operator to convey securely his high level intentions and to control the states of the task execution. We evaluated and demonstrated the effectiveness of the proposed multimodal interaction framework in a high weight carrying human-robot collaboration task using the humanoid robot COMAN +.
ER  - 

TY  - CONF
TI  - SMT-Based Control and Feedback for Social Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5005
EP  - 5011
AU  - T. Campos
AU  - A. Pacheck
AU  - G. Hoffman
AU  - H. Kress-Gazit
PY  - 2019
KW  - collision avoidance
KW  - computability
KW  - feedback
KW  - human-robot interaction
KW  - motion control
KW  - SMT-based control
KW  - social navigation
KW  - HRI
KW  - socially acceptable distance
KW  - robot motion
KW  - high-level formal specifications
KW  - human behavior
KW  - formal methods
KW  - human-robot interaction
KW  - collision avoidance
KW  - satisfiability modulo theories
KW  - utility-based side-by-side navigation control
KW  - SMT formula
KW  - Navigation
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Mathematical model
KW  - Safety
DO  - 10.1109/ICRA.2019.8794208
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper combines techniques from Formal Methods and Human-Robot Interaction (HRI) to address the challenge of a robot walking with a human while maintaining a socially acceptable distance and avoiding collisions. We formulate a set of constraints on the robot motion using Satisfiability Modulo Theories (SMT) formulas, and synthesize robot control that is guaranteed to be safe and correct. Due to its use of high-level formal specifications, the controller is able to provide feedback to the user in situations where human behavior causes the robot to fail. This feedback allows the human to adjust their behavior and recover joint navigation. We demonstrate the behavior of the robot in a variety of simulated scenarios and compare it to utility-based side-by-side navigation control.
ER  - 

TY  - CONF
TI  - Safe and Efficient High Dimensional Motion Planning in Space-Time with Time Parameterized Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5012
EP  - 5018
AU  - S. Li
AU  - J. A. Shah
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - probability
KW  - trajectory control
KW  - human-robot collaborative environments
KW  - pre-planned path
KW  - 6-joint manipulator
KW  - human hand
KW  - robot trajectories
KW  - obstacle-avoidance strategies
KW  - motion planning
KW  - lazy safe interval probabilistic roadmap
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Prediction algorithms
KW  - Heuristic algorithms
KW  - Collision avoidance
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793580
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we propose an algorithm that can plan safe and efficient robot trajectories in real time, given time-parameterized motion predictions, in order to avoid fast-moving obstacles in human-robot collaborative environments. Our algorithm is able to reduce the robot configuration space and the time domain significantly by constructing a Lazy Safe Interval Probabilistic Roadmap based on a pre-planned path. The algorithm then plans efficient obstacle-avoidance strategies within the space-time roadmap. We benchmarked our algorithm by evaluating the performance of a simulated 6-joint manipulator attempting to avoid a quickly moving human hand, using a dataset collected from human experiments. We compared our algorithm's performance with those of 8 variations of prior state-of-the-art planners. Results from this empirical evaluation indicate that our method generated safe plans in 97.5% of the evaluated situations, achieved a planning speed 30 times faster than the benchmarked methods that planned in the time domain without space reduction, and accomplished the minimal solution execution time among the benchmarked planners with a similar planning speed.
ER  - 

TY  - CONF
TI  - Fast Online Segmentation of Activities from Partial Trajectories
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5019
EP  - 5025
AU  - T. Iqbal
AU  - S. Li
AU  - C. Fourie
AU  - B. Hayes
AU  - J. A. Shah
PY  - 2019
KW  - assembling
KW  - hidden Markov models
KW  - image segmentation
KW  - industrial robots
KW  - maximum likelihood estimation
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - robot vision
KW  - fast online segmentation
KW  - partial trajectory
KW  - efficient plan
KW  - safe plan
KW  - online activity segmentation algorithm
KW  - hidden Markov model
KW  - efficient particle-filtering approach
KW  - activity sequence
KW  - online search process
KW  - task model information
KW  - partial order
KW  - human activity datasets
KW  - industrial mobile robot
KW  - automotive assembly task
KW  - Trajectory
KW  - Hidden Markov models
KW  - Robots
KW  - Task analysis
KW  - Computational modeling
KW  - Prediction algorithms
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794054
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Augmenting a robot with the capacity to understand the activities of the people it collaborates with in order to then label and segment those activities allows the robot to generate an efficient and safe plan for performing its own actions. In this work, we introduce an online activity segmentation algorithm that can detect activity segments by processing a partial trajectory. We model the transitions through activities as a hidden Markov model, which runs online by implementing an efficient particle-filtering approach to infer the maximum a posteriori estimate of the activity sequence. This process is complemented by an online search process to refine activity segments using task model information about the partial order of activities. We evaluated our algorithm by comparing its performance to two state-of-the-art activity segmentation algorithms on three human activity datasets. The proposed algorithm improved activity segmentation accuracy across all three datasets compared with the other two approaches, with a range from 11.3% to 65.5%, and could accurately recognize an activity through observation alone for 31.6% of the initial trajectory of that activity, on average. We also implemented the algorithm onto an industrial mobile robot during an automotive assembly task in which the robot tracked a human worker's progress and provided the worker with the correct materials at the appropriate time.
ER  - 

TY  - CONF
TI  - Laparoscopy instrument tracking for single view camera and skill assessment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5039
EP  - 5045
AU  - B. Gautier
AU  - H. Tugal
AU  - B. Tang
AU  - G. Nabi
AU  - M. S. Erden
PY  - 2019
KW  - cameras
KW  - medical computing
KW  - surgery
KW  - visual tracking algorithm
KW  - 3D reconstructed trajectories
KW  - linear discriminant analysis
KW  - frequency analysis
KW  - simple colored tapes
KW  - standard physical training box
KW  - extracted tool trajectories
KW  - single webcam camera
KW  - standard laparoscopy training box
KW  - minimally invasive surgical skills
KW  - single view camera
KW  - laparoscopy instrument tracking
KW  - Instruments
KW  - Laparoscopes
KW  - Training
KW  - Estimation
KW  - Kalman filters
KW  - Trajectory
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794038
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Assessment of minimally invasive surgical skills is a non-trivial task, usually requiring the presence and time of expert observers, including subjectivity and requiring special and expensive equipment and software. This study develops an algorithm for tracking laparoscopy instruments in the video cues of a standard laparoscopy training box with a single webcam camera and proposes new criteria to assess skill level using the extracted tool trajectories. Instrument tracking and assessment criteria together constitute a significant step towards developing a low cost, automated, and widely applicable laparoscopy training and assessment system using a standard physical training box equipped with a webcam. The developed visual tracking algorithm recovers the 3D positions of the laparoscopic instruments tips to which simple colored tapes (markers) are attached. The new assessment criteria are based on frequency analysis and linear discriminant analysis of the 3D reconstructed trajectories of the instruments. The performance of these proposed criteria are compared to the conventional criteria for laparoscopy training and demonstrated to be superior on the data we have recorded from six professional laparoscopy surgeons and ten novice subjects.
ER  - 

TY  - CONF
TI  - OffsetNet: Deep Learning for Localization in the Lung using Rendered Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5046
EP  - 5052
AU  - J. Sganga
AU  - D. Eng
AU  - C. Graetzel
AU  - D. Camarillo
PY  - 2019
KW  - cameras
KW  - closed loop systems
KW  - image reconstruction
KW  - image registration
KW  - medical computing
KW  - medical image processing
KW  - phantoms
KW  - rendering (computer graphics)
KW  - surgery
KW  - bronchoscope
KW  - update rate
KW  - average position error
KW  - conserved regions
KW  - training dataset
KW  - simulated images
KW  - simulated domains
KW  - conservative thresholds
KW  - rendered images
KW  - surgical tools
KW  - dynamic anatomy
KW  - tortuous anatomy
KW  - real-time localization
KW  - preoperative scan
KW  - human operators
KW  - closed-loop control
KW  - autonomous agents
KW  - deep learning architecture
KW  - recorded camera images
KW  - lung phantom
KW  - OffsetNet
KW  - time 30.0 min
KW  - frequency 47.0 Hz
KW  - Lung
KW  - Computed tomography
KW  - Training
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Cameras
KW  - Imaging phantoms
DO  - 10.1109/ICRA.2019.8793940
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Navigating surgical tools in the dynamic and tortuous anatomy of the lung's airways requires accurate, real-time localization of the tools with respect to the preoperative scan of the anatomy. Such localization can inform human operators or enable closed-loop control by autonomous agents, which would require accuracy not yet reported in the literature. In this paper, we introduce a deep learning architecture, called OffsetNet, to accurately localize a bronchoscope in the lung in real-time. After training on only 30 minutes of recorded camera images in conserved regions of a lung phantom, OffsetNet tracks the bronchoscope's motion on a held-out recording through these same regions at an update rate of 47 Hz and an average position error of 1.4 mm. Because this model performs poorly in less conserved regions, we augment the training dataset with simulated images from these regions. To bridge the gap between camera and simulated domains, we implement domain randomization and a generative adversarial network (GAN). After training on simulated images, OffsetNet tracks the bronchoscope's motion in less conserved regions at an average position error of 2.4 mm, which meets conservative thresholds required for successful tracking.
ER  - 

TY  - CONF
TI  - Using Augmentation to Improve the Robustness to Rotation of Deep Learning Segmentation in Robotic-Assisted Surgical Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5068
EP  - 5075
AU  - D. Itzkovich
AU  - Y. Sharon
AU  - A. Jarc
AU  - Y. Refaely
AU  - I. Nisky
PY  - 2019
KW  - data handling
KW  - learning (artificial intelligence)
KW  - medical computing
KW  - medical robotics
KW  - recurrent neural nets
KW  - robot kinematics
KW  - surgery
KW  - telerobotics
KW  - JIGSAWS dataset
KW  - data augmentation
KW  - kinematic data
KW  - surgical data science
KW  - deep learning segmentation
KW  - robotic-assisted surgical data
KW  - Robotic-Assisted Minimally Invasive Surgery
KW  - automated segmentation
KW  - data-intensive segmentation algorithms
KW  - da Vinci Research Kit
KW  - recurrent neural network
KW  - Surgery
KW  - Task analysis
KW  - Training
KW  - Robots
KW  - Kinematics
KW  - Deep learning
KW  - Robustness
KW  - Surgical Robotics: Laparoscopy
KW  - Deep Learning in Robotics and Automation
KW  - Rotation augmentation
KW  - Network generalization
DO  - 10.1109/ICRA.2019.8793963
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic-Assisted Minimally Invasive Surgery allows for easy recording of kinematic data, and presents excellent opportunities for data-intensive approaches to assessment of surgical skill, system design, and automation of procedures. However, typical surgical cases result in long data streams, and therefore, automated segmentation into gestures is important. The public release of the JIGSAWS dataset allowed for developing and benchmarking data-intensive segmentation algorithms. However, this dataset is small and the gestures are similar in their structure and directions. This may limit the generalization of the algorithms to real surgical data that are characterized by movements in arbitrary directions. In this paper, we use a recurrent neural network to segment a suturing task, and demonstrate one such generalization problem-limited generalization to rotation. We propose a simple augmentation that can solve this problem without collecting new data, and demonstrate its benefit using: (1) the JIGSAWS dataset, and (2) a new dataset that we recorded with a da Vinci Research Kit. Our study highlights the prospect of using data augmentation in the analysis of kinematic data in surgical data science.
ER  - 

TY  - CONF
TI  - Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5076
EP  - 5082
AU  - J. Ren
AU  - Y. Chien
AU  - E. Chia
AU  - L. Fu
AU  - J. Lai
PY  - 2019
KW  - biomechanics
KW  - electromyography
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - medical signal processing
KW  - mobile robots
KW  - motion control
KW  - patient rehabilitation
KW  - trajectory control
KW  - wearable robots
KW  - deep learning based motion prediction model
KW  - human arm dynamics
KW  - surface electromyography
KW  - deep learning model
KW  - robot arm
KW  - exoskeleton robot control
KW  - robot-assisted training
KW  - motion trajectory
KW  - 8 degrees-of-freedom upper limb rehabilitation exoskeleton
KW  - NTUH-II
KW  - user motion prediction
KW  - RAT
KW  - wireless sensors
KW  - sEMG
KW  - 8DoFs
KW  - Manipulators
KW  - Exoskeletons
KW  - Sensors
KW  - Deep learning
KW  - Muscles
KW  - Training
DO  - 10.1109/ICRA.2019.8794187
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.
ER  - 

TY  - CONF
TI  - Adaptive Gait Planning for Walking Assistance Lower Limb Exoskeletons in Slope Scenarios
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5083
EP  - 5089
AU  - C. Zou
AU  - R. Huang
AU  - H. Cheng
AU  - Q. Chen
AU  - J. Qiu
PY  - 2019
KW  - adaptive control
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - pendulums
KW  - robot dynamics
KW  - adaptive gait planning approach
KW  - lower-limb walking assistance exoskeletons
KW  - human-exoskeleton system
KW  - reference foot locations
KW  - adaptive gait trajectories
KW  - level ground walking
KW  - paraplegic patients
KW  - slope terrains
KW  - stepping locations
KW  - dynamic movement primitives
KW  - 2D linear inverted pendulum model
KW  - dynamic gait generator
KW  - conventional capture point theory
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Foot
KW  - Trajectory
KW  - Adaptation models
KW  - Force
KW  - Planning
KW  - Adaptive Gait Planning
KW  - Lower-limb Exoskeleton
KW  - LIPM
KW  - Dynamic Movement Primitives
KW  - Slope
DO  - 10.1109/ICRA.2019.8793863
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Lower-limb exoskeleton has gained considerable interests in walking assistance applications for paraplegic patients. In walking assistance of paraplegic patients, the exoskeleton should have the ability to help patients to walk over different terrains in the daily life, such as slope terrains. One critical issue is how to plan the stepping locations on slopes with different gradients, and generate stable and human-like gaits for patients. This paper proposed an adaptive gait planning approach which can generate gait trajectories adapt to slopes with different gradients for lower-limb walking assistance exoskeletons. We modeled the human-exoskeleton system as a 2D Linear Inverted Pendulum Model (2D-LIPM) with an external force in the two-dimensional sagittal plane, and proposed a Dynamic Gait Generator (DGG) based on an extension of the conventional Capture Point (CP) theory and Dynamic Movement Primitives (DMPs). The proposed approach can dynamically generate reference foot locations for each step on slopes, and human-like adaptive gait trajectories can be reproduced after the learning from demonstrated trajectories that sampled from level ground walking of normal healthy human. We demonstrated the efficiency of the proposed approach on both the Gazebo simulation platform and an exoskeleton named AIDER. Experimental results indicate that the proposed approach is able to provide the ability for exoskeletons to generate appropriate gaits adapt to slopes with different gradients.
ER  - 

TY  - CONF
TI  - A Data-Driven Predictive Model of Individual-Specific Effects of FES on Human Gait Dynamics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5090
EP  - 5096
AU  - L. Drnach
AU  - J. L. Allen
AU  - I. Essa
AU  - L. H. Ting
PY  - 2019
KW  - bioelectric phenomena
KW  - gait analysis
KW  - kinematics
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - gait coordination patterns
KW  - robotic control strategies
KW  - functional electrical stimulation
KW  - gait cycle
KW  - Switched Linear Dynamical Systems
KW  - joint angles
KW  - kinematic model
KW  - SLDS predictions
KW  - SLDS dynamics matrices
KW  - gait phase information
KW  - joint angle trajectories
KW  - SLDS models
KW  - normal gait
KW  - joint angle kinematic data
KW  - data-driven gait models
KW  - electrical perturbations
KW  - mechanical perturbations
KW  - gait kinematics
KW  - gait rehabilitation robotics
KW  - human gait dynamics
KW  - individual-specific effects
KW  - data-driven predictive model
KW  - Superluminescent diodes
KW  - Legged locomotion
KW  - Kinematics
KW  - Trajectory
KW  - Predictive models
KW  - Iron
KW  - Data models
DO  - 10.1109/ICRA.2019.8794304
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modeling individual-specific gait dynamics based on kinematic data could aid development of gait rehabilitation robotics by enabling robots to predict the user's gait kinematics with and without external inputs, such as mechanical or electrical perturbations. Here we address a current limitation of data-driven gait models, which do not yet predict human gait dynamics nor responses to perturbations. We used Switched Linear Dynamical Systems (SLDS) to model joint angle kinematic data from healthy individuals walking on a treadmill during normal gait and during gait perturbed by functional electrical stimulation (FES) to the ankle muscles. Our SLDS models were able to generate joint angle trajectories in each of four gait phases, as well as across an entire gait cycle, given initial conditions and gait phase information. Because the SLDS dynamics matrices encoded significant coupling across joints that differed across indivdiuals, we compared the SLDS predictions to that of a kinematic model, where the joint angles were independent. Joint angle trajectories generated by SLDS and kinematic models were similar over time horizons of a few milliseconds, but SLDS models provided better predictions of gait kinematics over time horizons of up to a second. We also demonstrated that SLDS models can infer and predict individual-specific responses to FES during swing phase. As such, SLDS models may be a promising approach for online estimation and control of and human gait dynamics, allowing robotic control strategies to be tailored to an individual's specific gait coordination patterns.
ER  - 

TY  - CONF
TI  - The (Sensorized) Hand is Quicker than the Eye: Restoring Grasping Speed and Confidence for Amputees with Tactile Reflexes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5097
EP  - 5102
AU  - J. A. Fishel
AU  - B. Matulevich
AU  - K. A. Muller
AU  - G. M. Berke
PY  - 2019
KW  - electromyography
KW  - medical control systems
KW  - prosthetics
KW  - tactile sensors
KW  - touch (physiological)
KW  - myoelectric prosthetic hand
KW  - closing signals
KW  - open-cell self-skinning polyurethane foam
KW  - tactile reflexes
KW  - user confidence
KW  - sound side limb
KW  - rigid items
KW  - fragile items
KW  - unilateral myoelectric prosthesis users
KW  - inhibitory reflex controller
KW  - contact signal
KW  - air pressure
KW  - excessive forces
KW  - simple tactile reflex
KW  - tactile sensors
KW  - human hand dexterity
KW  - fragile objects
KW  - myoelectric prosthetic hand users
KW  - grasping speed
KW  - Electromyography
KW  - Grasping
KW  - Prosthetic hand
KW  - Task analysis
KW  - Tactile sensors
DO  - 10.1109/ICRA.2019.8793643
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Myoelectric prosthetic hand users have difficulty with, and frequently avoid, grasping fragile objects with their prosthesis. While the sense of touch is known to be critical for human hand dexterity, it has been virtually absent in prosthetic hands. In this study, a standard myoelectric prosthetic hand was modified with tactile sensors and a simple tactile reflex to inhibit excessive forces on contact. The tactile sensors were made from an open-cell self-skinning polyurethane foam that produced a detectable increase in air pressure inside the foam when contacted. This contact signal was then used by an inhibitory reflex controller which served to reduce the gain of weaker closing signals after contact but allow stronger closing signals to pass through. Four unilateral myoelectric prosthesis users completed five trials of three different timed grasping tasks with fragile and rigid items. Subjects performed each task in three different scenarios: with their sound side limb, their current myoelectric hand, and the modified prosthesis with tactile reflex. Findings demonstrated that grasping performance with fragile objects was significantly enhanced using the modified prosthesis, even nearing the performance of subject's sound side limb. Results suggest that this approach can substantially improve the speed and success of grasping fragile items, leading to improved use patterns, decreased cognitive effort, and improved user confidence.
ER  - 

TY  - CONF
TI  - Development of A Soft Power Suit for Lower Back Assistance*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5103
EP  - 5109
AU  - Z. Yao
AU  - C. Linnenberg
AU  - R. Weidner
AU  - J. Wulfsberg
PY  - 2019
KW  - actuators
KW  - bending
KW  - biomechanics
KW  - bone
KW  - kinematics
KW  - medical control systems
KW  - muscle
KW  - biomechanical study
KW  - fabric construction
KW  - twisted string actuators
KW  - mechanical stresses
KW  - lower back assistance
KW  - static forward bending
KW  - trunk flexion
KW  - bending kinematics
KW  - static bending posture
KW  - risk factor
KW  - muscle activation
KW  - lightweight design
KW  - tensile forces
KW  - force transmission
KW  - dynamic lifting
KW  - physical load
KW  - repetitive heavy lifting
KW  - occupational activities
KW  - low back pain
KW  - soft power suit
KW  - Back
KW  - Force
KW  - Muscles
KW  - Fabrics
KW  - Thigh
KW  - Hip
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794026
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mechanical stresses on the spine are a significant risk factor for low back pain, a highly prevalent health problem around the world. Certain occupational activities such as repetitive heavy lifting and static bending posture lead to high loads on the lower back. To address this problem, we are developing a soft power suit capable of reducing physical load on the lower back during dynamic lifting and static forward bending. The power suit is designed to mimic the force transmission in the body and duplicate the force generated by muscles and tendons. Two twisted string actuators (TSAs) attached to a back brace are used to generate tensile forces which assist the underlying muscles to control trunk flexion. The fabric construction and TSA enable a lightweight design of the suit: without the battery, the entire system weighs only 2.4kg. Here we present the design and implementation of the prototype system along with a preliminary biomechanical study that evaluates the effect of the system on the body. The results show that the power suit does not change the wearer's bending kinematics and helps the subject to keep the static bending posture. Moreover, using the power suit significantly reduced the muscle activation required for both static bending and dynamic lifting (50.2-54.0% and 21.4-25.2% reduction, respectively).
ER  - 

TY  - CONF
TI  - A new soft fingertip based on electroactive hydrogels
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5126
EP  - 5132
AU  - A. LÃ³pez-DÃ­az
AU  - A. MartÃ­n-Pacheco
AU  - R. FernÃ¡ndez
AU  - A. M. RodrÃ­guez
AU  - M. A. Herrero
AU  - E. VÃ¡zquez
AU  - A. S. VÃ¡zquez
PY  - 2019
KW  - control system synthesis
KW  - dexterous manipulators
KW  - hydrogels
KW  - robotic hands
KW  - aqueous solutions
KW  - fingertip applications
KW  - stiffness
KW  - electric fields
KW  - fingertip properties
KW  - electroactive hydrogels
KW  - active soft fingertip
KW  - Ions
KW  - Grasping
KW  - Electrodes
KW  - Mathematical model
KW  - Soft robotics
KW  - Polymers
DO  - 10.1109/ICRA.2019.8794105
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present the design and application of an active soft fingertip for robotic hands. This fingertip is based on a new type of hydrogel which has been designed with the purpose of overcoming some of the major drawbacks of previous hydrogels such as the dependency of aqueous solutions. Fingertip applications benefit from the changes of stiffness and volume which take place in our hydrogel when electric fields are applied. Theoretical modeling and experimental verification of the fingertip properties are presented in this work, showing its potential usability in grasping and manipulation tasks.
ER  - 

TY  - CONF
TI  - Open Loop Position Control of Soft Continuum Arm Using Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5133
EP  - 5139
AU  - S. Satheeshbabu
AU  - N. K. Uppalapati
AU  - G. Chowdhary
AU  - G. Krishnan
PY  - 2019
KW  - bending
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - neural nets
KW  - numerical analysis
KW  - pneumatic actuators
KW  - position control
KW  - torsion
KW  - open loop position control
KW  - deep reinforcement learning
KW  - soft robots
KW  - nonlinear spatial deformations
KW  - inherent actuation
KW  - numerical models
KW  - soft spatial continuum arm
KW  - unidirectional bending deformation
KW  - bidirectional torsional deformation
KW  - Deep-Q Learning
KW  - continuum arm prototype
KW  - external loading conditions
KW  - Manipulators
KW  - Load modeling
KW  - Mathematical model
KW  - Numerical models
KW  - Strain
DO  - 10.1109/ICRA.2019.8793653
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots undergo large nonlinear spatial deformations due to both inherent actuation and external loading. The physics underlying these deformations is complex, and often requires intricate analytical and numerical models. The complexity of these models may render traditional model-based control difficult and unsuitable. Model-free methods offer an alternative for analyzing the behavior of such complex systems without the need for elaborate modeling techniques. In this paper, we present a model-free approach for open loop position control of a soft spatial continuum arm, based on deep reinforcement learning. The continuum arm is pneumatically actuated and attains a spatial work-space by a combination of unidirectional bending and bidirectional torsional deformation. We use Deep-Q Learning with experience replay to train the system in simulation. The efficacy and robustness of the control policy obtained from the system is validated both in simulation and on the continuum arm prototype for varying external loading conditions.
ER  - 

TY  - CONF
TI  - Fast Motion Planning for High-DOF Robot Systems Using Hierarchical System Identification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5140
EP  - 5147
AU  - B. Jia
AU  - Z. Pan
AU  - D. Manocha
PY  - 2019
KW  - actuators
KW  - elasticity
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - motion control
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - reinforcement-learning-based feedback control
KW  - underwater swimming robot
KW  - line-actuated elastic robot arm
KW  - optimization-based motion planning
KW  - hierarchical adaptive grid
KW  - forward dynamics
KW  - articulated robots
KW  - soft robots
KW  - hierarchical system identification
KW  - high-DOF robot systems
KW  - fast motion planning
KW  - Dynamics
KW  - Planning
KW  - Heuristic algorithms
KW  - Soft robotics
KW  - Finite element analysis
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793814
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an efficient algorithm for motion planning and controlling a robot system with a high number of degrees-of-freedom (DOF). These systems include high-DOF soft robots and articulated robots interacting with a deformable environment. We present a novel technique to accelerate the evaluations of the forward dynamics function by storing the results of costly computations in a hierarchical adaptive grid. Furthermore, we exploit the underactuated properties of the robot systems and build the grid in a low-dimensional space. Our approach approximates the forward dynamics function with guaranteed error bounds and can be used in optimization-based motion planning and reinforcement-learning-based feed-back control. We highlight the performance on two high-DOF robot systems: a line-actuated elastic robot arm and an underwater swimming robot in water. Compared to prior techniques based on exact dynamics evaluation, we observe one to two orders of magnitude improvement in the performance.
ER  - 

TY  - CONF
TI  - Resilient Task Planning and Execution for Reactive Soft Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5148
EP  - 5154
AU  - S. Hamill
AU  - J. Whitehead
AU  - P. Ferenz
AU  - R. F. Shepherd
AU  - H. Kress-Gazit
PY  - 2019
KW  - control system synthesis
KW  - legged locomotion
KW  - temporal logic
KW  - physical soft robot
KW  - reactive soft robots
KW  - compliant materials
KW  - rigid bodied systems
KW  - soft actuator fabrication methods
KW  - multigait walking soft robots
KW  - soft materials
KW  - resilient task planning
KW  - reactive controllers
KW  - formal synthesis
KW  - sensing-based abstraction
KW  - linear temporal logic
KW  - Actuators
KW  - Legged locomotion
KW  - Soft robotics
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794303
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots utilize compliant materials to perform motions and behaviors not typically achievable by rigid bodied systems. These materials and soft actuator fabrication methods have been leveraged to create multigait walking soft robots. However, soft materials are prone to failure, restricting the ability of soft robots to accomplish tasks. In this work we address the problem of generating reactive controllers for multigait walking soft robots that are resilient to actuator failure by applying methods of formal synthesis. We present a sensing-based abstraction for actuator performance, provide a framework for encoding multigait behavior and actuator failure in Linear Temporal Logic (LTL), and demonstrate synthesized controllers on a physical soft robot.
ER  - 

TY  - CONF
TI  - Dynamic morphological computation through damping design of soft material robots: application to under-actuated grippers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5155
EP  - 5161
AU  - A. D. Lallo
AU  - M. Catalano
AU  - M. Garabini
AU  - G. Grioli
AU  - M. Gabiccini
AU  - A. Bicchi
PY  - 2019
KW  - bending
KW  - damping
KW  - design engineering
KW  - dexterous manipulators
KW  - elasticity
KW  - granular materials
KW  - grippers
KW  - pneumatic actuators
KW  - pneumatic systems
KW  - granular material
KW  - bending actuators
KW  - dynamic morphological computation
KW  - damping design
KW  - soft material robots
KW  - under-actuated grippers
KW  - multichamber pneumatic systems
KW  - mechanical parameters
KW  - stiffness system
KW  - viscous oil
KW  - immersion
KW  - deformation pattern
KW  - Damping
KW  - Strain
KW  - Oils
KW  - Viscosity
KW  - Robots
KW  - Pneumatic systems
KW  - Actuators
DO  - 10.1109/ICRA.2019.8793987
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This article presents the design of soft material robots with tunable damping properties. This study derives from the investigation of an under-actuated dynamic approach involving multi-chamber pneumatic systems. The co-design of the mechanical parameters (stiffness and damping) of the system along with the time profile of the input allows to obtain different behaviors using a reduced number of feeding line. In this work we analyze via simulations and experiments several approaches to tune the damping of soft robots. The most effective solution employs a layer of granular material immersed in viscous oil within the chamber wall. This method has been employed to realize bending actuators with a continuous deformation pattern. Finally, we show an application involving a two-fingered gripper fed by a single pneumatic line, which is able to perform pinch and power grasp.
ER  - 

TY  - CONF
TI  - Augmented Reality Assisted Instrument Insertion and Tool Manipulation for the First Assistant in Robotic Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5173
EP  - 5179
AU  - L. Qian
AU  - A. Deguet
AU  - Z. Wang
AU  - Y. Liu
AU  - P. Kazanzides
PY  - 2019
KW  - augmented reality
KW  - helmet mounted displays
KW  - mean square error methods
KW  - medical robotics
KW  - robot vision
KW  - surgery
KW  - telerobotics
KW  - hand-eye configurations
KW  - root-mean-square path deviation
KW  - novice assistants
KW  - hand-eye coordination
KW  - tool manipulation time
KW  - navigation time
KW  - experienced surgeons
KW  - head-mounted display
KW  - augmented reality application
KW  - ARssist
KW  - hand-held tools
KW  - FA
KW  - robotic-assisted laparoscopic surgery
KW  - first assistant
KW  - augmented reality assisted instrument insertion
KW  - Instruments
KW  - Endoscopes
KW  - Surgery
KW  - Robot kinematics
KW  - Tools
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794263
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In robotic-assisted laparoscopic surgery, the first assistant (FA) stands at the bedside assisting the intervention, while the surgeon sits at the console teleoperating the robot. Tasks for the FA include navigating new instruments into the surgeon's field-of-view and passing in or retracting materials from the body using hand-held tools. We previously developed ARssist, an augmented reality application based on an optical see-through head-mounted display, to aid the FA. In this paper, we refine the system and first perform a pilot study with three experienced surgeons for two specific tasks: instrument insertion and tool manipulation. The results suggest that ARssist would be especially useful for less experienced assistants and for difficult hand-eye configurations. We then perform a multi-user study with inexperienced subjects. The results show that ARssist can reduce navigation time by 34.57%, enhance insertion path consistency by 41.74%, reduce root-mean-square path deviation by 40.04%, and reduce tool manipulation time by 72.25%. Thus, ARssist has the potential to improve efficiency, safety and hand-eye coordination, especially for novice assistants.
ER  - 

TY  - CONF
TI  - High-Fidelity Grasping in Virtual Reality using a Glove-based System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5180
EP  - 5186
AU  - H. Liu
AU  - Z. Zhang
AU  - X. Xie
AU  - Y. Zhu
AU  - Y. Liu
AU  - Y. Wang
AU  - S. Zhu
PY  - 2019
KW  - computational geometry
KW  - computer simulation
KW  - data gloves
KW  - haptic interfaces
KW  - human computer interaction
KW  - manipulators
KW  - object tracking
KW  - virtual reality
KW  - physics-based simulation
KW  - haptic feedback
KW  - glove-based design
KW  - collision geometry
KW  - Vive Tracker
KW  - high-fidelity grasping
KW  - virtual objects
KW  - caging-based approach
KW  - virtual environments
KW  - virtual object manipulation
KW  - high-fidelity hand
KW  - VR
KW  - Virtual Reality
KW  - real-time stable grasps
KW  - hand localization
KW  - glove-based system
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Vibrations
KW  - Real-time systems
KW  - Hardware
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794230
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a design that jointly provides hand pose sensing, hand localization, and haptic feedback to facilitate real-time stable grasps in Virtual Reality (VR). The design is based on an easy-to-replicate glove-based system that can reliably perform (i) a high-fidelity hand pose sensing in real time through a network of 15 IMUs, and (ii) the hand localization using a Vive Tracker. The supported physics-based simulation in VR is capable of detecting collisions and contact points for virtual object manipulation, which drives the collision event to trigger the physical vibration motors on the glove to signal the user, providing a better realism inside virtual environments. A caging-based approach using collision geometry is integrated to determine whether a grasp is stable. In the experiment, we showcase successful grasps of virtual objects with large geometry variations. Comparing to the popular LeapMotion sensor, we demonstrate the proposed glove-based design yields a higher success rate in various tasks in VR. We hope such a glove-based system can simplify the data collection of human manipulations with VR.
ER  - 

TY  - CONF
TI  - On the role of wearable haptics for force feedback in teleimpedance control for dual-arm robotic teleoperation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5187
EP  - 5193
AU  - J. P. Clark
AU  - G. Lentini
AU  - F. Barontini
AU  - M. G. Catalano
AU  - M. Bianchi
AU  - M. K. OâMalley
PY  - 2019
KW  - dexterous manipulators
KW  - force feedback
KW  - haptic interfaces
KW  - telerobotics
KW  - haptic sensation
KW  - wearable haptic devices
KW  - wearable haptics
KW  - force feedback
KW  - teleimpedance control
KW  - dual-arm robotic teleoperation
KW  - box placement task
KW  - higher mean interaction forces
KW  - wearable haptic feedback
KW  - safely complete exploratory procedures
KW  - deep sea exploration
KW  - haptic interactions
KW  - dual arm robotic coordination
KW  - Task analysis
KW  - Force feedback
KW  - Force
KW  - Manipulators
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793652
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic teleoperation enables humans to safely complete exploratory procedures in remote locations for applications such as deep sea exploration or building assessments following natural disasters. Successful task completion requires meaningful dual arm robotic coordination and proper understanding of the environment. While these capabilities are inherent to humans via impedance regulation and haptic interactions, they can be challenging to achieve in telerobotic systems. Teleimpedance control has allowed impedance regulation in such applications, and bilateral teleoperation systems aim to restore haptic sensation to the operator, though often at the expense of stability or workspace size. Wearable haptic devices have the potential to apprise the operator of key forces during task completion while maintaining stability and transparency. In this paper, we evaluate the impact of wearable haptics for force feedback in teleimpedance control for dual-arm robotic teleoperation. Participants completed a peg-in-hole, box placement task, aiming to seat as many boxes as possible within the trial period. Experiments were conducted both transparent and opaque boxes. With the opaque box, participants achieved a higher number of successful placements with haptic feedback, and we saw higher mean interaction forces. Results suggest that the provision of wearable haptic feedback may increase confidence when visual cues are obscured.
ER  - 

TY  - CONF
TI  - CNN-SVO: Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5218
EP  - 5223
AU  - S. Y. Loo
AU  - A. J. Amiri
AU  - S. Mashohor
AU  - S. H. Tang
AU  - H. Zhang
PY  - 2019
KW  - feature extraction
KW  - motion estimation
KW  - probability
KW  - SLAM (robots)
KW  - SVO mapping results
KW  - frame rate camera motion estimation
KW  - map points
KW  - initialized map point
KW  - depth uncertainty
KW  - single-image depth prediction network
KW  - feature location
KW  - probabilistic mapping method
KW  - direct pixel correspondence
KW  - semidirect visual odometry
KW  - V-SLAM algorithms
KW  - visual simultaneous localization
KW  - Uncertainty
KW  - Cameras
KW  - Visual odometry
KW  - Feature extraction
KW  - Reliability
KW  - Estimation
KW  - Motion estimation
DO  - 10.1109/ICRA.2019.8794425
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reliable feature correspondence between frames is a critical step in visual odometry (VO) and visual simultaneous localization and mapping (V-SLAM) algorithms. In comparison with existing VO and V-SLAM algorithms, semi-direct visual odometry (SVO) has two main advantages that lead to state-of-the-art frame rate camera motion estimation: direct pixel correspondence and efficient implementation of probabilistic mapping method. This paper improves the SVO mapping by initializing the mean and the variance of the depth at a feature location according to the depth prediction from a single-image depth prediction network. By significantly reducing the depth uncertainty of the initialized map point (i.e., small variance centred about the depth prediction), the benefits are twofold: reliable feature correspondence between views and fast convergence to the true depth in order to create new map points. We evaluate our method with two outdoor datasets: KITTI dataset and Oxford Robotcar dataset. The experimental results indicate that improved SVO mapping results in increased robustness and camera tracking accuracy. The implementation of this work is available at https: //github.com/yan99033/CNN-SVO.
ER  - 

TY  - CONF
TI  - A Unified Framework for Mutual Improvement of SLAM and Semantic Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5224
EP  - 5230
AU  - K. Wang
AU  - Y. Lin
AU  - L. Wang
AU  - L. Han
AU  - M. Hua
AU  - X. Wang
AU  - S. Lian
AU  - B. Huang
PY  - 2019
KW  - image motion analysis
KW  - image segmentation
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - segmentation algorithms
KW  - semantic segmentation
KW  - robotics
KW  - refined 3D pose information
KW  - vision-based tasks
KW  - mutual improvement
KW  - unified framework
KW  - instantaneous motion change handling
KW  - long-term changes
KW  - simultaneous localization and segmentation
KW  - Image segmentation
KW  - Task analysis
KW  - Robot sensing systems
KW  - Motion segmentation
KW  - Feature extraction
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793499
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel framework for simultaneously implementing localization and segmentation, which are two of the most important vision-based tasks for robotics. While the goals and techniques used for them were considered to be different previously, we show that by making use of the intermediate results of the two modules, their performance can be enhanced at the same time. Our framework is able to handle both the instantaneous motion and long-term changes of instances in localization with the help of the segmentation result, which also benefits from the refined 3D pose information. We conduct experiments on various datasets, and prove that our framework works effectively on improving the precision and robustness of the two tasks and outperforms existing localization and segmentation algorithms.
ER  - 

TY  - CONF
TI  - MID-Fusion: Octree-based Object-Level Multi-Instance Dynamic SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5231
EP  - 5237
AU  - B. Xu
AU  - W. Li
AU  - D. Tzoumanikas
AU  - M. Bloesch
AU  - A. Davison
AU  - S. Leutenegger
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image motion analysis
KW  - image segmentation
KW  - image sequences
KW  - object detection
KW  - object tracking
KW  - octrees
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - robustly track
KW  - foreground object probabilities
KW  - object model
KW  - object-level dynamic volumetric map
KW  - instance segmentation part
KW  - octree-based object-level multiinstance dynamic SLAM
KW  - multiinstance dynamic RGB-D SLAM system
KW  - robust camera tracking
KW  - geometric motion properties
KW  - geometric motion information
KW  - object-oriented tracking method
KW  - camera pose estimation
KW  - semantic motion properties
KW  - frequency 2.0 Hz to 3.0 Hz
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Tracking
KW  - Motion segmentation
KW  - Semantics
KW  - Dynamics
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8794371
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a new multi-instance dynamic RGB-D SLAM system using an object-level octree-based volumetric representation. It can provide robust camera tracking in dynamic environments and at the same time, continuously estimate geometric, semantic, and motion properties for arbitrary objects in the scene. For each incoming frame, we perform instance segmentation to detect objects and refine mask boundaries using geometric and motion information. Meanwhile, we estimate the pose of each existing moving object using an object-oriented tracking method and robustly track the camera pose against the static scene. Based on the estimated camera pose and object poses, we associate segmented masks with existing models and incrementally fuse corresponding colour, depth, semantic, and foreground object probabilities into each object model. In contrast to existing approaches, our system is the first system to generate an object-level dynamic volumetric map from a single RGB-D camera, which can be used directly for robotic tasks. Our method can run at 2-3 Hz on a CPU, excluding the instance segmentation part. We demonstrate its effectiveness by quantitatively and qualitatively testing it on both synthetic and real-world sequences.
ER  - 

TY  - CONF
TI  - Surfel-Based Dense RGB-D Reconstruction With Global And Local Consistency
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5238
EP  - 5244
AU  - Y. Yang
AU  - W. Dong
AU  - M. Kaess
PY  - 2019
KW  - computer vision
KW  - image colour analysis
KW  - image reconstruction
KW  - optimisation
KW  - pose estimation
KW  - surfel-based dense RGB-D reconstruction
KW  - local consistency
KW  - high surface reconstruction accuracy
KW  - dense mapping
KW  - vision communities
KW  - robotics literature
KW  - RGB-D cameras
KW  - dense map
KW  - depth input
KW  - accurate local pose estimation
KW  - locally consistent model
KW  - pose tracking
KW  - offline computer vision methods
KW  - structure-from-motion
KW  - multiview stereo
KW  - batch optimization
KW  - global consistency
KW  - heavy computation loads
KW  - consistent reconstruction
KW  - offline SfM pipeline
KW  - strong global constraints
KW  - off-the-shelf SLAM systems
KW  - high local accuracy
KW  - factor graph optimization
KW  - accurate camera
KW  - dense reconstruction
KW  - dense SLAM systems
KW  - SfM-MVS pipelines
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Pose estimation
KW  - Image reconstruction
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794355
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Achieving high surface reconstruction accuracy in dense mapping has been a desirable target for both robotics and vision communities. In the robotics literature, simultaneous localization and mapping (SLAM) systems use RGB-D cameras to reconstruct a dense map of the environment. They leverage the depth input to provide accurate local pose estimation and a locally consistent model. However, drift in the pose tracking over time leads to misalignments and artifacts. On the other hand, offline computer vision methods, such as the pipeline that combines structure-from-motion (SfM) and multi-view stereo (MVS), estimate the camera poses by performing batch optimization. These methods achieve global consistency, but suffer from heavy computation loads. We propose a novel approach that integrates both methods to achieve locally and globally consistent reconstruction. First, we estimate poses of keyframes in the offline SfM pipeline to provide strong global constraints at relatively low cost. Afterwards, we compute odometry between frames driven by off-the-shelf SLAM systems with high local accuracy. We fuse the two pose estimations using factor graph optimization to generate accurate camera poses for dense reconstruction. Experiments on real-world and synthetic datasets demonstrate that our approach produces more accurate models comparing to existing dense SLAM systems, while achieving significant speedup with respect to state-of-the-art SfM-MVS pipelines.
ER  - 

TY  - CONF
TI  - A-SLAM: Human in-the-loop Augmented SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5245
EP  - 5251
AU  - A. Sidaoui
AU  - M. K. Zein
AU  - I. H. Elhajj
AU  - D. Asmar
PY  - 2019
KW  - augmented reality
KW  - human-robot interaction
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - real-time systems
KW  - SLAM (robots)
KW  - telerobotics
KW  - A-SLAM
KW  - map editing
KW  - navigation-forbidden areas
KW  - navigation goals
KW  - SLAM algorithm
KW  - occupancy grid maps
KW  - human in-the-loop augmented SLAM
KW  - real environment representation
KW  - Microsoft HoloLens
KW  - robot teleoperation
KW  - pose correction
KW  - map correction
KW  - AR interface
KW  - Simultaneous localization and mapping
KW  - Navigation
KW  - Collaboration
KW  - Three-dimensional displays
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793539
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we are proposing an intuitive Augmented SLAM method (A-SLAM) that allows the user to interact, in real-time, with a robot running SLAM to correct for pose and map errors. We built an AR application that works on HoloLens and allows the operator to view the robot's map superposed on the physical environment and edit it. Through map editing, the operator can account for errors affecting real environment's representation by adding navigation-forbidden areas to the map in addition to the ability to correct errors affecting the localization. The proposed system allows the operator to edit the robot's pose (based on SLAM request) and can be extended to sending navigation goals to the robot, viewing the planned path to evaluate it before execution, and teleoperating the robot. The proposed solution could be applied on any 2D-based SLAM algorithm and can easily be extended to 3D SLAM techniques. We validated our system through experimentation on pose correction and map editing. Experiments demonstrated that through A-SLAM, SLAM runtime is cut to half, post-processing of maps is totally eliminated, and high quality occupancy grid maps could be achieved with minimal added computational and hardware costs.
ER  - 

TY  - CONF
TI  - Balance Map Analysis as a Measure of Walking Balance Based on Pendulum-Like Leg Movements
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5260
EP  - 5265
AU  - T. Kagawa
PY  - 2019
KW  - legged locomotion
KW  - linearisation techniques
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - state-space methods
KW  - balance map analysis
KW  - pendulum-like leg movements
KW  - swing legs
KW  - inverted pendulum
KW  - simple pendulum
KW  - linearization
KW  - nondimensionalization
KW  - compass gait model
KW  - energy ratio
KW  - phase difference
KW  - stance leg
KW  - swing leg
KW  - orbital energy conservation
KW  - step transition
KW  - balance loss
KW  - state space
KW  - reachability
KW  - walking balance
KW  - Legged locomotion
KW  - Trajectory
KW  - Orbits
KW  - Mathematical model
KW  - Compass
KW  - Computational modeling
KW  - Computer simulation
DO  - 10.1109/ICRA.2019.8793651
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes an analysis of walking balance in terms of movements of stance and swing legs based on an inverted pendulum and a simple pendulum. Linearization, decoupling, and non-dimensionalization of a compass gait model enable to characterize the relationship of the trajectories between the stance and swing legs by only two parameters (energy ratio and phase difference). The energy ratio is defined by the ratio of the orbital energy between the pendulums. The phase difference represents the position of the stance leg in relation to the swing leg. This study considers an orbital energy conservation of a step transition and analyzes reachability of a desirable touchdown condition. If the time evolution from a current state is not reachable to the desired touchdown region, the state is labeled as a state in balance loss. By analyzing the reachability limits of the energy ratio and phase difference, we illustrate the balance loss and safe regions on the state space of the inverted pendulum, which is termed as balance map. We examined the effects of the simplification and linearization of the compass gait model by using computer simulations. Through the simulations of walking with perturbations, we confirmed that the balance map analysis could predict a future fall in an early phase for even trajectories derived by the nonlinear model.
ER  - 

TY  - CONF
TI  - Non-parametric Imitation Learning of Robot Motor Skills
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5266
EP  - 5272
AU  - Y. Huang
AU  - L. Rozo
AU  - J. SilvÃ©rio
AU  - D. G. Caldwell
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonparametric imitation learning
KW  - robot motor skills
KW  - learning capabilities
KW  - learning approach
KW  - kernel treatment
KW  - human skills
KW  - correlation-adaptive imitation learning
KW  - collaborative task
KW  - Trajectory
KW  - Robots
KW  - Task analysis
KW  - Probabilistic logic
KW  - Kernel
KW  - Databases
KW  - Correlation
DO  - 10.1109/ICRA.2019.8794267
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unstructured environments impose several challenges when robots are required to perform different tasks and adapt to unseen situations. In this context, a relevant problem arises: how can robots learn to perform various tasks and adapt to different conditions? A potential solution is to endow robots with learning capabilities. In this line, imitation learning emerges as an intuitive way to teach robots different motor skills. This learning approach typically mimics human demonstrations by extracting invariant motion patterns and subsequently applies these patterns to new situations. In this paper, we propose a novel kernel treatment of imitation learning, which endows the robot with imitative and adaptive capabilities. In particular, due to the kernel treatment, the proposed approach is capable of learning human skills associated with high-dimensional inputs. Furthermore, we study a new concept of correlation-adaptive imitation learning, which allows for the adaptation of correlations exhibited in high-dimensional demonstrated skills. Several toy examples and a collaborative task with a real robot are provided to verify the effectiveness of our approach.
ER  - 

TY  - CONF
TI  - Dynamic Stepping on Unknown Obstacles With Upper-Body Compliance and Angular Momentum Damping From the Reaction Null-Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5273
EP  - 5279
AU  - Y. Hidaka
AU  - K. Nishizawa
AU  - D. N. Nenchev
PY  - 2019
KW  - acceleration control
KW  - angular momentum
KW  - damping
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - stability
KW  - short time interval
KW  - reaction null-space
KW  - stepping time
KW  - general whole-body controller
KW  - relative angular acceleration control component
KW  - angular momentum damping
KW  - dynamic stepping
KW  - unknown obstacles
KW  - upper-body compliance
KW  - robot steps
KW  - unknown height
KW  - RNS
KW  - iterative optimization
KW  - simulated dynamic stepping
KW  - Acceleration
KW  - Robots
KW  - Optimization
KW  - Damping
KW  - Dynamics
KW  - Task analysis
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793832
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Contact destabilization after an impact that occurs at high-speed, e.g. when a robot steps on an obstacle of unknown height, can be tackled by injecting angular momentum damping for a short time interval immediately after the impact. This is done by making use of the motion from within the reaction null-space (RNS). The angular momentum damping results in an appropriate arm motion that stabilizes the contacts. An impact at high-speed occurs when the stepping time is very short. In this case, conventional controllers cannot handle the reaction stemming from the swing leg dynamics. A general whole-body controller is designed that makes use of the relative angular acceleration control component to inject the angular momentum damping. The proposed control method is robust; it can deal with obstacles of various height and inclination without altering the feedback gains. The controller is fast since iterative optimization is avoided. The performance is examined via a simulated dynamic stepping.
ER  - 

TY  - CONF
TI  - Efficient Humanoid Contact Planning using Learned Centroidal Dynamics Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5280
EP  - 5286
AU  - Y. Lin
AU  - B. Ponton
AU  - L. Righetti
AU  - D. Berenson
PY  - 2019
KW  - computational complexity
KW  - convex programming
KW  - humanoid robots
KW  - integer programming
KW  - legged locomotion
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot dynamics
KW  - learned centroidal dynamics prediction
KW  - humanoid robots
KW  - intermittent contact
KW  - contact sequence
KW  - quasistatic balance criterion
KW  - dynamic motions
KW  - efficient mixed integer convex programming solvers
KW  - dynamic contact sequences
KW  - short time horizon contact sequences
KW  - dynamic evolution
KW  - robot centroidal momenta
KW  - dynamically robust contact sequences
KW  - search-based contact planner
KW  - humanoid contact planning
KW  - Dynamics
KW  - Planning
KW  - End effectors
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794032
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humanoid robots dynamically navigate an environment by interacting with it via contact wrenches exerted at intermittent contact poses. Therefore, it is important to consider dynamics when planning a contact sequence. Traditional contact planning approaches assume a quasi-static balance criterion to reduce the computational challenges of selecting a contact sequence over a rough terrain. This however limits the applicability of the approach when dynamic motions are required, such as when walking down a steep slope or crossing a wide gap. Recent methods overcome this limitation with the help of efficient mixed integer convex programming solvers capable of synthesizing dynamic contact sequences. Nevertheless, its exponential-time complexity limits its applicability to short time horizon contact sequences within small environments. In this paper, we go beyond current approaches by learning a prediction of the dynamic evolution of the robot centroidal momenta, which can then be used for quickly generating dynamically robust contact sequences for robots with arms and legs using a search-based contact planner. We demonstrate the efficiency and quality of the results of the proposed approach in a set of dynamically challenging scenarios.
ER  - 

TY  - CONF
TI  - Scalable Closed-Form Trajectories for Periodic and Non-Periodic Human-Like Walking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5295
EP  - 5301
AU  - S. Faraji
AU  - A. J. Ijspeert
PY  - 2019
KW  - gait analysis
KW  - medical control systems
KW  - optimal control
KW  - trajectory control
KW  - humanoid robots
KW  - linear simplified model
KW  - nonperiodic walking
KW  - lower-limb trajectories
KW  - closed-form trajectories
KW  - torso style
KW  - body mass
KW  - gait parameters
KW  - body properties
KW  - walking gaits
KW  - numerical optimization
KW  - geometric variables
KW  - kinematic conversion
KW  - stabilization
KW  - gait generation
KW  - footstep locations
KW  - optimal time-projecting controller
KW  - Legged locomotion
KW  - Trajectory
KW  - Pelvis
KW  - Foot
KW  - Kinematics
KW  - Torso
KW  - Knee
DO  - 10.1109/ICRA.2019.8793877
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a new framework to generate human-like lower-limb trajectories in periodic and non-periodic walking. In our method, walking dynamics is encoded in 3LP, a linear simplified model composed of three pendulums to simulate falling, swing, and torso balancing dynamics. To stabilize the motion, we use an optimal time-projecting controller which suggests new footstep locations. On top of gait generation and stabilization in the simplified space, we introduce a kinematic conversion that synthesizes more humanlike trajectories by combining geometric variables of the 3LP model adaptively. Without any tuning, numerical optimization or off-line data, our walking gaits are scalable with respect to body properties and gait parameters. We can change body mass and height, walking direction, speed, frequency, double support time, torso style, ground clearance, and terrain inclinations. We can also simulate constant external dragging forces or momentary perturbations. The proposed framework offers closed-form solutions with simulation speeds orders of magnitude faster than real time. This can be used for video games and animations on portable electronic devices with limited power. It also gives insights for generation of more human-like walking gaits on humanoid robots.
ER  - 

TY  - CONF
TI  - Flying STAR, a Hybrid Crawling and Flying Sprawl Tuned Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5302
EP  - 5308
AU  - N. Meiri
AU  - D. Zarrouk
PY  - 2019
KW  - control engineering computing
KW  - helicopters
KW  - legged locomotion
KW  - mobile robots
KW  - path planning
KW  - three-dimensional printing
KW  - Flying STAR
KW  - hybrid crawling
KW  - reconfigurable hybrid
KW  - quadcopter robot
KW  - STAR robots
KW  - sprawling mechanism
KW  - propellers
KW  - FSTAR robot
KW  - experimental robot
KW  - flying modes
KW  - flying sprawl tuned robot
KW  - running modes
KW  - 3D printed prototype
KW  - Mobile robots
KW  - Wheels
KW  - Servomotors
KW  - Propellers
KW  - Torque
KW  - Force
KW  - Crawling Robot
KW  - Flying Robot
KW  - Mechanical Design
KW  - Reconfigurable Robot
KW  - Sprawl Tuning
DO  - 10.1109/ICRA.2019.8794260
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents Flying STAR (FSTAR) a reconfigurable hybrid flying quadcopter robot. FSTAR is the latest in the family of the STAR robots fitted with a sprawling mechanism and propellers allowing it to both run and fly using the same motors. The combined capabilities of running and flying allows FSTAR to fly over obstacles or run underneath them and move inside pipes. The robot can reduce its width to crawl in confined spaces or underneath obstacles while touching the ground. We first describe the design of the robot and the configuration of the wheels and propellers in the flying and running modes. Then we present the 3D printed prototype of the FSTAR robot which we used for our experiments. We evaluate the energy requirements of the robot and the forces it can generate. The experimental robot can fly like an ordinary quadcopter but can also run on the ground at a speed of up to 2.6 m/s to save energy (see video).
ER  - 

TY  - CONF
TI  - Autonomous Cooperative Flight of Rigidly Attached Quadcopters
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5309
EP  - 5315
AU  - D. G. MorÃ­n
AU  - J. Araujo
AU  - S. Tayamon
AU  - L. A. A. Andersson
PY  - 2019
KW  - adaptive control
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - parameter estimation
KW  - quadcopter inertial measurement units
KW  - IMU
KW  - plug and play assembly
KW  - reinforcement learning
KW  - quadcopters stable operation
KW  - autonomous flight
KW  - controller parameters
KW  - adaptive controller architecture
KW  - estimated physical attachment
KW  - short online experiments
KW  - physical structure
KW  - automatic control
KW  - online parameter estimation
KW  - rigidly attached quadcopters
KW  - autonomous cooperative flight
KW  - Propellers
KW  - Estimation
KW  - Acceleration
KW  - Parameter estimation
KW  - Adaptation models
KW  - Force
KW  - Measurement units
DO  - 10.1109/ICRA.2019.8794266
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a method for online parameter estimation and automatic control of a system of rigidly attached quadcopters is introduced. First, the method performs an estimation of the physical structure attaching the quadcopters by relying solely on information from the quadcopters' Inertial Measurement Units (IMU). This information is obtained via simple and short online experiments, allowing their plug and play assembly without any human intervention. Then, given the estimated physical attachment's parameters, a stable operation of the quadcopters is achieved via an adaptive controller architecture, where the controller parameters are obtained using Reinforcement Learning. Finally, experimental results validate the proposed method, showing that a correct estimation of the physical structure is obtained allowing the autonomous flight of a pair of attached quadcopters.
ER  - 

TY  - CONF
TI  - Energy Optimal Control Allocation in a Redundantly Actuated Omnidirectional UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5316
EP  - 5322
AU  - E. Dyer
AU  - S. Sirouspour
AU  - M. Jafarinasab
PY  - 2019
KW  - autonomous aerial vehicles
KW  - convex programming
KW  - motion control
KW  - optimal control
KW  - propellers
KW  - trajectory control
KW  - energy optimal control allocation
KW  - redundantly actuated omnidirectional UAV
KW  - actuation model
KW  - control allocation strategy
KW  - redundantly-actuated multirotor unmanned aerial vehicle
KW  - omnicopter
KW  - actuation redundancy
KW  - inverse actuator model
KW  - propeller airflows
KW  - convex constrained optimization problem
KW  - propellers thrusts
KW  - propeller thrust limits
KW  - underactuated multirotors
KW  - motion trajectories
KW  - Propellers
KW  - Actuators
KW  - Atmospheric modeling
KW  - Aerodynamics
KW  - Pulse width modulation
KW  - Resource management
DO  - 10.1109/ICRA.2019.8793549
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel actuation model and control allocation strategy for a redundantly-actuated multirotor unmanned aerial vehicle (UAV), referred to as the omnicopter. With an unconventional configuration, the omnicopter's eight propellers are able to produce all the six components of net force/torque, with two degrees of actuation redundancy. This enables the vehicle to execute motion trajectories unattainable with conventional underactuated multi-rotors. A new inverse actuator model is proposed that accounts for the significant interactions between propeller airflows by relating their output thrust forces to their input motor commands. Actuation redundancy is resolved by solving a convex constrained optimization problem. Its solution yields the most power efficient set of propellers thrusts that would produce a required net force/torque, while respecting the propeller thrust limits. When the required force/torque is infeasible due to the thrust limits, the solution would minimize the norm of the error between the desired and actual net force/torque vectors. Experimental results demonstrate the effectiveness of the proposed model and control allocation strategy.
ER  - 

TY  - CONF
TI  - Development of SAM: cable-Suspended Aerial Manipulator*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5323
EP  - 5329
AU  - Y. S. Sarkisov
AU  - M. J. Kim
AU  - D. Bicego
AU  - D. Tsetserukou
AU  - C. Ott
AU  - A. Franchi
AU  - K. Kondak
PY  - 2019
KW  - actuators
KW  - aerospace robotics
KW  - cables (mechanical)
KW  - collision avoidance
KW  - control system synthesis
KW  - manipulators
KW  - stability
KW  - SAM
KW  - rotor blades
KW  - robotic manipulator
KW  - aerial carrier
KW  - actuation systems
KW  - suspended aerial manipulator
KW  - collision risk
KW  - winches
KW  - propulsion units
KW  - Manipulators
KW  - Winches
KW  - Legged locomotion
KW  - Propellers
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793592
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High risk of a collision between rotor blades and the obstacles in a complex environment imposes restrictions on the aerial manipulators. To solve this issue, a novel system cable-Suspended Aerial Manipulator (SAM) is presented in this paper. Instead of attaching a robotic manipulator directly to an aerial carrier, it is mounted on an active platform which is suspended on the carrier by means of a cable. As a result, higher safety can be achieved because the aerial carrier can keep a distance from the obstacles. For self-stabilization, the SAM is equipped with two actuation systems: winches and propulsion units. This paper presents an overview of the SAM including the concept behind, hardware realization, control strategy, and the first experimental results.
ER  - 

TY  - CONF
TI  - The Phoenix Drone: An Open-Source Dual-Rotor Tail-Sitter Platform for Research and Education
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5330
EP  - 5336
AU  - Y. Wu
AU  - X. Du
AU  - R. Duivenvoorden
AU  - J. Kelly
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - educational robots
KW  - helicopters
KW  - microrobots
KW  - mobile robots
KW  - rotors
KW  - educational purposes
KW  - design methodology
KW  - open-source Phoenix reference design
KW  - software design
KW  - Phoenix drone
KW  - open-source dual-rotor tail-sitter platform
KW  - open-source tail-sitter microaerial vehicle platform
KW  - dual-rotor design
KW  - open-source release
KW  - design documents
KW  - high-performance tail-sitter
KW  - testing
KW  - open-source materials
KW  - aerodynamics
KW  - flight control
KW  - state estimation
KW  - Open source software
KW  - Propellers
KW  - Aerodynamics
KW  - Vehicle dynamics
KW  - Attitude control
KW  - Drones
KW  - Atmospheric modeling
DO  - 10.1109/ICRA.2019.8794433
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce the Phoenix drone: the first completely open-source tail-sitter micro aerial vehicle (MAV) platform. The vehicle has a highly versatile, dual-rotor design and is engineered to be low-cost and easily extensible/modifiable. Our open-source release includes all of the design documents, software resources, and simulation tools needed to build and fly a high-performance tail-sitter for research and educational purposes.The drone has been developed for precision flight with a high degree of control authority. Our design methodology included extensive testing and characterization of the aerodynamic properties of the vehicle. The platform incorporates many off-the-shelf components and 3D-printed parts, in order to keep the cost down. Nonetheless, the paper includes results from flight trials which demonstrate that the vehicle is capable of very stable hovering and accurate trajectory tracking.Our hope is that the open-source Phoenix reference design will be useful to both researchers and educators. In particular, the details in this paper and the available open-source materials should enable learners to gain an understanding of aerodynamics, flight control, state estimation, software design, and simulation, while experimenting with a unique aerial robot.
ER  - 

TY  - CONF
TI  - 1-Actuator 3-DoF Manipulation Using an Underactuated Mechanism with Multiple Nonparallel and Viscoelastic Passive Joints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5345
EP  - 5351
AU  - T. Kurita
AU  - M. Higashimori
PY  - 2019
KW  - actuators
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - plates (structures)
KW  - position control
KW  - viscoelasticity
KW  - sinusoidal displacement input
KW  - orbital shape
KW  - orbital direction
KW  - input frequency
KW  - switching frequency
KW  - mechanical parameters
KW  - three-DoF manipulation
KW  - plate orbital motions
KW  - 1-actuator 3-DoF manipulation
KW  - underactuated mechanism
KW  - multiple nonparallel
KW  - nonprehensile manipulation
KW  - planar part
KW  - manipulator
KW  - flat plate end effector
KW  - active joint joints
KW  - multiple passive viscoelastic joints
KW  - joint axes
KW  - viscoelastic passive joints
KW  - Orbits
KW  - Actuators
KW  - End effectors
KW  - Layout
KW  - Switches
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2019.8794157
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a nonprehensile manipulation based on the vibration of a plate, in which three degrees of freedom (DoF) of a planar part are controlled using only one actuator. First, the model of a manipulator with a flat plate end effector is proposed. The manipulator employs an underactuated mechanism including an active joint and multiple passive viscoelastic joints, in which the joint axes are arranged nonparallel to each other. Based on the model, the orbit of the plate for a sinusoidal displacement input to the active joint is theoretically derived. It is revealed that not only the orbital shape but also the orbital direction can be varied according to the input frequency. Based on the switching frequency of the orbital direction, a design index for the mechanical parameters is shown. Subsequently, the contribution of the switching of the orbital direction to the three-DoF manipulation of a part is explored via simulation. Eight primitives utilizing the plate orbital motions in both counter-clockwise and clockwise directions are provided. Finally, the proposed method is demonstrated by experiments.
ER  - 

TY  - CONF
TI  - Spline Based Curve Path Following of Underactuated Snake Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5352
EP  - 5358
AU  - W. Yang
AU  - G. Wang
AU  - H. Shao
AU  - Y. Shen
PY  - 2019
KW  - biomimetics
KW  - interpolation
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - splines (mathematics)
KW  - time-varying systems
KW  - underactuated snake robots
KW  - planar underactuated bio-inspired snake robots
KW  - time-varying line-of-sight guidance law
KW  - cubic spline interpolation path-planning method
KW  - snake robot motion control
KW  - 8-link custom-built snake robot
KW  - spline based curve path following
KW  - integral controller
KW  - Snake robots
KW  - Friction
KW  - Turning
KW  - Splines (mathematics)
KW  - Interpolation
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793531
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper investigates the curve path following problem for a class of planar underactuated bio-inspired snake robots. The time-varying line-of-sight (LOS) guidance law and the cubic spline interpolation (CSI) path-planning method are employed. Existing studies focus on straight line path following which only gives a solution for snake robot motion control in relatively simple environments. Considering the snake robot's many degrees of freedom and excellent mobility in terrains, we propose a more applicable solution of curve path following for snake robots on the ground. The improved LOS helps the snake robot to steer aggressively at a sharp turning point. Furthermore, to avoid the sideslip of the snake robot caused by the ground friction change, an integral controller is introduced in the design of the heading reference. Simulations and experiments on an 8-link custom-built snake robot are conducted and the results demonstrate and validate the effectiveness of the proposed curve path following algorithm.
ER  - 

TY  - CONF
TI  - High-Bandwidth Control of Twisted String Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5359
EP  - 5364
AU  - S. Nedelchev
AU  - I. Gaponov
AU  - J. Ryu
PY  - 2019
KW  - actuators
KW  - adaptive control
KW  - control system synthesis
KW  - feedforward
KW  - parameter estimation
KW  - position control
KW  - twisted string behavior
KW  - adaptive control methodology
KW  - TSA-based systems
KW  - online parameter estimation
KW  - outline adaptive estimation methods
KW  - variable controller gain
KW  - adaptive control architecture
KW  - high-bandwidth control
KW  - adaptive control strategies
KW  - TSA control system
KW  - mechatronics
KW  - twisted string actuators
KW  - Mathematical model
KW  - Robots
KW  - Adaptation models
KW  - Jacobian matrices
KW  - Adaptive control
KW  - Task analysis
KW  - Actuators
KW  - Tendon/Wire Mechanism
KW  - Motion Control
KW  - Learning and Adaptive Systems
DO  - 10.1109/ICRA.2019.8794259
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Twisted string actuators are an emerging type of transmission systems that may benefit various applications of robotics and mechatronics. However, control of TSAs in applications that require high bandwidth has attracted comparatively little interest from research community, mainly due to complexity of twisted string behavior. This paper proposes a new adaptive control methodology that allows to sufficiently increase bandwidth of TSA-based systems. We reformulate mathematical model of the TSA into a suitable form for online parameter estimation, outline adaptive estimation methods and propose a method to design variable controller gain that rectifies nonlinearities in the system. we present experimental comparison of proposed adaptive control strategies with two conventional tsa control techniques. experimental results demonstrated that the proposed adaptive control architecture with feedforward speed term was nearly insensitive to increase in input signal frequency while reducing position tracking error by 80%. proposed algorithm can be applied in any tsa control system that has input and output signal measurements.
ER  - 

TY  - CONF
TI  - TREE: A Variable Topology, Branching Continuum Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5365
EP  - 5371
AU  - M. C. Lastinger
AU  - S. Verma
AU  - A. D. Kapadia
AU  - I. D. Walker
PY  - 2019
KW  - adaptive systems
KW  - manipulators
KW  - TREE
KW  - variable topology
KW  - cleaning operations
KW  - hard-to-reach environments
KW  - hybrid concentric-tube
KW  - fully retractable continuum branches
KW  - branching continuum robot
KW  - inspection operations
KW  - tendon actuated continuum trunk core
KW  - Electron tubes
KW  - Tendons
KW  - Prototypes
KW  - Manipulators
KW  - Meters
KW  - Inspection
DO  - 10.1109/ICRA.2019.8794463
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We describe the design and physical realization of a novel branching continuum robot, aimed at inspection and cleaning operations in hard-to-reach environments at depths greater than human arm lengths. The design, based on a hybrid concentric-tube/tendon actuated continuum trunk core, features two pairs of fully retractable continuum branches. The retractable nature of the branches allows the robot to actively change its topology, allowing it to penetrate narrow openings and expand to adaptively engage complex environmental geometries. We detail and discuss the realization of a physical prototype of the design, and its testing in a simulated glove box environment.
ER  - 

TY  - CONF
TI  - Model Based In Situ Calibration with Temperature compensation of 6 axis Force Torque Sensors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5397
EP  - 5403
AU  - F. J. A. Chavez
AU  - G. Nava
AU  - S. Traversaro
AU  - F. Nori
AU  - D. Pucci
PY  - 2019
KW  - calibration
KW  - compensation
KW  - force measurement
KW  - force sensors
KW  - humanoid robots
KW  - temperature measurement
KW  - temperature sensors
KW  - torque measurement
KW  - temperature compensation
KW  - sensor measurements
KW  - model based in situ calibration
KW  - 6 axis force torque sensors method
KW  - strain gauges
KW  - F-T measurement
KW  - humanoid robot platform iCub
KW  - Temperature sensors
KW  - Temperature measurement
KW  - Calibration
KW  - Robot sensing systems
KW  - Strain measurement
KW  - Force Torque Sensing
KW  - Calibration and Identification
KW  - Humanoid Robots
DO  - 10.1109/ICRA.2019.8794382
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is well known that sensors using strain gauges have a potential dependency on temperature. This creates temperature drift in the measurements of six axis force torque sensors (F/T). The temperature drift can be considerable if an experiment is long or the environmental conditions are different from when the calibration of the sensor was performed. Other in situ methods disregard the effect of temperature on the sensor measurements. Experiments performed using the humanoid robot platform iCub show that the effect of temperature is relevant. The model based in situ calibration of six axis force torque sensors method is extended to perform temperature compensation.
ER  - 

TY  - CONF
TI  - Whole-Body Active Compliance Control for Humanoid Robots with Robot Skin
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5404
EP  - 5410
AU  - E. Dean-Leon
AU  - J. R. Guadarrama-Olvera
AU  - F. Bergner
AU  - G. Cheng
PY  - 2019
KW  - compliance control
KW  - humanoid robots
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - skin
KW  - tactile sensors
KW  - control systems
KW  - control framework
KW  - skin cells
KW  - whole-body active compliance control
KW  - multicontact interactions
KW  - whole-body control methods
KW  - human environments
KW  - humanoid robots
KW  - body active compliance control
KW  - position-controlled stiff humanoid robot
KW  - multiple control strategies
KW  - robot body
KW  - full-size humanoid robot
KW  - robot skin
KW  - multimodal tactile information
KW  - compliant robots
KW  - tactile sensor information
KW  - physical interactions
KW  - online information
KW  - touch sensing
KW  - Skin
KW  - Robot sensing systems
KW  - Task analysis
KW  - Legged locomotion
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8793258
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humanoid robots are expected to interact in human environments, where physical interactions are unavoidable. Therefore, whole-body control methods that include multi-contact interactions are required. The new emerging technologies in touch sensing are fundamental to acquire online and rich information about these physical interactions with the environment. These technologies lead to the design of novel control systems that can profit from the tactile sensor information in an efficient form, thus producing reactive and compliant robots capable of interacting with their environment. In this paper, we present a novel control framework to integrate the multi-modal tactile information of a robot skin with different control strategies, producing dynamic behaviours suitable for Human-Robot Interactions (HRI). The control framework was experimentally evaluated on a full-size humanoid robot covered with more than 1260 skin cells distributed in the whole robot body. The results show that multi-modal tactile information can be fused hierarchically with multiple control strategies, producing active compliance in a position-controlled stiff humanoid robot.
ER  - 

TY  - CONF
TI  - Internal Array Electrodes Improve the Spatial Resolution of Soft Tactile Sensors Based on Electrical Resistance Tomography
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5411
EP  - 5417
AU  - H. Lee
AU  - K. Park
AU  - J. Kim
AU  - K. J. Kuchenbecker
PY  - 2019
KW  - electrodes
KW  - tactile sensors
KW  - tomography
KW  - soft tactile sensors
KW  - electrical resistance tomography
KW  - unstructured environments
KW  - whole-body tactile sensors
KW  - complex electrical wiring
KW  - sensing elements
KW  - reconstruction method
KW  - sensing region
KW  - central region
KW  - ERT approach
KW  - optimal pairwise current injection patterns
KW  - ERT system
KW  - electrode pair
KW  - fabric-based soft tactile sensor
KW  - sensor-specific calibration
KW  - constructed sensor
KW  - internal array electrodes
KW  - frequency 200.0 Hz
KW  - Electrodes
KW  - Tactile sensors
KW  - Conductivity
KW  - Voltage measurement
KW  - Spatial resolution
KW  - Fabrics
DO  - 10.1109/ICRA.2019.8794276
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots operating in unstructured environments would benefit from soft whole-body tactile sensors, but implementing such systems typically requires complex electrical wiring to a large number of sensing elements. The reconstruction method called electrical resistance tomography (ERT) has shown promising results (good coverage, manufacturability, and robustness) using electrodes located only along the boundary of the sensing region. However, relatively poor spatial resolution in the sensor's central region is a major drawback of the ERT approach. This paper introduces a new scheme of internal array electrodes to improve spatial resolution. We also systematically derive the optimal pairwise current injection patterns from a mathematical formulation of the ERT system. By highlighting the importance of each electrode pair, this approach enabled us to reduce the number of current injection patterns. Simulation of the standard and proposed sensor designs revealed that the internal array electrodes greatly improve distinguishability in the central region. For validation, a fabric-based soft tactile sensor made of multiple conductive fabrics was developed, including electronics that enable sampling at 200 Hz. During a 225-point localization test conducted without sensor-specific calibration, the constructed sensor showed average localization errors of 2.85 cm Â± 1.02 cm. This result is notable because only 16 point electrodes were used to achieve this performance.
ER  - 

TY  - CONF
TI  - Dense Tactile Force Estimation using GelSlim and inverse FEM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5418
EP  - 5424
AU  - D. Ma
AU  - E. Donlon
AU  - S. Dong
AU  - A. Rodriguez
PY  - 2019
KW  - deformation
KW  - finite element analysis
KW  - image sensors
KW  - tactile sensors
KW  - tactile sensor
KW  - GelSlim 2
KW  - inverse FEM
KW  - Kendama manipulations
KW  - force field
KW  - reconstructed force distribution
KW  - marker displacements
KW  - inverse finite element method
KW  - gel pad
KW  - contact force distribution
KW  - dense tactile force estimation
KW  - Force
KW  - Tactile sensors
KW  - Finite element analysis
KW  - Cameras
KW  - Force measurement
KW  - Strain
DO  - 10.1109/ICRA.2019.8794113
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a new version of tactile sensor GelSlim 2.0 with the capability to estimate the contact force distribution in real time. The sensor is vision-based and uses an array of markers to track deformations on a gel pad due to contact. A new hardware design makes the sensor more rugged, parametrically adjusTable AND Improves illumination. leveraging the sensor's increased functionality, we propose to use inverse finite element method (ifem), a numerical method to reconstruct the contact force distribution based on marker displacements. the sensor is able to provide force distribution of contact with high spatial density. experiments and comparison with ground truth show that the reconstructed force distribution is physically reasonable with good accuracy.A sequence of Kendama manipulations with corresponding displacement field (yellow) and force field (red). Video can be found on Youtube: https://youtu.be/hWw9A0ZBZuU.
ER  - 

TY  - CONF
TI  - Pose Graph optimization for Unsupervised Monocular Visual Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5439
EP  - 5445
AU  - Y. Li
AU  - Y. Ushiku
AU  - T. Harada
PY  - 2019
KW  - graph theory
KW  - neural nets
KW  - optimisation
KW  - pose estimation
KW  - unsupervised learning
KW  - pose graph optimization
KW  - unsupervised monocular visual odometry
KW  - unsupervised learning
KW  - label-free leaning ability
KW  - drift correction technique
KW  - large-scale odometry estimation
KW  - loop closure detection
KW  - hybrid VO system
KW  - NeuralBundler
KW  - temporal loss
KW  - spatial photometric loss
KW  - multiview 6DoF constraints
KW  - cycle consistency loss
KW  - global pose graph
KW  - local loop 6DoF constraints
KW  - KITTI odometry dataset
KW  - unsupervised monocular VO estimation
KW  - monocular SLAM systems
KW  - Optimization
KW  - Visual odometry
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Training
KW  - Neural networks
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793706
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unsupervised Learning based monocular visual odometry (VO) has lately drawn significant attention for its potential in label-free leaning ability and robustness to camera parameters and environmental variations. However, partially due to the lack of drift correction technique, these methods are still by far less accurate than geometric approaches for large-scale odometry estimation. In this paper, we propose to leverage graph optimization and loop closure detection to overcome limitations of unsupervised learning based monocular visual odometry. To this end, we propose a hybrid VO system which combines an unsupervised monocular VO called NeuralBundler with a pose graph optimization back-end. NeuralBundler is a neural network architecture that uses temporal and spatial photometric loss as main supervision and generates a windowed pose graph consists of multi-view 6DoF constraints. We propose a novel pose cycle consistency loss to relieve the tensions in the windowed pose graph, leading to improved performance and robustness. In the back-end, a global pose graph is built from local and loop 6DoF constraints estimated by NeuralBundler, and is optimized over SE(3). Empirical evaluation on the KITTI odometry dataset demonstrates that 1) NeuralBundler achieves state-of-the-art performance on unsupervised monocular VO estimation, and 2) our whole approach can achieve efficient loop closing and show favorable overall translational accuracy compared to established monocular SLAM systems.
ER  - 

TY  - CONF
TI  - Probably Unknown: Deep Inverse Sensor Modelling Radar
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5446
EP  - 5452
AU  - R. Weston
AU  - S. Cen
AU  - P. Newman
AU  - I. Posner
PY  - 2019
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - probability
KW  - radar computing
KW  - radar imaging
KW  - autonomous vehicle applications
KW  - weather conditions
KW  - raw radar power returns
KW  - sensor noise
KW  - occlusion
KW  - Inverse Sensor Model
KW  - grid map
KW  - grid cell
KW  - heteroscedastic uncertainty
KW  - deep Inverse Sensor modelling radar
KW  - sensor observation
KW  - model formulation
KW  - standard CFAR filtering approaches
KW  - dynamic urban environment
KW  - world occupancy
KW  - lidar
KW  - partial occupancy labels
KW  - deep neural network
KW  - occupancy probabilities
KW  - Uncertainty
KW  - Robot sensing systems
KW  - Laser radar
KW  - Training
KW  - Spaceborne radar
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793263
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Radar presents a promising alternative to lidar and vision in autonomous vehicle applications, able to detect objects at long range under a variety of weather conditions. However, distinguishing between occupied and free space from raw radar power returns is challenging due to complex interactions between sensor noise and occlusion. To counter this we propose to learn an Inverse Sensor Model (ISM) converting a raw radar scan to a grid map of occupancy probabilities using a deep neural network. Our network is selfsupervised using partial occupancy labels generated by lidar, allowing a robot to learn about world occupancy from past experience without human supervision. We evaluate our approach on five hours of data recorded in a dynamic urban environment. By accounting for the scene context of each grid cell our model is able to successfully segment the world into occupied and free space, outperforming standard CFAR filtering approaches. Additionally by incorporating heteroscedastic uncertainty into our model formulation, we are able to quantify the variance in the uncertainty throughout the sensor observation. Through this mechanism we are able to successfully identify regions of space that are likely to be occluded.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Occupancy Map Prediction Using Generative Networks for Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5453
EP  - 5459
AU  - K. Katyal
AU  - K. Popek
AU  - C. Paxton
AU  - P. Burlina
AU  - G. D. Hager
PY  - 2019
KW  - mobile robots
KW  - multi-robot systems
KW  - neural net architecture
KW  - path planning
KW  - sensor field of view
KW  - sensor FOV
KW  - generated hypotheses
KW  - information-theoretic exploration strategy
KW  - combined map prediction
KW  - neural network architecture
KW  - custom loss function
KW  - deep neural networks
KW  - future robot motions
KW  - sensor data
KW  - occupancy map representations
KW  - biological systems
KW  - sensor field
KW  - future motion
KW  - robotic systems
KW  - robot navigation
KW  - generative networks
KW  - uncertainty-aware occupancy map prediction
KW  - Neural networks
KW  - Robot sensing systems
KW  - Training
KW  - Measurement
KW  - Navigation
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793500
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Efficient exploration through unknown environments remains a challenging problem for robotic systems. In these situations, the robot's ability to reason about its future motion is often severely limited by sensor field of view (FOV). By contrast, biological systems routinely make decisions by taking into consideration what might exist beyond their FOV based on prior experience. We present an approach for predicting occupancy map representations of sensor data for future robot motions using deep neural networks. We develop a custom loss function used to make accurate prediction while emphasizing physical boundaries. We further study extensions to our neural network architecture to account for uncertainty and ambiguity inherent in mapping and exploration. Finally, we demonstrate a combined map prediction and information-theoretic exploration strategy using the variance of the generated hypotheses as the heuristic for efficient exploration of unknown environments.
ER  - 

TY  - CONF
TI  - Empty Cities: Image Inpainting for a Dynamic-Object-Invariant Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5460
EP  - 5466
AU  - B. Bescos
AU  - J. Neira
AU  - R. Siegwart
AU  - C. Cadena
PY  - 2019
KW  - augmented reality
KW  - convolutional neural nets
KW  - image classification
KW  - image restoration
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - augmented reality
KW  - static structure
KW  - image inpainting
KW  - dynamic-object-invariant space
KW  - vehicles
KW  - pedestrians
KW  - plausible imagery
KW  - multiclass semantic segmentation
KW  - inpainting methods
KW  - deep learning
KW  - generative adversarial model
KW  - convolutional network
KW  - vision-based robot localization
KW  - visual place recognition
KW  - Vehicle dynamics
KW  - Semantics
KW  - Task analysis
KW  - Image segmentation
KW  - Deep learning
KW  - Image reconstruction
KW  - Training
DO  - 10.1109/ICRA.2019.8794417
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we present an end-to-end deep learning framework to turn images that show dynamic content, such as vehicles or pedestrians, into realistic static frames. This objective encounters two main challenges: detecting all the dynamic objects, and inpainting the static occluded background with plausible imagery. The former challenge is addressed by the use of a convolutional network that learns a multiclass semantic segmentation of the image. The second problem is approached with a conditional generative adversarial model that, taking as input the original dynamic image and its dynamic/static binary mask, is capable of generating the final static image. These generated images can be used for applications such as augmented reality or vision-based robot localization purposes. To validate our approach, we show both qualitative and quantitative comparisons against other state-of-the-art inpainting methods by removing the dynamic objects and hallucinating the static structure behind them. Furthermore, to demonstrate the potential of our results, we carry out pilot experiments that show the benefits of our proposal for visual place recognition.
ER  - 

TY  - CONF
TI  - Autonomous Exploration, Reconstruction, and Surveillance of 3D Environments Aided by Deep Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5467
EP  - 5473
AU  - L. Ly
AU  - Y. R. Tsai
PY  - 2019
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - neural nets
KW  - autonomous exploration
KW  - surveillance
KW  - greedy learning approach
KW  - supervised learning approach
KW  - level set representation
KW  - convolutional neural network
KW  - visibility
KW  - on-line computational cost
KW  - topologically accurate maps
KW  - complex 3D environments
KW  - frontier-based strategies
KW  - potential vantage points
KW  - deep learning approaches
KW  - obstacle avoidance
KW  - local navigation
KW  - global exploration problem
KW  - 3D urban environments
KW  - Training
KW  - Level set
KW  - Surveillance
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Sensors
KW  - Convolution
DO  - 10.1109/ICRA.2019.8794426
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a greedy and supervised learning approach for visibility-based exploration, reconstruction and surveillance. Using a level set representation, we train a convolutional neural network to determine vantage points that maximize visibility. We show that this method drastically reduces the on-line computational cost and determines a small set of vantage points that solve the problem. This enables us to efficiently produce highly-resolved and topologically accurate maps of complex 3D environments. Unlike traditional next-best-view and frontier-based strategies, the proposed method accounts for geometric priors while evaluating potential vantage points. While existing deep learning approaches focus on obstacle avoidance and local navigation, our method aims at finding near-optimal solutions to the more global exploration problem. We present realistic simulations on 2D and 3D urban environments.
ER  - 

TY  - CONF
TI  - GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5474
EP  - 5480
AU  - Y. Almalioglu
AU  - M. R. U. Saputra
AU  - P. P. B. d. GusmÃ£o
AU  - A. Markham
AU  - N. Trigoni
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - distance measurement
KW  - image colour analysis
KW  - image motion analysis
KW  - image sequences
KW  - pose estimation
KW  - unsupervised learning
KW  - unlabelled RGB image sequences
KW  - deep convolutional Generative Adversarial Networks
KW  - single-view depth generation network
KW  - unsupervised deep VO methods
KW  - unsupervised deep monocular visual odometry
KW  - depth estimation
KW  - supervised deep learning approaches
KW  - visual odometry applications
KW  - unsupervised deep learning approaches
KW  - VO research
KW  - generative unsupervised learning framework
KW  - multiview pose estimation
KW  - 6-DoF pose camera motion
KW  - Image reconstruction
KW  - Pose estimation
KW  - Cameras
KW  - Deep learning
KW  - Training
KW  - Feature extraction
KW  - Gallium nitride
DO  - 10.1109/ICRA.2019.8793512
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the last decade, supervised deep learning approaches have been extensively employed in visual odometry (VO) applications, which is not feasible in environments where labelled data is not abundant. On the other hand, unsupervised deep learning approaches for localization and mapping in unknown environments from unlabelled data have received comparatively less attention in VO research. In this study, we propose a generative unsupervised learning framework that predicts 6-DoF pose camera motion and monocular depth map of the scene from unlabelled RGB image sequences, using deep convolutional Generative Adversarial Networks (GANs). We create a supervisory signal by warping view sequences and assigning the re-projection minimization to the objective loss function that is adopted in multi-view pose estimation and single-view depth generation network. Detailed quantitative and qualitative evaluations of the proposed framework on the KITTI [1] and Cityscapes [2] datasets show that the proposed method outperforms both existing traditional and unsupervised deep VO methods providing better results for both pose estimation and depth recovery.
ER  - 

TY  - CONF
TI  - Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5481
EP  - 5487
AU  - A. Milioto
AU  - L. Mandtler
AU  - C. Stachniss
PY  - 2019
KW  - convolutional neural nets
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - object detection
KW  - robot vision
KW  - metric learning
KW  - one-shot detection
KW  - semantic scene understanding
KW  - autonomous robots
KW  - dynamic environments
KW  - instance segmentation
KW  - multitask convolutional neural network architecture
KW  - object instances
KW  - local connectivity
KW  - semantic segmentation
KW  - Semantics
KW  - Image segmentation
KW  - Decoding
KW  - Feature extraction
KW  - Task analysis
KW  - Robots
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793593
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.
ER  - 

TY  - CONF
TI  - Adding Cues to Binary Feature Descriptors for Visual Place Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5488
EP  - 5494
AU  - D. Schlegel
AU  - G. Grisetti
PY  - 2019
KW  - feature extraction
KW  - image retrieval
KW  - binary feature descriptors
KW  - visual place recognition
KW  - multidimensional continuous cues
KW  - feature descriptor
KW  - binary string
KW  - continuous cue
KW  - binary descriptor types
KW  - Hamming distance
KW  - Search problems
KW  - Quantization (signal)
KW  - Visualization
KW  - Measurement
KW  - Simultaneous localization and mapping
KW  - Image retrieval
DO  - 10.1109/ICRA.2019.8793753
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we propose an approach to embed multi-dimensional continuous cues in binary feature descriptors used for visual place recognition. The embedding is achieved by extending each feature descriptor with a binary string that encodes a cue and supports the Hamming distance metric. Augmenting the descriptors in such a way has the advantage of being transparent to the procedure used to compare them. We present a concrete application of our methodology, demonstrating the considered type of continuous cue. Additionally, we conducted a broad quantitative and comparative evaluation on that application, covering five benchmark datasets and several state-of-the-art image retrieval approaches in combination with various binary descriptor types.
ER  - 

TY  - CONF
TI  - Recursive Bayesian Classification for Perception of Evolving Targets using a Gaussian Toroid Prediction Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5495
EP  - 5501
AU  - J. J. Steckenrider
AU  - T. Furukawa
PY  - 2019
KW  - Bayes methods
KW  - belief networks
KW  - feature extraction
KW  - Gaussian processes
KW  - image classification
KW  - real-time systems
KW  - recursive estimation
KW  - uncertainty handling
KW  - Gaussian toroid prediction model
KW  - probabilistic framework
KW  - recursive Bayesian estimation
KW  - perception-oriented context
KW  - recursive Bayesian classification scheme
KW  - high-dimensional belief spaces
KW  - evolving target classification
KW  - perception target evolution
KW  - RBC scheme
KW  - feature extraction
KW  - multiGaussian belief representation
KW  - real-time analysis
KW  - observational uncertainty
KW  - Predictive models
KW  - Bayes methods
KW  - Probabilistic logic
KW  - Probability density function
KW  - Estimation
KW  - Decision making
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793951
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a probabilistic framework for classification of evolving targets, leveraging the principles of recursive Bayesian estimation in a perception-oriented context. By implementing a Gaussian toroid prediction model of the perception target's evolution, the proposed recursive Bayesian classification (RBC) scheme provides probabilistically robust classification. Appropriate features are extracted from the target, which is then probabilistically represented in a belief space. This approach is capable of handling high-dimensional belief spaces, while simultaneously allowing for multi-Gaussian representation of belief without computational complexity that hinders real-time analysis. The proposed technique is validated over several parameter values by thousands of simulated experiments, where it is shown to outperform naÄ±ve classification when high observational uncertainty is present.
ER  - 

TY  - CONF
TI  - Large-Scale Object Mining for Object Discovery from Unlabeled Video
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5502
EP  - 5508
AU  - A. OÅ¡ep
AU  - P. Voigtlaender
AU  - J. Luiten
AU  - S. Breuers
AU  - B. Leibe
PY  - 2019
KW  - data mining
KW  - image representation
KW  - object tracking
KW  - pattern clustering
KW  - traffic engineering computing
KW  - video signal processing
KW  - video streaming
KW  - generic object tracker
KW  - unlabeled video
KW  - unlabeled driving videos
KW  - raw video streams
KW  - object distribution
KW  - object discovery
KW  - object tracks
KW  - object categories
KW  - large scale object mining
KW  - realistic automotive setting
KW  - feature representations
KW  - clustering strategies
KW  - Proposals
KW  - Data mining
KW  - Detectors
KW  - Automobiles
KW  - Feature extraction
KW  - Streaming media
KW  - Robots
DO  - 10.1109/ICRA.2019.8793683
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of object discovery from unlabeled driving videos captured in a realistic automotive setting. Identifying recurring object categories in such raw video streams is a very challenging problem. Not only do object candidates first have to be localized in the input images, but many interesting object categories occur relatively infrequently. Object discovery will therefore have to deal with the difficulties of operating in the long tail of the object distribution. We demonstrate the feasibility of performing fully automatic object discovery in such a setting by mining object tracks using a generic object tracker. In order to facilitate further research in objet discovery, we release a collection of more than 360,000 automatically mined object tracks from 10 + hours of video data (560,000 frames). We use this dataset to evaluate the suitability of different feature representations and clustering strategies for object discovery.
ER  - 

TY  - CONF
TI  - Goal-oriented Object Importance Estimation in On-road Driving Videos
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5509
EP  - 5515
AU  - M. Gao
AU  - A. Tawari
AU  - S. Martin
PY  - 2019
KW  - driver information systems
KW  - feature extraction
KW  - object detection
KW  - road traffic
KW  - road vehicles
KW  - video signal processing
KW  - on-road driving videos
KW  - OIE
KW  - driving scene
KW  - visual model
KW  - object importance estimation
KW  - ego-vehicles driver
KW  - driving control
KW  - binary brake prediction
KW  - Vehicles
KW  - Feature extraction
KW  - Videos
KW  - Roads
KW  - Visualization
KW  - Task analysis
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8793970
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We formulate a new problem as Object Importance Estimation (OIE) in on-road driving videos, where the road users are considered as important objects if they have influence on the control decision of the ego-vehicle's driver. The importance of a road user depends on both its visual dynamics, e.g., appearance, motion and location, in the driving scene and the driving goal, e.g., the planned path, of the ego vehicle. We propose a novel framework that incorporates both visual model and goal representation to conduct OIE. To evaluate our framework, we collect an on-road driving dataset at traffic intersections in the real world and conduct human-labeled annotation of the important objects. Experimental results show that our goal-oriented method outperforms baselines and has much more improvement on the left-turn and right-turn scenarios. Furthermore, we explore the possibility of using object importance for driving control prediction and demonstrate that binary brake prediction can be improved with the information of object importance.
ER  - 

TY  - CONF
TI  - Priming Deep Pedestrian Detection with Geometric Context
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5516
EP  - 5522
AU  - I. Chakraborty
AU  - G. Hua
PY  - 2019
KW  - computational geometry
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - pedestrians
KW  - deep neural networks
KW  - deep object detectors
KW  - geometric context
KW  - deep pedestrian detection
KW  - DNN detectors
KW  - DNN feature learning
KW  - Cameras
KW  - Detectors
KW  - Proposals
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Geometry
KW  - Context modeling
DO  - 10.1109/ICRA.2019.8794018
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We investigate the role of geometric context in deep neural networks to establish better pedestrian detectors that are more robust to occlusions. Notwithstanding their demonstrated successes, deep object detectors under-perform in crowded scenes with high intra-category occlusions. One brute-force solution is to collect a large number of labeled training samples under occlusion, but the combinatorial increase in the labeling effort makes it an unaffordable solution. We argue that a promising and complementary direction to solve this problem is to bring geometric context to modulate feature learning in a DNN. We identify that an effective way to leverage geometric context is to induce it in two steps - through early fusion, by guiding region proposal generation to focus on occluded regions, and through late fusion, by penalizing misalignments of bounding boxes in both 2D and 3D. Our experiments on multiple state-of-the-art DNN detectors and detection benchmarks clearly demonstrates that our proposed method outperforms strong baselines by an average of 5%.
ER  - 

TY  - CONF
TI  - The Robust Canadian Traveler Problem Applied to Robot Routing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5523
EP  - 5529
AU  - H. Guo
AU  - T. D. Barfoot
PY  - 2019
KW  - graph theory
KW  - mobile robots
KW  - stochastic processes
KW  - telecommunication network routing
KW  - worst-case cost
KW  - Robust Canadian Traveler Problem applied
KW  - stochastic Canadian Traveler Problem
KW  - CTP
KW  - robot route selection
KW  - traversal policy
KW  - policy cost
KW  - evaluation criteria
KW  - approximate algorithm
KW  - traversal cost
KW  - robot field trials
KW  - RCTP framework
KW  - sub-optimal policy alternatives
KW  - minimum expected cost
KW  - distance 5.0 km
KW  - Approximation algorithms
KW  - Robot sensing systems
KW  - Visualization
KW  - Search problems
KW  - Heuristic algorithms
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8794252
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The stochastic Canadian Traveler Problem (CTP), which finds application in robot route selection under uncertainty, aims to find the traversal policy with the minimum expected cost. This paper extends the CTP to what we call the Robust Canadian Traveler Problem (RCTP), in which the variability of the policy cost is also part of the evaluation criteria. An optimal (offline) algorithm and an approximate (online) algorithm are then proposed to compute the policy that has a good balance of both mean and variation of the traversal cost. The benefit of the proposed framework versus traditional approaches is shown by doing simulations in randomly generated worlds as well as on a map of 5 km of paths built from robot field trials. Specifically, the RCTP framework is able to search for sub-optimal policy alternatives with significantly lower worst-case cost and less computational time compared to the optimal policy, but with little sacrifice on the expected cost.
ER  - 

TY  - CONF
TI  - Improved A-search guided tree construction for kinodynamic planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5530
EP  - 5536
AU  - Y. Wang
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - search problems
KW  - trees (mathematics)
KW  - A-search guided tree
KW  - node selection
KW  - heuristic cost
KW  - computation efficiency
KW  - improved AGT
KW  - i-AGT
KW  - node expansion
KW  - prioritizing control actions
KW  - prioritizing nodes
KW  - bi-directional AGT
KW  - BAGT
KW  - kinodynamic planning
KW  - second tree encodes obstacles information
KW  - Robots
KW  - Path planning
KW  - Aerospace electronics
KW  - Complexity theory
KW  - Probabilistic logic
KW  - Lattices
KW  - Planning
DO  - 10.1109/ICRA.2019.8793705
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - With node selection being directed by a heuristic cost [1]-[3], A-search guided tree (AGT) is constructed on-the-fly and enables fast kinodynamic planning. This work presents two variants of AGT to improve computation efficiency. An improved AGT (i-AGT) biases node expansion through prioritizing control actions, an analogy of prioritizing nodes. Focusing on node selection, a bi-directional AGT (BAGT) introduces a second tree originated from the goal in order to offer a better heuristic cost of the first tree. Effectiveness of BAGT pivots on the fact that the second tree encodes obstacles information near the goal. Case study demonstrates that i-AGT consistently reduces the complexity of the tree and improves computation efficiency; and BAGT works largely but not always, particularly with no benefit observed for simple cases.
ER  - 

TY  - CONF
TI  - Balancing Global Exploration and Local-connectivity Exploitation with Rapidly-exploring Random disjointed-Trees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5537
EP  - 5543
AU  - T. Lai
AU  - F. Ramos
AU  - G. Francis
PY  - 2019
KW  - Markov processes
KW  - path planning
KW  - robots
KW  - sampling methods
KW  - search problems
KW  - trees (mathematics)
KW  - local-connectivity exploitation
KW  - sampling efficiency
KW  - sampling-based planners
KW  - incremental optimal multiquery planner
KW  - RRdT
KW  - Markov Chain random sampling
KW  - active balancing
KW  - sampling-based motion planners
KW  - incremental planners
KW  - rapidly-exploring random disjointed-trees
KW  - Convergence
KW  - Space exploration
KW  - Probabilistic logic
KW  - Planning
KW  - Path planning
KW  - Proposals
KW  - Markov processes
DO  - 10.1109/ICRA.2019.8793618
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sampling efficiency in a highly constrained environment has long been a major challenge for sampling-based planners. In this work, we propose Rapidly-exploring Random disjointed-Trees* (RRdT*), an incremental optimal multi-query planner. RRdT* uses multiple disjointed-trees to exploit local-connectivity of spaces via Markov Chain random sampling, which utilises neighbourhood information derived from previous successful and failed samples. To balance local exploitation, RRdT* actively explore unseen global spaces when local-connectivity exploitation is unsuccessful. The active trade-off between local exploitation and global exploration is formulated as a multi-armed bandit problem. We argue that the active balancing of global exploration and local exploitation is the key to improving sample efficient in sampling-based motion planners. We provide rigorous proofs of completeness and optimal convergence for this novel approach. Furthermore, we demonstrate experimentally the effectiveness of RRdT*'s locally exploring trees in granting improved visibility for planning. Consequently, RRdT* outperforms existing state-of-the-art incremental planners, especially in highly constrained environments.
ER  - 

TY  - CONF
TI  - Locomotion Planning through a Hybrid Bayesian Trajectory Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5544
EP  - 5550
AU  - T. Seyde
AU  - J. Carius
AU  - R. Grandia
AU  - F. Farshidian
AU  - M. Hutter
PY  - 2019
KW  - Bayes methods
KW  - computational complexity
KW  - Gaussian processes
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - nonlinear programming
KW  - optimal control
KW  - path planning
KW  - locomotion planning
KW  - legged systems
KW  - suitable contact schedules
KW  - contact sequence
KW  - hybrid dynamical system
KW  - achievable motions
KW  - optimal control problem
KW  - computational complexity
KW  - motion optimization
KW  - plans contacts
KW  - contact schedule selection
KW  - high-level task descriptors
KW  - motion planning nonlinear program
KW  - single-legged hopping
KW  - task appropriate contact schedules
KW  - hybrid Bayesian trajectory optimization
KW  - Bayesian optimization
KW  - Gaussian process model
KW  - bilevel optimization
KW  - Optimization
KW  - Schedules
KW  - Trajectory
KW  - Kernel
KW  - Task analysis
KW  - Robots
DO  - 10.1109/ICRA.2019.8794067
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Locomotion planning for legged systems requires reasoning about suitable contact schedules. The contact sequence and timings constitute a hybrid dynamical system and prescribe a subset of achievable motions. State-of-the-art approaches cast motion planning as an optimal control problem. In order to decrease computational complexity, one common strategy separates footstep planning from motion optimization and plans contacts using heuristics. In this paper, we propose to learn contact schedule selection from high-level task descriptors using Bayesian Optimization. A bi-level optimization is defined in which a Gaussian Process model predicts the performance of trajectories generated by a motion planning nonlinear program. The agent, therefore, retains the ability to reason about suitable contact schedules, while explicit computation of the corresponding gradients is avoided. We delineate the algorithm in its general form and provide results for planning single-legged hopping. Our method is capable of learning contact schedule transitions that align with human intuition. It performs competitively against a heuristic baseline in predicting task appropriate contact schedules.
ER  - 

TY  - CONF
TI  - Dynamic Channel: A Planning Framework for Crowd Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5551
EP  - 5557
AU  - C. Cao
AU  - P. Trautman
AU  - S. Iba
PY  - 2019
KW  - collision avoidance
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - pedestrians
KW  - search problems
KW  - crowd navigation
KW  - real-time navigation
KW  - robotics
KW  - imminent collision avoidance
KW  - path planning problem
KW  - graph-searching
KW  - triangulation space
KW  - obstacle dynamics
KW  - public pedestrian datasets
KW  - dynamic obstacle avoidance
KW  - dynamic channels
KW  - motion planners
KW  - pedestrian dynamics
KW  - mobile robot applications
KW  - Robots
KW  - Collision avoidance
KW  - Navigation
KW  - Planning
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Logic gates
DO  - 10.1109/ICRA.2019.8794192
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Real-time navigation in dense human environments is a challenging problem in robotics. Most existing path planners fail to account for the dynamics of pedestrians because introducing time as an additional dimension in search space is computationally prohibitive. Alternatively, most local motion planners only address imminent collision avoidance and fail to offer long-term optimality. In this work, we present an approach, called Dynamic Channels, to solve this global to local quandary. Our method combines the high-level topological path planning with low-level motion planning into a complete pipeline. By formulating the path planning problem as graph-searching in the triangulation space, our planner is able to explicitly reason about the obstacle dynamics and capture the environmental change efficiently. We evaluate efficiency and performance of our approach on public pedestrian datasets and compare it to a state-of-the-art planning algorithm for dynamic obstacle avoidance. Completeness proofs are provided in the supplement at http://caochao.me/files/proof.pdf. An extended version of the paper is available on arXiv.
ER  - 

TY  - CONF
TI  - Composition of Local Potential Functions with Reflection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5558
EP  - 5564
AU  - A. Stager
AU  - H. G. Tanner
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - local potential functions
KW  - reflections
KW  - collision capable robot platforms
KW  - reflection surfaces
KW  - reflection capable omnidirectional robot
KW  - cell decompositions
KW  - navigation
KW  - global convergence
KW  - Omnipuck
KW  - Robots
KW  - Collision avoidance
KW  - Convergence
KW  - Planning
KW  - Navigation
KW  - Trajectory
KW  - Pins
DO  - 10.1109/ICRA.2019.8793807
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper suggests reflections can be practically useful if they are included in planning for collision capable robot platforms. By modifying a proven strategy for navigation with reflections we maintain global convergence results and reach the goal in less time. An algorithm for identifying reflection surfaces for a given cell decomposition is reported. Baseline and reflected scenarios are compared for two different cell decompositions. Omnipuck, a reflection capable omnidirectional robot meant to store and release impact energy, is used to obtain experimental results and draw conclusions for future work.
ER  - 

TY  - CONF
TI  - Analyzing Electromagnetic Actuator based on Force Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5565
EP  - 5570
AU  - J. Ahn
AU  - D. Yun
PY  - 2019
KW  - electric field effects
KW  - electromagnetic actuators
KW  - embossing
KW  - hot working
KW  - impact (mechanical)
KW  - magnetic field effects
KW  - impact hot embossing
KW  - force analysis
KW  - magnetic field
KW  - system equation
KW  - electromagnetic actuator
KW  - electrical field
KW  - mechanical system
KW  - Simulink analysis
KW  - Mathematical model
KW  - Actuators
KW  - Magnetic flux
KW  - Force
KW  - Magnetic forces
KW  - Magnetic circuits
KW  - Embossing
KW  - Hot Embossing
KW  - electromagnetic actuator
KW  - linear actuator
KW  - system modeling
KW  - equivalent magnetic circuit
DO  - 10.1109/ICRA.2019.8793518
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - By modeling the system with the mechanical, electrical, and magnetic field, we can derive the system equation for the actuator modeling. As it is not easy to conclude the output signal from the equations, we used Simulink to simulate and check the performance aspect of the system. After that, we did several experiments to verify whether experimental force meets with the needed condition for impact hot embossing and matches with simulation force. We tried to adjust the parameters of the system to match the force of experiment result and that of the simulation result. From the comparison, we can consider the analysis of the actuator as precise. A successful study can contribute to the better application of new type hot embossing techniques and better understanding and usage of the electromagnetic actuator when it is applied to another technology and research.
ER  - 

TY  - CONF
TI  - A Novel Robotic System for Finishing of Freeform Surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5571
EP  - 5577
AU  - Y. Wen
AU  - J. Hu
AU  - P. R. Pagilla
PY  - 2019
KW  - closed loop systems
KW  - end effectors
KW  - fixtures
KW  - force sensors
KW  - industrial manipulators
KW  - industrial robots
KW  - mobile robots
KW  - optical scanners
KW  - surface finishing
KW  - freeform surfaces
KW  - consistent surface quality
KW  - robotic surface finishing system
KW  - finishing tool
KW  - proximity laser sensor
KW  - surface finishing process
KW  - surface profile mesh
KW  - robot closed-loop control system
KW  - robot base coordinates
KW  - surface finishing experiments
KW  - wooden surfaces
KW  - surface finish
KW  - robotic system
KW  - perception system
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Surface impedance
KW  - Surface treatment
KW  - Surface emitting lasers
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793734
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surface finishing of freeform surfaces is predominately a manual operation that requires a considerable amount of operator skill; automation of this process has many benefits, including consistent surface quality, preventing hazardous exposure to particulate, etc. A novel robotic surface finishing system, consisting of a robot and an end-effector that includes a force sensor, finishing tool, and proximity laser sensor, is developed in this paper to automate the surface finishing process. The laser sensor is treated as an additional link, and based on it a novel perception system is developed for real-time scanning of the surface that provides the surface profile mesh and the corresponding normal vectors which can be used directly by the robot closed-loop control system for pose tracking. A unique feature of the perception system is that the geometry of the surface profile and normal vectors are all obtained in real-time in the robot base coordinate system, thus eliminating issues such as precise registration of the work piece in the fixture and its location with respect to the robot base coordinates. An impedance-type closed-loop control algorithm is developed for pose tracking. The proposed system and control algorithm are employed to conduct surface finishing experiments on wooden surfaces. A representative sample of the results and measurement images of surface finish are provided to illustrate the capabilities of the robotic surface finishing system. A video of the system in operation is also provided.
ER  - 

TY  - CONF
TI  - Context-Dependent Compensation Scheme to Reduce Trajectory Execution Errors for Industrial Manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5578
EP  - 5584
AU  - P. M. Bhatt
AU  - P. Rajendran
AU  - K. McKay
AU  - S. K. Gupta
PY  - 2019
KW  - compensation
KW  - end effectors
KW  - industrial manipulators
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - execution error
KW  - end-effector loads
KW  - general purpose automated compensation scheme
KW  - trajectory errors
KW  - learned compensation scheme
KW  - context-dependent compensation scheme
KW  - automatically generated trajectories
KW  - robot model
KW  - actuator errors
KW  - low production volume applications
KW  - reduced trajectory execution errors
KW  - Trajectory
KW  - Service robots
KW  - End effectors
KW  - Trajectory tracking
KW  - Error correction
DO  - 10.1109/ICRA.2019.8793876
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Currently, automatically generated trajectories cannot be directly used on tasks that require high execution accuracies due to errors accused by inaccuracies in the robot model, actuator errors, and controller limitations. These trajectories often need manual refinement. This is not economically viable on low production volume applications. Unfortunately, execution errors are dependent on the nature of the trajectory and end-effector loads, and therefore devising a general purpose automated compensation scheme for reducing trajectory errors is not possible. This paper presents a method for analyzing the given trajectory, executing an exploratory physical run for a small portion of the given trajectory, and learning a compensation scheme based on the measured data. The learned compensation scheme is context-dependent and can be used to reduce the execution error. We have demonstrated the feasibility of this approach by conducting physical experiments.
ER  - 

TY  - CONF
TI  - Identifying Feasible Workpiece Placement with Respect to Redundant Manipulator for Complex Manufacturing Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5585
EP  - 5591
AU  - R. K. Malhan
AU  - A. M. Kabir
AU  - B. Shah
AU  - S. K. Gupta
PY  - 2019
KW  - end effectors
KW  - industrial manipulators
KW  - machine tools
KW  - nonlinear programming
KW  - redundant manipulators
KW  - redundant manipulator
KW  - complex manufacturing task
KW  - robot workspace
KW  - task surfaces
KW  - nonlinear optimization problem
KW  - complex workpieces
KW  - feasible workpiece placement
KW  - end-effector
KW  - constraint violation functions
KW  - Task analysis
KW  - Robot kinematics
KW  - End effectors
KW  - Tools
KW  - Indexes
DO  - 10.1109/ICRA.2019.8794353
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Successfully completing a complex manufacturing task requires finding a feasible placement of the workpiece in the robot workspace. The workpiece placement should be such that the task surfaces on the workpiece are reachable by the robot, the robot can apply the required forces, and the end-effector/tool can move with the desired velocity. This paper formulates the problem of identifying a feasible placement as a non-linear optimization problem over the constraint violation functions. This is a computationally challenging problem. We show that this problem can be solved by successively searching for the solution by incrementally applying different constraints. We demonstrate the feasibility of our approach using several complex workpieces.
ER  - 

TY  - CONF
TI  - Geometric Search-Based Inverse Kinematics of 7-DoF Redundant Manipulator with Multiple Joint Offsets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5592
EP  - 5598
AU  - A. Sinha
AU  - N. Chakraborty
PY  - 2019
KW  - end effectors
KW  - geometry
KW  - iterative methods
KW  - Jacobian matrices
KW  - manipulator kinematics
KW  - position control
KW  - redundant manipulators
KW  - geometric search-based inverse kinematics
KW  - geometric method
KW  - inverse kinematics problems
KW  - inverse position kinematics
KW  - manipulator Jacobian
KW  - IK algorithm
KW  - elbow joints
KW  - geometry-based IK solvers
KW  - redundant Baxter robot
KW  - End effectors
KW  - Kinematics
KW  - Shoulder
KW  - Wrist
KW  - Elbow
DO  - 10.1109/ICRA.2019.8793725
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a geometric method to solve inverse kinematics (IK) problems of 7-DoF manipulators with joint offsets at shoulder, elbow, and wrist. Traditionally, inverse position kinematics for redundant manipulators are solved by using an iterative method based on the pseudo-inverse of the manipulator Jacobian. This provides a single solution among the infinitely many possible solutions for the IK problem of redundant manipulators. There are no closed-form IK solutions for redundant manipulators with multiple joint offsets. Using our method we can compute multiple IK solutions using two-parameter search by exploiting geometry of the structure of a redundant manipulator. Our proposed IK algorithm can handle multiple joint offsets and is mathematically simple to implement in a few lines of code. We apply our algorithm to compute IK solutions for 7-DoF redundant Baxter robot (that has joint offsets at shoulder, wrist, and elbow joints) for end-effector configurations where existing geometry-based IK solvers fail to find solutions. We also demonstrate the use of our algorithm in an application where we want to compute an IK solution (among the infinitely many possible solutions) that has minimum error bound in end-effector position, in the presence of random joint actuation and sensing uncertainties.
ER  - 

TY  - CONF
TI  - Design and Formal Verification of a Safe Stop Supervisor for an Automated Vehicle*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5607
EP  - 5613
AU  - J. Krook
AU  - L. Svensson
AU  - Y. Li
AU  - L. Feng
AU  - M. Fabian
PY  - 2019
KW  - Global Positioning System
KW  - mobile robots
KW  - remotely operated vehicles
KW  - road safety
KW  - road vehicles
KW  - model-based approach
KW  - model checking
KW  - demonstration vehicle
KW  - formal verification
KW  - safe stop supervisor
KW  - automated vehicle
KW  - autonomous vehicles
KW  - pertinent planning
KW  - control algorithms
KW  - mode switch
KW  - nominal planners
KW  - safe fallback routine
KW  - safe position
KW  - nominal operational conditions
KW  - system failure
KW  - mode switching
KW  - safe stop trajectory planner
KW  - research concept vehicle
KW  - Trajectory
KW  - Planning
KW  - Automation
KW  - Global Positioning System
KW  - Software
KW  - Switches
KW  - Roads
DO  - 10.1109/ICRA.2019.8793636
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous vehicles apply pertinent planning and control algorithms under different driving conditions. The mode switch between these algorithms should also be autonomous. On top of the nominal planners, a safe fallback routine is needed to stop the vehicle at a safe position if nominal operational conditions are violated, such as for a system failure. This paper describes the design and formal verification of a supervisor to manage all requirements for mode switching between nominal planners, and additional requirements for switching to a safe stop trajectory planner that acts as the fallback routine. The supervisor is designed via a model-based approach and its abstraction is formally verified by model checking. The supervisor is implemented and integrated with the Research Concept Vehicle, an experimental research and demonstration vehicle developed at the KTH Royal Institute of Technology. Simulations and experiments show that the vehicle is able to autonomously drive in a safe manner between two parking lots and can successfully come to a safe stop upon GPS sensor failure.
ER  - 

TY  - CONF
TI  - Optimization-Based Terrain Analysis and Path Planning in Unstructured Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5614
EP  - 5620
AU  - U. Graf
AU  - P. Borges
AU  - E. HernÃ¡ndez
AU  - R. Siegwart
AU  - R. DubÃ©
PY  - 2019
KW  - data structures
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - optimisation
KW  - path planning
KW  - position control
KW  - remotely operated vehicles
KW  - terrain mapping
KW  - trees (mathematics)
KW  - path planning
KW  - environment representation
KW  - terrain modeling
KW  - graph edge expansions
KW  - optimization-based terrain analysis
KW  - unmanned ground vehicle
KW  - hierarchical model
KW  - local terrain map
KW  - graph search algorithms
KW  - vertex positions
KW  - compact data structure
KW  - space-dividing tree
KW  - environment model
KW  - rough environments
KW  - real-time optimization-based approach
KW  - unstructured environments
KW  - autonomous ground vehicle navigation
KW  - Optimization
KW  - Path planning
KW  - Planning
KW  - Data structures
KW  - Collision avoidance
KW  - Navigation
KW  - Robots
DO  - 10.1109/ICRA.2019.8794331
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate environment representation is one of the key challenges in autonomous ground vehicle navigation in unstructured environments. We propose a real-time optimization-based approach to terrain modeling and path planning in off-road and rough environments. Our method uses an irregular, hierarchical, graph-like environment model. A space-dividing tree is used to define a compact data structure capturing vertex positions and establishing connectivity. The same unique underlying data structure is used for both terrain modeling and path planning without memory reallocation. Local plans are generated by graph search algorithms and are continuously regenerated for on-the-fly obstacle avoidance inside the scope of the local terrain map. We show that implementing a hierarchical model over a regular space division reduces graph edge expansions by up to 84%. We illustrate the applicability of the method through experiments with an unmanned ground vehicle in both structured and unstructured environments.
ER  - 

TY  - CONF
TI  - Pedestrian Dominance Modeling for Socially-Aware Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5621
EP  - 5628
AU  - T. Randhavane
AU  - A. Bera
AU  - E. Kubin
AU  - A. Wang
AU  - K. Gray
AU  - D. Manocha
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - socially-aware robot navigation
KW  - dominance characteristics
KW  - PDM models
KW  - perceived dominance levels
KW  - dominance-based collision-avoidance
KW  - pedestrian dominance model
KW  - robot navigation
KW  - autonomous vehicle navigation
KW  - Robots
KW  - Navigation
KW  - Trajectory
KW  - Psychology
KW  - Computational modeling
KW  - Prediction algorithms
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794465
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Pedestrian Dominance Model (PDM) to identify the dominance characteristics of pedestrians for robot navigation. Through a perception study on a simulated dataset of pedestrians, PDM models the perceived dominance levels of pedestrians with varying motion behaviors corresponding to trajectory, speed, and personal space. At runtime, we use PDM to identify the dominance levels of pedestrians to facilitate socially-aware navigation for the robots. PDM can predict dominance levels from trajectories with ~85% accuracy. Prior studies in psychology literature indicate that when interacting with humans, people are more comfortable around people that exhibit complementary movement behaviors. Our algorithm leverages this by enabling the robots to exhibit complementing responses to pedestrian dominance. We also present an application of PDM for generating dominance-based collision-avoidance behaviors in the navigation of autonomous vehicles among pedestrians. We demonstrate the benefits of our algorithm for robots navigating among tens of pedestrians in simulated environments.
ER  - 

TY  - CONF
TI  - Dynamic Traffic Scene Classification with Space-Time Coherence
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5629
EP  - 5635
AU  - A. Narayanan
AU  - I. Dwivedi
AU  - B. Dariush
PY  - 2019
KW  - feature extraction
KW  - image classification
KW  - image motion analysis
KW  - object detection
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - traffic engineering computing
KW  - video signal processing
KW  - space-time variations
KW  - dynamic traffic scene classification
KW  - road scenes
KW  - space-time coherence
KW  - San Francisco Bay area
KW  - semantic context
KW  - feature extraction
KW  - tactical driver behavior understanding
KW  - driving behavior detection
KW  - vehicle ego-motion
KW  - time 80.0 hour
KW  - Roads
KW  - Meteorology
KW  - Vehicle dynamics
KW  - Semantics
KW  - Heuristic algorithms
KW  - Task analysis
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794137
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper examines the problem of dynamic traffic scene classification under space-time variations in viewpoint that arise from video captured on-board a moving vehicle. Solutions to this problem are important for realization of effective driving assistance technologies required to interpret or predict road user behavior. Currently, dynamic traffic scene classification has not been adequately addressed due to a lack of benchmark datasets that consider spatiotemporal evolution of traffic scenes resulting from a vehicle's ego-motion. This paper has three main contributions. First, an annotated dataset is released to enable dynamic scene classification that includes 80 hours of diverse high quality driving video data clips collected in the San Francisco Bay area. The dataset includes temporal annotations for road places, road types, weather, and road surface conditions. Second, we introduce novel and baseline algorithms that utilize semantic context and temporal nature of the dataset for dynamic classification of road scenes. Finally, we showcase algorithms and experimental results that highlight how extracted features from scene classification serve as strong priors and help with tactical driver behavior understanding. The results show significant improvement from previously reported driving behavior detection baselines in the literature.
ER  - 

TY  - CONF
TI  - Towards the Design of Robotic Drivers for Full-Scale Self-Driving Racing Cars
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5643
EP  - 5649
AU  - D. Caporale
AU  - A. Settimi
AU  - F. Massa
AU  - F. Amerotti
AU  - A. Corti
AU  - A. Fagiolini
AU  - M. Guiggiani
AU  - A. Bicchi
AU  - L. Pallottino
PY  - 2019
KW  - automobiles
KW  - control system synthesis
KW  - mobile robots
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - full-scale self-driving racing cars
KW  - autonomous vehicles
KW  - planning
KW  - control methods
KW  - autonomous racing cars
KW  - electric full scale autonomous racing car
KW  - control system architecture
KW  - localization methods
KW  - nonlinear model predictive control
KW  - pre-planned racing line
KW  - robotic driver design
KW  - Automobiles
KW  - Planning
KW  - Real-time systems
KW  - Computer architecture
KW  - Optimization
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8793882
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous vehicles are undergoing a rapid development thanks to advances in perception, planning and control methods and technologies achieved in the last two decades. Moreover, the lowering costs of sensors and computing platforms are attracting industrial entities, empowering the integration and development of innovative solutions for civilian use. Still, the development of autonomous racing cars has been confined mainly to laboratory studies and small to middle scale vehicles. This paper tackles the development of a planning and control framework for an electric full scale autonomous racing car, which is an absolute novelty in the literature, upon which we report our preliminary experiments and perspectives on future work. Our system leverages real time Nonlinear Model Predictive Control to track a pre-planned racing line. We describe the whole control system architecture including the mapping and localization methods employed.
ER  - 

TY  - CONF
TI  - Model-free Online Motion Adaptation for Optimal Range and Endurance of Multicopters
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5650
EP  - 5656
AU  - A. Tagliabue
AU  - X. Wu
AU  - M. W. Mueller
PY  - 2019
KW  - adaptive control
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - motion control
KW  - optimal control
KW  - path planning
KW  - position control
KW  - quadcopter
KW  - on-board power measurement
KW  - power consumption
KW  - energy-efficient loitering strategy
KW  - model-free online motion adaptation
KW  - extremum seeking control
KW  - aerodynamic disturbances
KW  - Power demand
KW  - Aerodynamics
KW  - Payloads
KW  - Propellers
KW  - Robots
KW  - Batteries
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793708
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we introduce an approach that allows a quadcopter to find the velocity which maximizes its flight time (endurance) or flight distance (range) while moving along a given path, using on-board power measurement. The proposed strategy is based on Extremum Seeking control and (a) does not require any model of the power consumption of the system, (b) can be executed on-line, and (c) guarantees adaptation to unknown disturbances. We show experimentally that hovering is not the most energy-efficient loitering strategy, and we demonstrate the proposed method's ability to adapt to different aerodynamic disturbances, such as payloads. The method may be especially useful in applications where a quadcopter carries an unknown payload, allowing it to adapt for improved range.
ER  - 

TY  - CONF
TI  - Multi-view Reconstruction of Wires using a Catenary Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5657
EP  - 5664
AU  - R. Madaan
AU  - M. Kaess
AU  - S. Scherer
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - extrapolation
KW  - image reconstruction
KW  - image segmentation
KW  - inspection
KW  - object detection
KW  - power cables
KW  - power engineering computing
KW  - robot vision
KW  - stereo image processing
KW  - multiview reconstruction
KW  - catenary model
KW  - UAV community
KW  - wire avoidance capabilities
KW  - powerline corridor inspection
KW  - multiview algorithm
KW  - catenary curve
KW  - partial wire detections
KW  - bundle-adjustment approaches
KW  - binarized wire segmentation images
KW  - approximate extrapolation
KW  - Wires
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Cameras
KW  - Transforms
KW  - Computational modeling
KW  - Atmospheric modeling
DO  - 10.1109/ICRA.2019.8793852
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reliable detection and reconstruction of wires is one of the hardest problems in the UAV community, with a wide ranging impact in the industry in terms of wire avoidance capabilities and powerline corridor inspection. In this work, we introduce a real-time, model-based, multi-view algorithm to reconstruct wires from a set of images with known camera poses, while exploiting their natural shape - the catenary curve. Using a model-based approach helps us deal with partial wire detections in images, which may occur due to natural occlusion and false negatives. In addition, using a parsimonious model makes our algorithm efficient as we only need to optimize for 5 model parameters, as opposed to hundreds of 3D points in bundle-adjustment approaches. Our algorithm obviates the need for pixel correspondences by computing the reprojection error via the distance transform of binarized wire segmentation images. Further, we make our algorithm robust to arbitrary initializations by introducing an on-demand, approximate extrapolation of the distance transform based objective. We demonstrate the effectiveness of our algorithm against false negatives and random initializations in simulation, and show qualitative results with real data collected from a small UAV.
ER  - 

TY  - CONF
TI  - Real-time Optimal Planning and Model Predictive Control of a Multi-rotor with a Suspended Load
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5665
EP  - 5671
AU  - C. Y. Son
AU  - D. Jang
AU  - H. Seo
AU  - T. Kim
AU  - H. Lee
AU  - H. J. Kim
PY  - 2019
KW  - aerospace robotics
KW  - collision avoidance
KW  - convex programming
KW  - helicopters
KW  - mobile robots
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - high-dimensional nonlinear system
KW  - differential flatness property
KW  - nonconvex constraints
KW  - convex optimization problem
KW  - optimal trajectory
KW  - semifeasible trajectory
KW  - model predictive control
KW  - suspended load
KW  - control algorithms
KW  - multirotor dynamics
KW  - real-time trajectory generation
KW  - collision-free trajectories
KW  - collision-free trajectory
KW  - dynamic coupling
KW  - real-time optimal planning
KW  - concave obstacle-avoidance constraints
KW  - sequential linear quadratic solver
KW  - Trajectory
KW  - Real-time systems
KW  - Planning
KW  - Convex functions
KW  - Vehicle dynamics
KW  - Nonlinear dynamical systems
KW  - Load modeling
DO  - 10.1109/ICRA.2019.8793674
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents planning and control algorithms for a multi-rotor with a suspended load. The suspended load cannot be controlled easily by the multi-rotor due to severe dynamic coupling between them. Difficulties are exacerbated by under-actuated, highly nonlinear nature of multi-rotor dynamics. Although many studies have been proposed to plan trajectories and control this system, there exist only a few reports on real-time trajectory generation. With this in mind, we propose a planning method which is capable of generating collision-free trajectories real-time and applicable to a high-dimensional nonlinear system. Using a differential flatness property, the system can be linearized entirely with elaborately chosen flat outputs. Convexification of non-convex constraints is carried out, and concave obstacle-avoidance constraints are converted to convex ones. After that, a convex optimization problem is solved to generate an optimal trajectory, but semi-feasible trajectory which considers only some parts of the initial state. We apply model predictive control with a sequential linear quadratic solver to compute a feasible collision-free trajectory and to control the system. Performance of the algorithm is validated by flight experiment.
ER  - 

TY  - CONF
TI  - Bioinspired Direct Visual Estimation of Attitude Rates with Very Low Resolution Images using Deep Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5672
EP  - 5678
AU  - M. MÃ©rida-Floriano
AU  - F. Caballero
AU  - D. Acedo
AU  - D. GarcÃ­a-Morales
AU  - F. Casares
AU  - L. Merino
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - data visualisation
KW  - image resolution
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - light source direction
KW  - artificial neural networks
KW  - deep networks
KW  - bioinspired visual system sensor
KW  - low resolution images
KW  - attitude rates
KW  - bioinspired direct visual estimation
KW  - source code
KW  - classical computer vision based method
KW  - learning approach
KW  - low resolution cameras
KW  - Drosophila's ocellar system
KW  - hardware setup
KW  - UAV
KW  - unmanned aerial vehicles
KW  - angular rates
KW  - Cameras
KW  - Robot sensing systems
KW  - Visualization
KW  - Estimation
KW  - Neural networks
KW  - Computer vision
KW  - Image resolution
DO  - 10.1109/ICRA.2019.8794057
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present a bioinspired visual system sensor to estimate angular rates in unmanned aerial vehicles (UAV) using Neural Networks. We have conceived a hardware setup to emulate Drosophila's ocellar system, three simple eyes related to stabilization. This device is composed of three low resolution cameras with a similar spatial configuration as the ocelli. There have been previous approaches based on this ocellar system, most of them considering assumptions such as known light source direction or a punctual light source. In contrast, here we present a learning approach using Artificial Neural Networks in order to recover the system's angular rates indoors and outdoors without previous knowledge. A classical computer vision based method is also derived to be used as a benchmark for the learning approach. The method is validated with a large dataset of images (more than half a million samples) including synthetic and real data. The source code of the algorithms and the datasets used in this paper have been released in an open repository.
ER  - 

TY  - CONF
TI  - Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5679
EP  - 5685
AU  - A. Keipour
AU  - M. Mousaei
AU  - S. Scherer
PY  - 2019
KW  - actuators
KW  - aerospace components
KW  - aerospace simulation
KW  - aircraft testing
KW  - autonomous aerial vehicles
KW  - fault diagnosis
KW  - fault tolerant control
KW  - least squares approximations
KW  - mobile robots
KW  - recursive least squares method
KW  - anomaly detection method
KW  - aircraft model
KW  - fault detection research
KW  - fixed-wing flights
KW  - ground truth
KW  - mid-flight actuator failures
KW  - fault detection open dataset
KW  - autonomous aircraft
KW  - correlated input-output pairs
KW  - autonomous aerial vehicles
KW  - Aircraft
KW  - Atmospheric modeling
KW  - Fault detection
KW  - Actuators
KW  - Reliability
KW  - Computational modeling
KW  - Safety
DO  - 10.1109/ICRA.2019.8794286
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent increase in the use of aerial vehicles raises concerns about the safety and reliability of autonomous operations. There is a growing need for methods to monitor the status of these aircraft and report any faults and anomalies to the safety pilot or to the autopilot to deal with the emergency situation. In this paper, we present a real-time approach using the Recursive Least Squares method to detect anomalies in the behavior of an aircraft. The method models the relationship between correlated input-output pairs online and uses the model to detect the anomalies. The result is an easy-to-deploy anomaly detection method that does not assume a specific aircraft model and can detect many types of faults and anomalies in a wide range of autonomous aircraft. The experiments on this method show a precision of 88.23%, recall of 88.23% and 86.36% accuracy for over 22 flight tests. The other contribution is providing a new fault detection open dataset for autonomous aircraft, which contains complete data and the ground truth for 22 fixed-wing flights with eight different types of mid-flight actuator failures to help future fault detection research for aircraft.
ER  - 

TY  - CONF
TI  - Learning ad-hoc Compact Representations from Salient Landmarks for Visual Place Recognition in Underwater Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5739
EP  - 5745
AU  - A. Maldonado-RamÃ­rez
AU  - L. A. Torres-Mendez
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - image coding
KW  - image representation
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - SLAM (robots)
KW  - unsupervised learning
KW  - salient landmarks
KW  - visual place recognition
KW  - underwater environments
KW  - visual attention algorithm
KW  - hand-crafted local descriptors
KW  - ad hoc descriptor generator
KW  - convolutional autoencoder
KW  - ad-hoc compact representations
KW  - SeqSLAM
KW  - FAB-MAP
KW  - SURF method
KW  - Visualization
KW  - Feature extraction
KW  - Image color analysis
KW  - Training
KW  - Robots
KW  - Task analysis
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793550
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose an approach to learn compact representations from salient landmarks detected by a visual attention algorithm to recognize previously visited places in underwater environments. Instead of using hand-crafted local descriptors as it has been typically done in visual place recognition, we use a convolutional autoencoder to obtain an ad hoc descriptor generator from salient landmarks. The main advantage of using an autoencoder is that it can learn in an unsupervised manner directly from the salient landmarks. In addition, we show that it is possible to do the training with less than 100,000 examples instead of several hundreds of thousands or even millions of labeled examples as in other convolutional architectures. The trained convolutional autoencoder is used to obtain descriptors for salient landmarks that are later utilized in a voting scheme to calculate similarity between images with the objective of finding if a place has already been visited. The proposed method has obtained good results compared to SeqSLAM and FAB-MAP in different datasets obtained from robotic explorations of coral reefs in real life conditions. Moreover, when the visual attention algorithm is used, fewer features are required to get a good performance in terms of precision and recall compared when using the SURF method to extract visual features.
ER  - 

TY  - CONF
TI  - Finding divers with SCUBANet
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5746
EP  - 5751
AU  - R. Codd-Downey
AU  - M. Jenkin
PY  - 2019
KW  - autonomous underwater vehicles
KW  - convolutional neural nets
KW  - gesture recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - diver-diver communication
KW  - diver-robot communication
KW  - underwater detection dataset
KW  - standard diver gestures
KW  - diver recognition
KW  - diver body-head-hand localization
KW  - CNN-based approach
KW  - SCUBANet dataset
KW  - human-robot communication
KW  - diver component recognition
KW  - robot-diver communication
KW  - human operators
KW  - divers finding
KW  - RF signal attenuation
KW  - gesture visual recognition
KW  - per-instance bounding boxes
KW  - crowd sourcing
KW  - transfer learning
KW  - Web-based interface
KW  - Standards
KW  - Training
KW  - Object detection
KW  - Robot sensing systems
KW  - Computer vision
KW  - Human-robot interaction
KW  - computer vision
KW  - object detection
KW  - dataset
KW  - underwater
KW  - robotics
DO  - 10.1109/ICRA.2019.8793655
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot-diver communication underwater is complicated by the attenuation of RF signals, the complexities of the environment in terms of deploying interaction devices, and issues related to the cognitive loading of human operators. Humans operating underwater have developed a simple yet effective strategy for diver-diver communication based on the visual recognition of gestures. Can a similar approach be effective for diver-robot communication? Here we present experiments with SCUBANet, an underwater detection dataset of body parts associated with diver-robot communication. Given the nature of standard diver gestures, here we concentrate on diver recognition and in particular on diver body-head-hand localization and examine the feasibility of using a CNN-based approach to address this problem. Such data-driven approaches typically require an appropriately annotated dataset. The SCUBANet dataset contains images of object classes commonly encountered during human-robot communication underwater. Object classes are labeled using per-instance bounding boxes. Annotations were created through crowd sourcing via a web-based interface to ease deployment. We provide baseline performance on diver and diver component recognition and localization using transfer learning on three widely available pre-trained models.
ER  - 

TY  - CONF
TI  - Robotic Detection of Marine Litter Using Deep Visual Detection Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5752
EP  - 5758
AU  - M. Fulton
AU  - J. Hong
AU  - M. J. Islam
AU  - J. Sattar
PY  - 2019
KW  - autonomous underwater vehicles
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - marine engineering
KW  - marine pollution
KW  - mobile robots
KW  - neural net architecture
KW  - object detection
KW  - robotic detection
KW  - marine litter
KW  - deep visual detection models
KW  - trash deposits
KW  - aquatic environments
KW  - marine ecosystems
KW  - autonomous underwater vehicles
KW  - AUV
KW  - deep-learning algorithms
KW  - convolutional neural network architectures
KW  - object detection
KW  - trained networks
KW  - underwater trash removal
KW  - Plastics
KW  - Training
KW  - Oceans
KW  - Data models
KW  - Object detection
KW  - Visualization
KW  - Biological system modeling
DO  - 10.1109/ICRA.2019.8793975
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Trash deposits in aquatic environments have a destructive effect on marine ecosystems and pose a long-term economic and environmental threat. Autonomous underwater vehicles (AUVs) could very well contribute to the solution of this problem by finding and eventually removing trash. This paper evaluates a number of deep-learning algorithms performing the task of visually detecting trash in realistic underwater environments, with the eventual goal of exploration, mapping, and extraction of such debris by using AUVs. A large and publicly-available dataset of actual debris in open-water locations is annotated for training a number of convolutional neural network architectures for object detection. The trained networks are then evaluated on a set of images from other portions of that dataset, providing insight into approaches for developing the detection capabilities of an AUV for underwater trash removal. In addition, the evaluation is performed on three different platforms of varying processing power, which serves to assess these algorithms' fitness for real-time applications.
ER  - 

TY  - CONF
TI  - A Dual-Bladder Buoyancy Engine for a Cephalopod-Inspired AUV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5759
EP  - 5764
AU  - N. Sholl
AU  - K. Mohseni
PY  - 2019
KW  - actuators
KW  - asymptotic stability
KW  - autonomous underwater vehicles
KW  - feedback
KW  - flow sensors
KW  - gears
KW  - Lyapunov methods
KW  - mobile robots
KW  - nonlinear control systems
KW  - pressure measurement
KW  - pressure sensors
KW  - pumps
KW  - remotely operated vehicles
KW  - robot dynamics
KW  - dual-bladder buoyancy engine
KW  - cephalopod-inspired AUV
KW  - nonlinear depth
KW  - backstepping depth
KW  - pitch controller
KW  - flow-rate feedback
KW  - custom flow sensor
KW  - differential pressure sensor
KW  - 3D-printed attachment
KW  - depth control capability
KW  - single-bladder buoyancy engine
KW  - depth controller
KW  - autonomous underwater vehicle
KW  - Buoyancy
KW  - Engines
KW  - Bladder
KW  - Backstepping
KW  - Force
KW  - Vehicle dynamics
KW  - Pressure sensors
DO  - 10.1109/ICRA.2019.8793872
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a nonlinear, backstepping depth and pitch controller for a dual-bladder buoyancy engine actuated by gear pumps. Flow-rate feedback is obtained using a custom flow sensor comprised of a differential pressure sensor and a small, 3D-printed attachment. The controller is simulated using a model of the CephaloBot, our in-house developed autonomous underwater vehicle (AUV). Its depth control capability is also experimentally validated using a single-bladder buoyancy engine on-board a smaller-scale test cylinder. Lyapunov stability analysis shows global, asymptotic stability, which is exhibited in our simulation. Our experiments verify that this buoyancy engine is a feasible and effective depth controller for AUVs.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Path Planning for Navigation on Road Networks Using Augmented MDPs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5780
EP  - 5786
AU  - L. Nardi
AU  - C. Stachniss
PY  - 2019
KW  - decision theory
KW  - Markov processes
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - state estimation
KW  - uncertainty-aware path planning
KW  - road networks
KW  - augmented MDPs
KW  - probabilistic algorithms
KW  - state estimation problems
KW  - robot
KW  - computationally expensive algorithms
KW  - uncertainty-augmented Markov Decision Process
KW  - planning approach
KW  - navigation policies
KW  - partially observable Markov decision process
KW  - navigation problems
KW  - Uncertainty
KW  - Roads
KW  - Planning
KW  - Navigation
KW  - Markov processes
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794121
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Although most robots use probabilistic algorithms to solve state estimation problems, path planning is often performed without considering the uncertainty about the robot's position. Uncertainty, however, matters in planning, but considering it often leads to computationally expensive algorithms. In this paper, we investigate the problem of path planning considering the uncertainty in the robot's belief about the world, in its perceptions and in its action execution. We propose the use of an uncertainty-augmented Markov Decision Process to approximate the underlying Partially Observable Markov Decision Process, and we employ a localization prior to estimate how the belief about the robot's position propagates through the environment. This yields to a planning approach that generates navigation policies able to make decisions according to the degree of uncertainty while being computationally tractable. We implemented our approach and thoroughly evaluated it on different navigation problems. Our experiments suggest that we are able to compute policies that are more effective than approaches that ignore the uncertainty, and that also outperform policies that always take the safest actions.
ER  - 

TY  - CONF
TI  - Real-time Model Based Path Planning for Wheeled Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5787
EP  - 5792
AU  - J. Jordan
AU  - A. Zell
PY  - 2019
KW  - electric vehicles
KW  - image colour analysis
KW  - image sensors
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - road safety
KW  - road vehicles
KW  - robot vision
KW  - search problems
KW  - wheels
KW  - model based traversability analysis method
KW  - complex environments
KW  - vehicles 3D pose
KW  - chassis collision
KW  - elevation map
KW  - reactive planning
KW  - safe paths
KW  - wheeled mobile robots
KW  - real world environment setups
KW  - real-time model
KW  - real-time path planning
KW  - simulated world environment setups
KW  - wheeled vehicles
KW  - vehicle model
KW  - scoring function
KW  - A*-like search strategy
KW  - RGB-D sensor
KW  - frequency 30.0 Hz
KW  - Wheels
KW  - Path planning
KW  - Robot sensing systems
KW  - Planning
KW  - Mobile robots
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8794133
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work presents a model based traversability analysis method which employs a detailed vehicle model to perform real-time path planning in complex environments. The vehicle model represents the vehicle's wheels and chassis, allowing it to accurately predict the vehicles 3D pose, detailed contact information for each wheel and the occurrence of a chassis collision given a 2D pose on an elevation map. These predictions are weighted, depending on the safety requirements of the vehicle, to provide a scoring function for an A*-like search strategy. The proposed method is designed to run at frame rates of 30Hz on data from a RGB-D sensor to provide reactive planning of safe paths. For evaluation, two wheeled mobile robots in different simulated and real world environment setups were tested to show the reliability and performance of the proposed method.
ER  - 

TY  - CONF
TI  - Integrity Risk-Based Model Predictive Control for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5793
EP  - 5799
AU  - O. A. Hafez
AU  - G. D. Arana
AU  - M. Spenko
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - predictive control
KW  - risk management
KW  - localization sensors
KW  - mission-critical situations
KW  - local nearest neighbor integrity risk evaluation methodology
KW  - data association faults
KW  - localization safety
KW  - control-input constraints
KW  - mobile robots
KW  - navigation integrity risk
KW  - integrity risk-based model predictive control
KW  - MPC
KW  - Feature extraction
KW  - Safety
KW  - Technological innovation
KW  - Predictive models
KW  - Mobile robots
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793521
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a Model Predictive Controller (MPC) that uses navigation integrity risk as a constraint. Navigation integrity risk accounts for the presence of faults in localization sensors and algorithms, an increasingly important consideration as the number of robots operating in life and mission-critical situations is expected to increase dramatically in near future (e.g. a potential influx of self-driving cars). Specifically, the work uses a local nearest neighbor integrity risk evaluation methodology that accounts for data association faults as a constraint in order to guarantee localization safety over a receding horizon. Moreover, state and control-input constraints have also been enforced in this work. The proposed MPC design is tested using real-world mapped environments, showing that a robot is capable of maintaining a predefined minimum level of localization safety while operating in an urban environment.
ER  - 

TY  - CONF
TI  - What lies in the shadows? Safe and computation-aware motion planning for autonomous vehicles using intent-aware dynamic shadow regions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5800
EP  - 5806
AU  - Y. Nager
AU  - A. Censi
AU  - E. Frazzoli
PY  - 2019
KW  - inference mechanisms
KW  - mobile robots
KW  - path planning
KW  - road safety
KW  - road vehicles
KW  - sensor fusion
KW  - autonomous driving safety
KW  - inference planning
KW  - passive safety
KW  - sensor observations
KW  - intent-aware dynamic shadow regions
KW  - computation-aware motion planning
KW  - driving behaviour
KW  - autonomous vehicle
KW  - Robot sensing systems
KW  - Planning
KW  - Safety
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793557
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the challenges of developing autonomous vehicles is planning in an inhabited environment under sensing uncertainty as well as limited perception and computational resources. Besides reasoning about the behaviour of traffic participants that are within the vehicles' field of view, safe autonomous driving also requires the vehicle to reason about possible traffic participants that might exist beyond its sensing horizon, and to adapt its driving behaviour accordingly. This paper describes an inference and motion planning pipeline that is able to guarantee passive safety (collisions are possible, but the autonomous vehicle will be at rest) with respect to hypothetical hidden agents that have not been observed yet. We also incorporate the vehicle's reaction time due to sensing and computational delays into the planning process; for example, we show how having a fast reaction time due to the availability of more computational resources leads to more aggressive trajectories, while a car with a larger reaction time will choose more relaxed trajectories that require less attention.
ER  - 

TY  - CONF
TI  - Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5807
EP  - 5814
AU  - A. Pierson
AU  - C. Vasile
AU  - A. Gandhi
AU  - W. Schwarting
AU  - S. Karaman
AU  - D. Rus
PY  - 2019
KW  - collision avoidance
KW  - handicapped aids
KW  - object detection
KW  - path planning
KW  - wheelchairs
KW  - dynamic risk density
KW  - congestion density
KW  - cost function
KW  - occupancy risk
KW  - velocity fields
KW  - object-based congestion cost
KW  - cluttered environments
KW  - autonomous navigation
KW  - object detection
KW  - object tracking
KW  - autonomous wheelchair
KW  - Navigation
KW  - Cost function
KW  - Wheelchairs
KW  - Dynamics
KW  - Vehicle dynamics
KW  - Planning
KW  - Level set
DO  - 10.1109/ICRA.2019.8793813
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we examine the problem of navigating cluttered environments without explicit object detection and tracking. We introduce the dynamic risk density to map the congestion density and spatial flow of the environment to a cost function for the agent to determine risk when navigating that environment. We build upon our prior work, wherein the agent maps the density and motion of objects to an occupancy risk, then navigate the environment over a specified risk level set. Here, the agent does not need to identify objects to compute the occupancy risk, and instead computes this cost function using the occupancy density and velocity fields around them. Simulations show how this dynamic risk density encodes movement information for the ego agent and closely models the object-based congestion cost. We implement our dynamic risk density on an autonomous wheelchair and show how it can be used for navigating unstructured, crowded and cluttered environments.
ER  - 

TY  - CONF
TI  - Deep Local Trajectory Replanning and Control for Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5815
EP  - 5822
AU  - A. Pokle
AU  - R. MartÃ­n-MartÃ­n
AU  - P. Goebel
AU  - V. Chow
AU  - H. M. Ewald
AU  - J. Yang
AU  - Z. Wang
AU  - A. Sadeghian
AU  - D. Sadigh
AU  - S. Savarese
AU  - M. VÃ¡zquez
PY  - 2019
KW  - collision avoidance
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - velocity control
KW  - robot navigation
KW  - hierarchical planning
KW  - machine learning
KW  - optimal paths
KW  - deep local trajectory planner
KW  - velocity controller
KW  - motion commands
KW  - attention mechanisms
KW  - nearby pedestrians
KW  - map global plan information
KW  - sensor data
KW  - velocity commands
KW  - hand-designed traditional navigation system
KW  - deep local trajectory replanning
KW  - global planner
KW  - Navigation
KW  - Robot kinematics
KW  - Trajectory
KW  - Planning
KW  - Robot sensing systems
KW  - Laser radar
DO  - 10.1109/ICRA.2019.8794062
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a navigation system that combines ideas from hierarchical planning and machine learning. The system uses a traditional global planner to compute optimal paths towards a goal, and a deep local trajectory planner and velocity controller to compute motion commands. The latter components of the system adjust the behavior of the robot through attention mechanisms such that it moves towards the goal, avoids obstacles, and respects the space of nearby pedestrians. Both the structure of the proposed deep models and the use of attention mechanisms make the system's execution interpretable. Our simulation experiments suggest that the proposed architecture outperforms baselines that try to map global plan information and sensor data directly to velocity commands. In comparison to a hand-designed traditional navigation system, the proposed approach showed more consistent performance.
ER  - 

TY  - CONF
TI  - Learning from Transferable Mechanics Models: Generalizable Online Mode Detection in Underactuated Dexterous Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5823
EP  - 5829
AU  - A. S. Morgan
AU  - W. G. Bircher
AU  - B. Calli
AU  - A. M. Dollar
PY  - 2019
KW  - control engineering computing
KW  - dexterous manipulators
KW  - grippers
KW  - Jacobian matrices
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - random forests
KW  - supervised learning
KW  - transferable mechanics models
KW  - generalizable online mode detection
KW  - underactuated dexterous manipulation
KW  - mechanics-inspired framework
KW  - fingertip-based planar within-hand manipulation
KW  - underactuated robotic gripper
KW  - hand-object system
KW  - grasp matrix
KW  - manipulability metrics
KW  - planar manipulation modes
KW  - supervised learning model
KW  - contact curvatures
KW  - prediction transferability
KW  - visual approach
KW  - gripper models
KW  - finger Jacobians
KW  - random forests classifier
KW  - Grippers
KW  - Transmission line matrix methods
KW  - Feature extraction
KW  - Jacobian matrices
KW  - Kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793727
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we investigate a mechanics-inspired framework for describing fingertip-based planar within-hand manipulation with an underactuated robotic gripper. In particular, this framework leverages fundamental mechanics properties of the hand-object system, including basic terms such as local contact curvature as well as more complex features including the grasp matrix and manipulability metrics. These are extracted using a simple visual approach and then in real-time used for predicting planar manipulation modes: namely rolling, dropped, stuck, and sliding. Given a desired cartesian motion for the object, a supervised learning model predicts these four manipulation modes before they occur, allowing us to either avoid or trigger these different behaviors. Since we utilize strictly fundamental properties of the grasp matrix, finger Jacobians, and contact curvatures, we are able to demonstrate prediction transferability between different grippers using our original classifier. In particular, a Random Forests classifier trained on one gripper successfully predicts manipulation modes for grippers with different fingers with 84% accuracy, compared to just 56% from an approach in previous work. Overall, we find that the features designed in our approach better describes fingertip manipulation when precise gripper models are not available.
ER  - 

TY  - CONF
TI  - CARA system Architecture - A Click and Assemble Robotic Assembly System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5830
EP  - 5836
AU  - H. Fakhurldeen
AU  - F. Dailami
AU  - A. G. Pipe
PY  - 2019
KW  - CAD
KW  - product design
KW  - robotic assembly
KW  - tolerance analysis
KW  - implemented architecture capabilities
KW  - CARA system architecture
KW  - click and assemble robotic assembly system
KW  - industrial product
KW  - tolerances
KW  - CAD
KW  - end to end robotic assembly premise
KW  - Robotic assembly
KW  - Robot sensing systems
KW  - Task analysis
KW  - Planning
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8794114
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Future robotic assembly systems will allow product designers to upload their assembled product models remotely such that they can be assembled autonomously. In this work we present the architecture for a Click and Assemble Robotic Assembly (CARA) system. This architecture takes an assembly file uploaded by the user through a web interface as the only input. It then performs all the necessary planning before executing the assembly. To the authors' knowledge, this is the first time that all of the required components from previous advances in robotic assembly have been brought together, with all interconnecting challenges solved, into a complete working system for physical, real world assembly tasks. To demonstrate the implemented architecture capabilities, a real industrial product with tight tolerances was assembled from its CAD file only, illustrating the end to end robotic assembly premise in a real world setting.
ER  - 

TY  - CONF
TI  - Tool Macgyvering: Tool Construction Using Geometric Reasoning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5837
EP  - 5843
AU  - L. Nair
AU  - J. Balloch
AU  - S. Chernova
PY  - 2019
KW  - hand tools
KW  - manipulators
KW  - tool construction
KW  - geometric reasoning
KW  - tool Macgyvering problem
KW  - substitution problems
KW  - 7-DOF robot arm
KW  - Tools
KW  - Robots
KW  - Task analysis
KW  - Fasteners
KW  - Pipelines
KW  - Cognition
KW  - Complexity theory
DO  - 10.1109/ICRA.2019.8793257
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - MacGyvering is defined as creating or repairing something in an inventive or improvised way by utilizing objects that are available at hand. In this paper, we explore a subset of Macgyvering problems involving tool construction, i.e., creating tools from parts available in the environment. We formalize the overall problem domain of tool Macgyvering, introducing three levels of complexity for tool construction and substitution problems, and presenting a novel computational framework aimed at solving one level of the tool Macgyvering problem, specifically contributing a novel algorithm for tool construction based on geometric reasoning. We validate our approach by constructing three tools using a 7-DOF robot arm.
ER  - 

TY  - CONF
TI  - A Framework for Robot Manipulation: Skill Formalism, Meta Learning and Adaptive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5844
EP  - 5850
AU  - L. Johannsmeier
AU  - M. Gerchow
AU  - S. Haddadin
PY  - 2019
KW  - adaptive control
KW  - learning systems
KW  - manipulators
KW  - adaptive control
KW  - adaptive impedance control
KW  - meta parameter learning
KW  - compatible skill specifications
KW  - abstract expert knowledge
KW  - quality evaluation metrics
KW  - adaptive impedance controller
KW  - carefully defined skill formalism
KW  - manipulation tasks
KW  - learned tasks
KW  - learning-based solution
KW  - learning force-sensitive robot manipulation skills
KW  - submillimeter industrial tolerances
KW  - time 20.0 min
KW  - Robots
KW  - Impedance
KW  - Task analysis
KW  - Trajectory
KW  - Reinforcement learning
KW  - Complexity theory
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793542
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we introduce a novel framework for expressing and learning force-sensitive robot manipulation skills. It is based on a formalism that extends our previous work on adaptive impedance control with meta parameter learning and compatible skill specifications. This way the system is also able to make use of abstract expert knowledge by incorporating process descriptions and quality evaluation metrics. We evaluate various state-of-the-art schemes for meta parameter learning and experimentally compare selected ones. Our results clearly indicate that the combination of our adaptive impedance controller with a carefully defined skill formalism significantly reduces the complexity of manipulation tasks even for learning peg-in-hole with submillimeter industrial tolerances. Overall, the considered system is able to learn variations of this skill in under 20 minutes. In fact, experimentally the system was able to perform the learned tasks without visual feedback faster than humans, leading to the first learning-based solution of complex assembly at such real-world performance.
ER  - 

TY  - CONF
TI  - Open-Loop Collective Assembly Using a Light Field to Power and Control a Phototaxic Mini-Robot Swarm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5851
EP  - 5857
AU  - A. Bignell
AU  - L. Li
AU  - R. Vaughan
PY  - 2019
KW  - artificial life
KW  - computational geometry
KW  - mobile robots
KW  - multi-robot systems
KW  - open loop systems
KW  - path planning
KW  - open-loop collective assembly
KW  - collective construction
KW  - dynamic light field design strategies
KW  - assembled shapes
KW  - mobile robots
KW  - polygonal shapes
KW  - phototaxic minirobot swarm
KW  - nonconvex polygons
KW  - global light field
KW  - Robot kinematics
KW  - Shape
KW  - Robot sensing systems
KW  - Mobile robots
KW  - Task analysis
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794148
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel scheme that jointly addresses the problems of powering and coordinating a population of mini-robots for collective construction. In our setting, a population of simple mobile robots must push blocks into desired polygonal shapes. Each robot performs only simple phototaxis. Coordination is purely open-loop: a global light field guides and powers the robots. We demonstrate this concept in simulation and explore a series of dynamic light field design strategies that robustly result in assembled shapes including nonconvex polygons.
ER  - 


